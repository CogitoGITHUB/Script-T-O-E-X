#+title:      Computer Networking

* Computer Networking
** Basics of computer networking
*** Basic intro to computer networking
**Open system:** A system which is connected to the network and is ready for communication.

**Closed system:** A system which is not connected to the network and can’t be communicated with.

**Computer Network:** An
 interconnection of multiple devices, also known as hosts, that are 
connected using multiple paths for the purpose of sending/receiving data
 or media. Computer networks can also include multiple devices/mediums 
which help in the communication between two different devices; these are
 known as **Network devices** and include things such as routers, switches, hubs, and bridges. 

!https://media.geeksforgeeks.org/wp-content/uploads/Computer-Networking-Diagram.png

**Network Topology:** The layout arrangement of the different devices in a network. Common examples include: Bus, Star, Mesh, Ring, and Daisy chain. 

!https://media.geeksforgeeks.org/wp-content/uploads/Network-Topology-Diagram.png

**OSI:** OSI stands for **Open Systems Interconnection**. It is a reference model that specifies standards for communications protocols and also the functionalities of each layer.

**Protocol:** A
 protocol is the set of rules or algorithms which define the way how two
 entities can communicate across the network and there exists different 
protocol defined at each layer of the OSI model. Few of such protocols 
are TCP, IP, UDP, ARP, DHCP, FTP and so on.

**UNIQUE IDENTIFIERS OF NETWORK** **Host name:** Each device in the network is associated with a unique device name known as Hostname. Type “hostname” in the command prompt(Administrator Mode) and press ‘Enter’, this displays the hostname of your machine. 

!https://media.geeksforgeeks.org/wp-content/uploads/hostname.png

**IP Address (Internet Protocol address):** Also known as the Logical Address, the IP Address is the network address of the system across the network. To
 identify each device in the world-wide-web, the Internet Assigned 
Numbers Authority (IANA) assigns an IPV4 (Version 4) address as a unique
 identifier to each device on the Internet. The length of an IPv4 address is 32-bits, hence, we have 232 IP addresses available. The length of an IPv6 address is 128-bits.*Type “ipconfig” in the command prompt and press ‘Enter’, this gives us the IP address of the device.*

**MAC Address (Media Access Control address):** Also
 known as physical address, the MAC Address is the unique identifier of 
each host and is associated with its NIC (Network Interface Card). A MAC address is assigned to the NIC at the time of manufacturing. The length of the MAC address is : 12-nibble/ 6 bytes/ 48 bits *Type “ipconfig/all” in the command prompt and press ‘Enter’, this gives us the MAC address.*

**Port:** A
 port can be referred to as a logical channel through which data can be 
sent/received to an application. Any host may have multiple applications
 running, and each of these applications is identified using the port 
number on which they are running. A port number is a 16-bit integer, hence, we have 216 ports available which are categorized as shown below:

[Untitled Database](https://www.notion.so/e155f0b740544b2faffd3446d145ba0e?pvs=21)

Number of ports: 65,536 Range: 0 – 65535 *Type “**netstat -a**” in the command prompt and press ‘Enter’, this lists all the ports being used.* 

!https://media.geeksforgeeks.org/wp-content/uploads/ports.png

**Socket:** The unique combination of IP address and Port number together are termed as Socket.

**Other related concepts** **DNS Server:** DNS stands for **Domain Name system**. DNS
 is basically a server which translates web addresses or URLs (ex: 
www.google.com) into their corresponding IP addresses. We don’t have to 
remember all the IP addresses of each and every website. The command ‘**nslookup**’ gives you the IP address of the domain you are looking for. This also provides the information of our DNS Server. 

!https://media.geeksforgeeks.org/wp-content/uploads/nslookup.png

**ARP:** ARP stands for **Address Resolution Protocol**. It is used to convert an IP address to its corresponding physical address(i.e., MAC Address). ARP is used by the Data Link Layer to identify the MAC address of the Receiver’s machine.

**RARP:** RARP stands for **Reverse Address Resolution Protocol**. As
 the name suggests, it provides the IP address of the device given a 
physical address as input. But RARP has become obsolete since the time 
DHCP has come into the picture.
*** GOALS OF NETWORKING
Computer
 Network means an interconnection of autonomous (standalone) computers 
for information exchange. The connecting media could be a copper wire, 
optical fiber, microwave, or satellite.

**Networking Elements –** The computer network includes the following networking elements:

1. At least two computers
2. Transmission medium either wired or wireless
3. Protocols or rules that govern the communication
4. Network software such as Network Operating System

**Network Criteria:** The criteria that have to be met by a computer network are:

**1. Performance –** It is measured in terms of transit time and response time.

- Transit time is the time for a message to travel from one device to another
- Response time is the elapsed time between an inquiry and a response.

Performance is dependent on the following factors:

- The number of users
- Type of transmission medium
- Capability of connected network
- Efficiency of software

**2. Reliability –** It is measured in terms of

- Frequency of failure
- Recovery from failures
- Robustness during catastrophe

**3. Security –** It means protecting data from unauthorized access.

**Goals of Computer Networks:** The following are some important goals of computer networks:

1. **Resource Sharing –** Many organization has a substantial number of computers in operations, which are located apart. Ex. A group of office workers can share a common
printer, fax, modem, scanner, etc. 
2. **High Reliability –** If there are alternate sources of supply, all files could be replicated on two or more machines. If one of them is not available, due to hardware
failure, the other copies could be used. 
3. **Inter-process Communication –** Network users, located geographically apart, may converse in an interactive
session through the network. In order to permit this, the network must
provide almost error-free communications. 
4. **Flexible access –** Files can be accessed from any computer in the network. The project can be begun on one computer and finished on another.
    
    Other
     goals include Distribution of processing functions, Centralized 
    management, and allocation of network resources, Compatibility of 
    dissimilar equipment and software, Good network performance, 
    Scalability, Saving money, Access to remote information, Person to 
    person communication, etc.
*** TYPES OF NETWORK TOPOLOGY
The 
arrangement of a network that comprises nodes and connecting lines via 
sender and receiver is referred to as network topology. The various 
network topologies are:

## Mesh Topology:

In
 a mesh topology, every device is connected to another device via a 
particular channel. In Mesh Topology, the protocols used are AHCP (Ad 
Hoc Configuration Protocols), DHCP (Dynamic Host Configuration 
Protocol), etc.

!https://media.geeksforgeeks.org/wp-content/uploads/1-75.png

**Figure 1**: Every device is connected with another via dedicated channels. These channels are known as links. 

- Suppose, the N number of devices are connected with each other in a mesh
topology, the total number of ports that are required by each device is
N-1. In Figure 1, there are 5 devices connected to each other, hence the total number of ports required by each device is 4. Total number of
ports required=N*(N-1).
- Suppose, N number of devices are
connected with each other in a mesh topology, then the total number of
dedicated links required to connect them is C
i.e. N(N-1)/2. In Figure 1, there are 5 devices connected to each other, hence the total number of links required is 5*4/2 = 10.
    
    N
    
    2
    

**Advantages of this topology:**

- It is robust.
- The fault is diagnosed easily. Data is reliable because data is transferred among the devices through dedicated channels or links.
- Provides security and privacy.

**Problems with this topology:**

- Installation and configuration are difficult.
- The cost of cables is high as bulk wiring is required, hence suitable for less number of devices.
- The cost of maintenance is high.

## Star Topology:

In
 star topology, all the devices are connected to a single hub through a 
cable. This hub is the central node and all other nodes are connected to
 the central node. The hub can be passive in nature i.e., not an 
intelligent hub such as broadcasting devices, at the same time the hub 
can be intelligent known as an active hub. Active hubs have repeaters in
 them. In Star Topology, many popular Ethernet LAN protocols are used as
 CD(Collision Detection), CSMA (Carrier Sense Multiple Access), etc.

!https://media.geeksforgeeks.org/wp-content/uploads/2-49.png

**Figure 2**: A star topology having four systems connected to a single point of connection i.e. hub.

**Advantages of this topology:**

- If N devices are connected to each other in a star topology, then the
number of cables required to connect them is N. So, it is easy to set
up.
- Each device requires only 1 port i.e. to connect to the hub, therefore the total number of ports required is N.
- It is Robust. If one link fails only that link will affect and not other than that.
- Easy to fault identification and fault isolation.

**Problems with this topology:**

- If the concentrator (hub) on which the whole topology relies fails, the whole system will crash down.
- The cost of installation is high.
- Performance is based on the single concentrator i.e. hub.

## Bus Topology:

Bus
 topology is a network type in which every computer and network device 
is connected to a single cable. It transmits the data from one end to 
another in a single direction. No bi-directional feature is in bus 
topology. It is a multi-point connection and a non-robust topology 
because if the backbone fails the topology crashes. In Bus Topology, 
various MAC (Media Access Control) protocols are followed by LAN 
ethernet connections like TDMA, Pure Aloha, CDMA, Slotted Aloha, etc.

!https://media.geeksforgeeks.org/wp-content/uploads/3-55.png

**Figure 3**: A bus topology with shared backbone cable. The nodes are connected to the channel via drop lines.

**Advantages of this topology:**

- If N devices are connected to each other in a bus topology, then the
number of cables required to connect them is 1, which is known as
backbone cable, and N drop lines are required.
- The cost of the cable is less compared to other topologies, but it is used to build small networks.

**Problems with this topology:**

- If the common cable fails, then the whole system will crash down.
- If the network traffic is heavy, it increases collisions in the network.
To avoid this, various protocols are used in the MAC layer known as Pure Aloha, Slotted Aloha, CSMA/CD, etc.
- Security is very low.

## Ring Topology:

In this topology, it forms a ring connecting devices with exactly two neighboring devices.

A
 number of repeaters are used for Ring topology with a large number of 
nodes, because if someone wants to send some data to the last node in 
the ring topology with 100 nodes, then the data will have to pass 
through 99 nodes to reach the 100th node. Hence to prevent data loss 
repeaters are used in the network.

The transmission is 
unidirectional, but it can be made bidirectional by having 2 connections
 between each Network Node, it is called Dual Ring Topology. In-Ring 
Topology, the Token Ring Passing protocol is used by the workstations to
 transmit the data.

!https://media.geeksforgeeks.org/wp-content/uploads/4-32.png

**Figure 4**: A ring topology comprises 4 stations connected with each forming a ring.

The following operations take place in ring topology are : 

1. One station is known as a **monitor** station which takes all the responsibility to perform the operations.
2. To transmit the data, the station has to hold the token. After the
transmission is done, the token is to be released for other stations to
use.
3. When no station is transmitting the data, then the token will circulate in the ring.
4. There are two types of token release techniques: **Early token release** releases the token just after transmitting the data and **Delay token release** releases the token after the acknowledgment is received from the receiver.

**Advantages of this topology:**

- The possibility of collision is minimum in this type of topology.
- Cheap to install and expand.

**Problems with this topology:**

- Troubleshooting is difficult in this topology.
- The addition of stations in between or removal of stations can disturb the whole topology.
- Less secure.

## Tree Topology :

This
 topology is the variation of the Star topology. This topology has a 
hierarchical flow of data. In Tree Topology, SAC (Standard Automatic 
Configuration ) protocols like DHCP and SAC are used.

!https://media.geeksforgeeks.org/wp-content/uploads/20200614134830/tree-topology2.png

**Figure 5**:
 In this, the various secondary hubs are connected to the central hub 
which contains the repeater. This data flow from top to bottom i.e. from
 the central hub to the secondary and then to the devices or from bottom
 to top i.e. devices to the secondary hub and then to the central 
hub. It is a multi-point connection and a non-robust topology because if
 the backbone fails the topology crashes.

**Advantages of this topology :**

- It allows more devices to be attached to a single central hub thus it
decreases the distance that is traveled by the signal to come to the
devices.
- It allows the network to get isolated and also prioritize from different computers.

**Problems with this topology :**

- If the central hub gets fails the entire system fails.
- The cost is high because of cabling.

## Hybrid Topology :

This
 topology technology is the combination of all the various types of 
topologies we have studied above. It is used when the nodes are free to 
take any form. It means these can be individuals such as Ring or Star 
topology or can be a combination of various types of topologies seen 
above. Each individual topology uses the protocol that has been 
discussed earlier.

!https://media.geeksforgeeks.org/wp-content/uploads/20220610155821/Untitleddesign.png

Hybrid Topology

**Figure 6**:
 The above figure shows the structure of the Hybrid topology. As seen it
 contains a combination of all different types of networks.
*** TYPES OF AREA NETWORK
The **Network** allows computers to **connect and communicate**
 with different computers via any medium. LAN, MAN, and WAN are the 
three major types of networks designed to operate over the area they 
cover. There are some similarities and dissimilarities between them. One
 of the major differences is the geographical area they cover, i.e. **LAN** covers the smallest area; **MAN** covers an area larger than LAN and **WAN** comprises the largest of all. There are other types of Computer Networks also, like : 

- PAN (Personal Area Network)
- SAN (Storage Area Network)
- EPN (Enterprise Private Network)
- VPN (Virtual Private Network)

### Local Area Network (LAN) –

LAN
 or Local Area Network connects network devices in such a way that 
personal computers and workstations can share data, tools, and programs.
 The group of computers and devices are connected together by a switch, 
or stack of switches, using a private addressing scheme as defined by 
the TCP/IP protocol. Private addresses are unique in relation to other 
computers on the local network. Routers are found at the boundary of a 
LAN, connecting them to the larger WAN.

Data transmits at a very 
fast rate as the number of computers linked is limited. By definition, 
the connections must be high speed and relatively inexpensive hardware 
(Such as hubs, network adapters, and Ethernet cables). LANs cover a 
smaller geographical area (Size is limited to a few kilometers) and are 
privately owned. One can use it for an office building, home, hospital, 
schools, etc. LAN is easy to design and maintain. A Communication medium
 used for LAN has twisted-pair cables and coaxial cables. It covers a 
short distance, and so the error and noise are minimized.

Early 
LANs had data rates in the 4 to 16 Mbps range. Today, speeds are 
normally 100 or 1000 Mbps. Propagation delay is very short in a LAN. The
 smallest LAN may only use two computers, while larger LANs can 
accommodate thousands of computers. A LAN typically relies mostly on 
wired connections for increased speed and security, but wireless 
connections can also be part of a LAN. The fault tolerance of a LAN is 
more and there is less congestion in this network. For example A bunch 
of students playing Counter-Strike in the same room (without internet).

### Metropolitan Area Network (MAN) –

MAN
 or Metropolitan area Network covers a larger area than that of a LAN 
and smaller area as compared to WAN. It connects two or more computers 
that are apart but reside in the same or different cities. It covers a 
large geographical area and may serve as an ISP (Internet Service 
Provider). MAN is designed for customers who need high-speed 
connectivity. Speeds of MAN range in terms of Mbps. It’s hard to design 
and maintain a Metropolitan Area Network.

!https://media.geeksforgeeks.org/wp-content/uploads/20210817121003/man-300x192.png

The
 fault tolerance of a MAN is less and also there is more congestion in 
the network. It is costly and may or may not be owned by a single 
organization. The data transfer rate and the propagation delay of MAN 
are moderate. Devices used for transmission of data through MAN are 
Modem and Wire/Cable. Examples of a MAN are the part of the telephone 
company network that can provide a high-speed DSL line to the customer 
or the cable TV network in a city.

### Wide Area Network (WAN) –

WAN
 or Wide Area Network is a computer network that extends over a large 
geographical area, although it might be confined within the bounds of a 
state or country. A WAN could be a connection of LAN connecting to other
 LANs via telephone lines and radio waves and may be limited to an 
enterprise (a corporation or an organization) or accessible to the 
public. The technology is high speed and relatively expensive.

There
 are two types of WAN: Switched WAN and Point-to-Point WAN. WAN is 
difficult to design and maintain. Similar to a MAN, the fault tolerance 
of a WAN is less and there is more congestion in the network. A 
Communication medium used for WAN is PSTN or Satellite Link. Due to 
long-distance transmission, the noise and error tend to be more in WAN.

WAN’s
 data rate is slow about a 10th LAN’s speed since it involves increased 
distance and increased number of servers and terminals etc. Speeds of 
WAN ranges from a few kilobits per second (Kbps) to megabits per second 
(Mbps). Propagation delay is one of the biggest problems faced here. 
Devices used for the transmission of data through WAN are Optic wires, 
Microwaves, and Satellites. An example of a Switched WAN is the 
asynchronous transfer mode (ATM) network and Point-to-Point WAN is a 
dial-up line that connects a home computer to the Internet.

Conclusion –

There
 are many advantages of LAN over MAN and WAN, such as LAN’s provide 
excellent reliability, high data transmission rate, they can easily be 
managed and shares peripheral devices too. Local Area Network cannot 
cover cities or towns and for that Metropolitan Area Network is needed, 
which can connect a city or a group of cities together. Further, for 
connecting a Country or a group of Countries one requires a Wide Area 
Network.
*** MANET
MANET stands for Mobile Adhoc Network also called a wireless Adhoc 
network or Adhoc wireless network that usually has a routable networking
 environment on top of a Link Layer ad hoc network.. They consist of a 
set of mobile nodes connected wirelessly in a self-configured, 
self-healing network without having a fixed infrastructure. MANET nodes 
are free to move randomly as the network topology changes frequently. 
Each node behaves as a router as they forward traffic to other specified
 nodes in the network.

!https://media.geeksforgeeks.org/wp-content/cdn-uploads/66-2.png

MANET
 may operate a standalone fashion or they can be part of larger 
internet. They form a highly dynamic autonomous topology with the 
presence of one or multiple different transceivers between nodes. The 
main challenge for the MANET is to equip each device to continuously 
maintain the information required to properly route traffic. MANETs 
consist of a peer-to-peer, self-forming, self-healing network MANET’s 
circa 2000-2015 typically communicate at radio frequencies (30MHz-5GHz).
 This can be used in road safety, ranging from sensors for the 
environment, home, health, disaster rescue operations, air/land/navy 
defense, weapons, robots, etc.

**Characteristics of MANET –**

- **Dynamic Topologies:** Network topology which is typically multihop may change randomly and rapidly
with time, it can form unidirectional or bi-directional links.
- **Bandwidth constrained, variable capacity links:** Wireless links usually have lower reliability, efficiency, stability, and capacity as compared to a wired network
- **Autonomous Behavior:** Each node can act as a host and router, which shows its autonomous behavior.
- **Energy Constrained Operation:** As some or all the nodes rely on batteries or other exhaustible means for
their energy. Mobile nodes are characterized by less memory, power, and
lightweight features.
- **Limited Security:** Wireless networks are more prone to security threats. A centralized firewall is
absent due to the distributed nature of the operation for security,
routing, and host configuration.
- **Less Human Intervention:** They require minimum human intervention to configure the network, therefore they are dynamically autonomous in nature.

**Pros and Cons of MANET –**

**Pros:**

1. Separation from central network administration.
2. Each node can play both the roles ie. of router and host showing autonomous nature.
3. Self-configuring and self-healing nodes do not require human intervention.
4. Highly scalable and suits the expansion of more network hub.

**Cons:**

1. Resources are limited due to various constraints like noise, interference conditions, etc.
2. Lack of authorization facilities.
3. More prone to attacks due to limited physical security.
4. High latency i.e. There is a huge delay in the transfer of data between two sleeping nodes.

**MANET** stands for Mobile adhoc Network also called as
 wireless adhoc network or adhoc wireless network. They consist of a set
 of mobile nodes connected wirelessly in a self-configured, self-healing
 network without having a fixed infrastructure. MANET nodes are free to 
move randomly as the network topology changes frequently.

**Types of MANET –** 

1. **Vehicular Ad hoc Network (VANETs) –** Enable effective communication with another vehicle or with the roadside
equipments. Intelligent vehicular ad hoc networks(InVANETs) deals with
another vehicle or with roadside equipments. 
2. **Smart Phone Ad hoc Network (SPANC) –** To create peer-to-peer networks without relying on cellular carrier
networks, wireless access points, or traditional network infrastructure. Here peers can join or leave the network without destroying it. 
3. **Internet based Mobile Ad hoc Network (iMANETs) –** It supports internet protocols such as TCP/UDP and IP. To link mobile nodes and establish routes distributed and automatically. 
4. **Hub-Spoke MANET:** Multiple sub MANET’s may be connected in hub-spoke VPN to create a
geographically distributed MANET. Normal Ad-hoc routing algorithm does
not apply directly. 
5. **Military or Tactical MANETs –** This is used by the military units. Emphasis on data rate, real-time demand, fast re-routing during mobility, security, radio range, etc. 
6. **Flying Ad hoc Network (FANETs) –** This is composed of unmanned aerial vehicles (commonly known as drones). Provides links to remote areas and mobility.
*** Redundant Link problems in Computer Network
Basically, **redundant links** are used to prevent nasty
 network failure. These are used to provide redundancy, i.e back up when
 a link fails, i.e a frame can be forwarded out through another path but
 it can cause problems also.

Here are some of these problems:

**Broadcast Storm –** A
 switch forwards out the broadcast frame, generated by another device, 
to all its ports. If no loop avoidance schemes are applied then the 
switches will flood broadcasts endlessly throughout the network which 
consumes all the available bandwidth. This phenomenon is called a 
broadcast storm.

A broadcast storm is a serious network problem and can shut down the entire network in seconds.

**Example:**

!https://media.geeksforgeeks.org/wp-content/uploads/Untitled-Diagram-2-3.png

Here,
 there are 3 switches connected to each other in order to provide 
redundancy. When host A generates a broadcast for host B, it is first 
received by switch A which in turn floods the traffic to all its ports. 
As switch B and Switch, C is also connected to switch A therefore, these
 switches also receive the broadcast frame and flood the frame through 
all its ports.

As a result, switch A and switch C will also 
receive the broadcast frame generated by switch B. Also, switch C will 
also generate a broadcast frame for switch B and switch A. This will 
result in a loop that will consume all the available bandwidth and can 
lead to the shutting down of a network.

**Multiple copies –** A device can receive multiple copies of the same frame if a frame arrives from different network segments at the same time.

**Example:**

!https://media.geeksforgeeks.org/wp-content/uploads/Untitled-Diagram-1-2.png

Here
 is a small topology in which a router is connected with 2 switches. 
Switch A is connected to host A and switch C. On the other hand, switch B
 is connected to switch C and host B. Suppose, if host A wants to send a
 unicast frame to the router then it will forward out the frame to 
switch A. Switch A in turn forward out it to the router and switch C. At
 this time, the router will receive the packet.

But switch C in 
turn forwards the packet to Switch B and Switch B will forward it out to
 the router. At this time, the router will receive multiple copies of a 
single frame. This is a problem as most protocols cannot correctly 
handle duplicate transmissions.

**MAC table thrashing –** Switches
 use the MAC address table to forward out the frames. When a switch 
receives a frame, it makes an entry of the device mac address with the 
switch port on which the frame is received but if the switch receives 
the frame of the same source from more than one link then it will be 
confusing for the switch to make an entry in the MAC table. It will lead
 to instability of the MAC table.

**Example:**

!https://media.geeksforgeeks.org/wp-content/uploads/Untitled-Diagram-4-1.png

In
 the given topology, if host A sends a unicast frame for host B then 
switch A will receive the frame. Switch A will forward it out to both 
switch B and switch D which in turn both forward it out to switch C. 
Now, switch C will receive the frame on two different ports with the 
same source mac address therefore it will lead to instability in the MAC
 table in switch C. Spanning Tree Protocol (STP) is used to prevent 
these loops. It will block down a (port) path using its own mechanism by
 which a single path is available for frame delivery at a time. If one 
path goes down, then the blocked path becomes active and frame 
transmission can take place from that path (in switches).
*** DSL (Digital Subscriber Line)
Digital Subscriber Line (DSL, *originally*, **digital subscriber loop**)
 is a communication medium, which is used to transfer internet through 
copper wire telecommunication line. Along with cable internet, DSL is 
one of the most popular ways *ISPs* provide broadband internet access. 

- Its aim is to maintain the high speed of the data being transferred.
- If we ask that how we gonna achieve such a thing i.e., both telephone and internet facility, then the answer is by using *splitters or DSL filters*(shown in the below diagram). Basically, the *splitter* is used to splits the frequency and make sure that they can’t get interrupted.

!https://media.geeksforgeeks.org/wp-content/uploads/Capture-86.png

**Types of DSL –** 

1. **Symmetric DSL –** SDSL, *splits* the upstream and downstream frequencies evenly, providing equal speeds
to both uploading and downloading data transfer. This connection may
provide *2 Mbps* upstream and downstream.it is mostly preferred by small organizations.
2. **Asymmetric DSL –** ADSL, provides a wider frequency range for downstream transfers, which
offers several times faster downstream speeds. an ADSL connection may
offer *20 Mbps downstream and 1.5 Mbps upstream*, it is because most users download more data than they upload.

**Benefits –** 

- **No Additional Wiring –** A DSL connection makes use of your existing telephone wiring, so you
will not have to pay for expensive upgrades to your phone system.
- **Cost-Effective –** DSL internet is a very cost-effective method and is best in connectivity
- Availability of DSL modems by the service providers.
- Users can use both telephone lines and the internet at the same time. And it
is because the voice and digital signals are transferred in different
frequencies.
- Users can choose between different connection *speeds* and *pricing* from various providers.

DSL
 Internet service only works over a limited physical distance and 
remains unavailable in many areas where the local telephone 
infrastructure does not support DSL technology. The service is not 
available everywhere. The connection is faster for receiving data than 
it is for sending data over the Internet.

# What is Scrambling in Digital Electronics ?

A 
computer network is designed to send information from one point to 
another. Data that we send can either be digital or analog. Also, 
signals that represent data can also be digital or analog. Thus to send 
data by using signals, we must be able to convert the data into signals,
 this conversion can be Analog to Analog, Analog to Digital, Digital to 
Analog, or Digital to Digital. Digital to Digital conversion involves 
three techniques – Line Coding, Block Coding, and Scrambling. [Line Coding](https://www.geeksforgeeks.org/digital-electronics-difference-unipolar-polar-bipolar-line-coding-schemes/) is always needed, whereas [Block Coding](https://www.geeksforgeeks.org/digital-electronics-block-coding/) and Scrambling may or may not be needed depending upon the need. **Scrambling**
 is a technique that does not increase the number of bits and does 
provide synchronization. The problem with techniques like Bipolar 
AMI(Alternate Mark Inversion) is that continuous sequence of zero’s 
create synchronization problems one solution to this is Scrambling.

> Prerequisite: Block Coding, Line Coding
> 

There are two common scrambling techniques:

1. B8ZS(Bipolar with 8-zero substitution)
2. HDB3(High-density bipolar3-zero)

**B8ZS(Bipolar with 8-zero substitution):** This
 technique is similar to Bipolar AMI except when eight consecutive 
zero-level voltages are encountered they are replaced by the sequence, 
“000VB0VB”.

> Note:
> 
> - V(Violation), is a non-zero voltage which means the signal has the same polarity as
> the previous non-zero voltage. Thus it is a violation of the general AMI technique.
> - B(Bipolar), is also a non-zero voltage level that is in accordance with the AMI rule (i.e., opposite polarity from the
> previous non-zero voltage).

```
Example: Data = 100000000
```

!https://media.geeksforgeeks.org/wp-content/uploads/Digital_Electronics_Scrambling_1.jpg

> Note: Both
 figures (left and right one) are correct, depending upon the last 
non-zero voltage signal of the previous data sequence (i.e., sequence 
before current data sequence “100000000”).
> 

**HDB3(High-density bipolar3-zero):** In
 this technique, four consecutive zero-level voltages are replaced with a
 sequence “000V” or “B00V”. Rules for using these sequences:

- If the number of nonzero pulses after the last substitution is odd, the
substitution pattern will be “000V”, this helps in maintaining a total
number of nonzero pulses even.
- If the number of nonzero pulses
after the last substitution is even, the substitution pattern will be
“B00V”. Hence even the number of nonzero pulses is maintained again.

!https://media.geeksforgeeks.org/wp-content/uploads/Digital_Electronics_Scrambling_2.jpg

```
Example: Data = 1100001000000000
```

**Output explanation:**
 After representing the first two 1’s of data we encounter four 
consecutive zeros. Since our last substitutions were two 1’s(thus the 
number of non-zero pulses is even). So, we substitute four zeros with 
“B00V”.

> Note: Zero non-zero pulses are also even.
>
*** Difference between Unipolar, Polar and Bipolar Line Coding Schemes
**Data** as well as **signals** that represents data can either be digital or analog. **Line coding** is the process of converting **digital data to digital signals**.
 By this technique we converts a sequence of bits to a digital signal. 
At the sender side digital data are encoded into a digital signal and at
 the receiver side the digital data are recreated by decoding the 
digital signal.

We can roughly divide line coding schemes into five categories:

1. Unipolar (eg. NRZ scheme).
2. Polar (eg. NRZ-L, NRZ-I, RZ, and Biphase – Manchester and differential Manchester).
3. Bipolar (eg. AMI and Pseudoternary).
4. Multilevel
5. Multitransition

But, before learning difference between first three schemes we should first know the **characteristic** of these line coding techniques:

- There should be **self-synchronizing** i.e., both receiver and sender clock should be synchronized.
- There should have some error-detecting capability.
- There should be immunity to noise and interference.
- There should be less complexity.
- There should be no low frequency component (**DC-component**) as long distance transfer is not feasible for low frequency component signal.
- There should be less base line wandering.

**Unipolar scheme –**In this scheme, all the signal levels are either above or below the axis.

- **Non return to zero (NRZ) –** It is unipolar line coding scheme in which positive voltage defines bit 1 and the zero voltage defines bit 0. Signal does not return to zero at the middle of the bit thus it is called NRZ. For example: Data = 10110.
    
    !https://media.geeksforgeeks.org/wp-content/uploads/Difference_Line_Coding_Schemes_1.jpg
    
    But
     this scheme uses more power as compared to polar scheme to send one bit
     per unit line resistance. Moreover for continuous set of zeros or ones 
    there will be self-synchronization and base line wandering problem.
    

**Polar schemes –**In polar schemes, the voltages are on the both sides of the axis.

- **NRZ-L and NRZ-I –** These are somewhat similar to unipolar NRZ scheme but here we use two levels of amplitude (voltages). For **NRZ-L(NRZ-Level)**, the level of the voltage determines the value of the bit, typically
binary 1 maps to logic-level high, and binary 0 maps to logic-level low, and for **NRZ-I(NRZ-Invert)**, two-level signal has a
transition at a boundary if the next bit that we are going to transmit
is a logical 1, and does not have a transition if the next bit that we
are going to transmit is a logical 0.
    
    **Note –** For 
    NRZ-I we are assuming in the example that previous signal before 
    starting of data set “01001110” was positive. Therefore, there is no 
    transition at the beginning and first bit “0” in current data set 
    “01001110” is starting from +V. Example: Data = 01001110.
    
    !https://media.geeksforgeeks.org/wp-content/uploads/Difference_Line_Coding_Schemes_2.jpg
    
    Comparison
     between NRZ-L and NRZ-I: Baseline wandering is a problem for both of 
    them, but for NRZ-L it is twice as bad as compared to NRZ-I. This is 
    because of transition at the boundary for NRZ-I (if the next bit that we
     are going to transmit is a logical 1). Similarly self-synchronization 
    problem is similar in both for long sequence of 0’s, but for long 
    sequence of 1’s it is more severe in NRZ-L.
    
- **Return to zero (RZ) –** One solution to NRZ problem is the RZ scheme, which uses three values
positive,negative,and zero. In this scheme signal goes to 0 in the
middle of each bit.**Note –** The logic we are using
here to represent data is that for bit 1 half of the signal is
represented by +V and half by zero voltage and for bit 0 half of the
signal is represented by -V and half by zero voltage. Example: Data =
01001.
    
    !https://media.geeksforgeeks.org/wp-content/uploads/Difference_Line_Coding_Schemes_3.jpg
    
    Main
     disadvantage of RZ encoding is that it requires greater bandwidth. 
    Another problem is the complexity as it uses three levels of voltage. As
     a result of all these deficiencies, this scheme is not used today. 
    Instead, it has been replaced by the better-performing Manchester and 
    differential Manchester schemes.
    
- **Biphase (Manchester and Differential Manchester ) –** Manchester encoding is somewhat combination of the RZ (transition at
the middle of the bit) and NRZ-L schemes. The duration of the bit is
divided into two halves. The voltage remains at one level during the
first half and moves to the other level in the second half. The
transition at the middle of the bit provides synchronization.
    
    Differential
     Manchester is somewhat combination of the RZ and NRZ-I schemes. There 
    is always a transition at the middle of the bit but the bit values are 
    determined at the beginning of the bit. If the next bit is 0, there is a
     transition, if the next bit is 1, there is no transition.
    
    **Note –1.** The
     logic we are using here to represent data using Manchester is that for 
    bit 1 there is transition form -V to +V volts in the middle of the bit 
    and for bit 0 there is transition from +V to -V volts in the middle of 
    the bit.**2.** For differential Manchester we are assuming in the
     example that previous signal before starting of data set “010011” was 
    positive. Therefore there is transition at the beginning and first bit 
    “0” in current data set “010011” is starting from -V. Example: Data = 
    010011.
    
    !https://media.geeksforgeeks.org/wp-content/uploads/Difference_Line_Coding_Schemes_4.jpg
    
    The
     Manchester scheme overcomes several problems associated with NRZ-L, and
     differential Manchester overcomes several problems associated with 
    NRZ-I as there is no baseline wandering and no DC component because each
     bit has a positive and negative voltage contribution.
    
    Only limitation is that the minimum bandwidth of Manchester and differential Manchester is twice that of NRZ.
    

**Bipolar schemes –**In
 this scheme there are three voltage levels positive, negative, and 
zero. The voltage level for one data element is at zero, while the 
voltage level for the other element alternates between positive and 
negative.

- **Alternate Mark Inversion (AMI) –** A neutral zero voltage represents binary 0. Binary 1’s are represented by alternating positive and negative voltages.
- **Pseudoternary –** Bit 1 is encoded as a zero voltage and the bit 0 is encoded as
alternating positive and negative voltages i.e., opposite of AMI scheme. Example: Data = 010010.
    
    !https://media.geeksforgeeks.org/wp-content/uploads/Difference_Line_Coding_Schemes_5-1.jpg
    
    The
     bipolar scheme is an alternative to NRZ.This scheme has the same signal
     rate as NRZ,but there is no DC component as one bit is represented by 
    voltage zero and other alternates every time.
    

**Reference –**[Data Communications and Networking](https://www.amazon.in/COMMUNICATIONS-NETWORKING-UPDATE-Behrouz-Forouzan/dp/0070499357?tag=googinhydr18418-21) By Behrouz A.Forouzan (Book)
*** Manchester Encoding in Computer Network
Prerequisite – [Difference between Unipolar, Polar and Bipolar Line Coding Schemes](https://www.geeksforgeeks.org/digital-electronics-difference-unipolar-polar-bipolar-line-coding-schemes/)

Manchester
 encoding is a synchronous clock encoding technique used by the physical
 layer of the Open System Interconnection [OSI] to encode the clock and 
data of a synchronous bit stream.  The idea of RZ and the idea of-L are 
combined in manchester

Hello everyone, welcome to Geeks for geeks.

Different
 encoding techniques are used in data communication to ensure data 
security and transmission speed. Manchester encoding is an example of 
digital encoding. Because each data bit length is defined by default, it
 differs from other digital encoding schemes. The bit state is defined 
by the direction of the transition. Bit status is represented in various
 ways by different systems, although most systems use 1 bit for low to 
high transitions and 0 bit for high to low transitions.

In 
manchester duration of a bit is divided into two halves. The voltage 
remains the same at one level during the first half & moves to the 
other level.The transition at the middle of the bit provides 
synchronization.Differential Manchester,on the other hand,combines the 
idea of RZ and NRZ-I. There is always a transition at the middle of the 
bit, but the bit values are determined at the beginning of the bit. if 
next bit is zero there is transition if next bit is 1 there is none.

**Note:** Manchester encoding’s main advantage is signal synchronization.

!https://media.geeksforgeeks.org/wp-content/uploads/ETHERNET_1.jpg

The binary data to be transmitted over the cable are not sent as NRZ [Non-return-to-zero].

**Non-return-to-zero [NRZ] –** NRZ
 code’s voltage level is constant during a bit interval. When there is a
 long sequence of 0s and 1s, there is a problem at the receiving end. 
The problem is that the synchronization is lost due to a lack of 
transmissions. It is of 2 types:

1. **NRZ-level encoding –** The polarity of signals changes when the incoming signal changes from ‘1’
to ‘0’ or from ‘0’ to ‘1’. It considers the first bit of data as
polarity change.
2. **NRZ-Inverted/ Differential encoding –** In this, the transitions at the beginning of the bit interval are equal to 1 and if there is no transition at the beginning of the bit interval is equal to 0.

**Characteristics of Manchester Encoding –**

- A logic 0 is indicated by a 0 to 1 transition at the center of the bit and logic 1 by 1 to 0 transition.
- The signal transitions do not always occur at the ‘bit boundary’ but there is always a transition at the center of each bit.
- The **Differential Physical Layer Transmission** does not employ an inverting line driver to convert the binary digits
into an electrical signal. And therefore the signal on the wire is not
opposite the output by the encoder.
- The following are the properties of Manchester encoding:
- Each bit is sent at a predetermined rate.
- When a high to low transition happens, a ‘1’ is recorded; when a low to high transition occurs, a ‘0’ is recorded.
- At the mid-point of a period, the transition that is utilized to precisely note 1 or 0 happens.The Manchester Encoding is also called **Biphase code** as each bit is encoded by a positive 90 degrees phase transition or by negative 90 degrees phase transition.
- The **Digital Phase Locked Loop (DPLL)** extracts the clock signal and deallocates the value and timing of each
bit. The transmitted bitstream must contain a high density of bit
transitions.
- The Manchester Encoding consumes twice the bandwidth of the original signal.
- The advantage of the Manchester code is that the DC component of the signal carries no information. This makes it possible that standards that
usually do not carry power can transmit this information.

Only
 drawback is the signal rate.The signal rate is manchester and 
differential is double that for NRZ. The reason is that there is always 
one transition at the middle of the bit and maybe one transition at the 
end of each bit.

```
Eg: For 10Mbps LAN the signal spectrum lies between 5 and 20
```

- Another example to find out the bits by seeing the transitions.

!https://media.geeksforgeeks.org/wp-content/uploads/Capture-154.png

1. [GATE-CS-2007 | Question 85](https://www.geeksforgeeks.org/gate-gate-cs-2007-question-19/)
2. [GATE IT 2007 | Question 59](https://www.geeksforgeeks.org/gate-gate-it-2007-question-59/)
3. [ISRO CS 2007 | Question 22](https://www.geeksforgeeks.org/isro-isro-cs-2007-question-22/)

**Reference :[Book – Computer Networks by Tanenbaum](https://amzn.to/3hfQerb)**
*** Let’s experiment with Networking
Most of us have studied Computer Networks in a very abstract manner. 
In other words, not many of us know how the abstract concepts of layers 
and packets translate in real-life networks such as the Internet. 
Therefore, let us do an experiment and see whether these layers, 
packets, etc. exist in any real network also. So get, set and ready to 
delve into this wonderful world of practical and experimental 
Networking!

The outline
 of our experiment is as follows. We will capture some live packets, and
 to understand what is inside those packets, we will analyze those 
packets by dissecting them. Sounds surgical? Yup, it is. J

To 
start with, we need to have a PC running Windows XP and connected to the
 Internet. If you are reading this article online, the chances are high 
that you have everything ready to experiment. Now let’s recall some of 
the theory stuff that we read in Networking Books. The first thing that 
almost every book tells us is – networking architecture is layered; 
remember that 7-layer OSI protocol stack! So where are these protocol 
layers? In our experiment, we will use 5 layer Internet Protocol stack 
so that we can solve the mystery of these layers.

We start our 
experiment by installing Wireshark (earlier known as Ethereal). 
Wireshark is a Network Protocol Analyzer that can capture and analyze 
the packets transmitted/received via a Network Interface Card (NIC). 
[You need to bear with me this acronym because Networking is full of 
acronyms], We install Wireshark from http://www.wireshark.org/download.html
 (at the time of this writing, the latest Wireshark version is 1.0.3). 
While installing Wireshark, leave the default settings/options as it is.
 Now our experimental setup is ready. Run Wireshark and click on the 
first icon (List the available capture interfaces …). Now we see a 
pop-up window that shows Capture Interfaces. See the snapshots as 
follows.

!https://media.geeksforgeeks.org/wp-content/cdn-uploads/2009/08/Drawing1.jpg

The
 number and types of interfaces shown in the Capture Interfaces window 
can be different for you depending on your PC’s configuration. For me, 
it shows two interfaces and my Internet connection is through Broadcom 
Gigabit Interface. So choose the interface through which your Internet 
connection is available to you. Now let’s click on the Options 
button of this interface. Now we see a new window named Capture Options.
 In this window, type “port 80” in the text field named Capture Filter. 
See the following snapshot for clarification.

!https://media.geeksforgeeks.org/wp-content/cdn-uploads/2009/08/Drawing2.jpg

Now
 we are ready to capture the packets passing through our NIC. By setting
 the filter to “port 80”, we have instructed Wireshark to capture only 
those packets that are because of HTTP traffic (remember that we were 
always told that the default HTTP port is 80!). Now click on the Start 
button on the Capture Options window. You may see some packets in 
Wireshark if any program in your PC is accessing HTTP traffic in the 
background; let’s not focus on that. Now open your browser and try to 
access [http://google.com](http://google.com/) and now you should be seeing a lot many packets getting captured in Wireshark. See the snapshot as follows.

!https://media.geeksforgeeks.org/wp-content/cdn-uploads/2009/08/Drawing3.jpg

Let’s
 start analyzing the captured packets. First of all, find the first 
instance of the HTTP packet that has   GET / HTTP/1.1 in its Info field.
 In the above snapshot, it’s shown in blue. If we take a closer look, we
 see that this packet has the headers of all 5 layers of the Internet 
Protocol stack.

- **Layer 1 –** It is the Physical layer. Here Frames are shown at the physical layer.
- **Layer 2 –** It is the Data Link layer. In this packet, we can see that Ethernet II is
used as a data link layer protocol. We can find the MAC address of the
source and destination in this header.
- **Layer 3 –** It is the Network layer. In this packet, we see that IP is used as a
network layer protocol. We can see the source and destination IP in this header.
- **Layer 4 –** It is the
Transport layer. In this packet, TCP is used as a Transport layer
protocol. We can find the source and destination ports in this header.
- **Layer 5 –** It is the Application layer. In this packet, HTTP is used as an Application layer protocol.

Let’s
 explore one of the layers. Other layers can be explored further 
similarly. If we expand Layer 5 i.e. HTTP header, it looks as follows.

!https://media.geeksforgeeks.org/wp-content/cdn-uploads/2009/08/Drawing4.jpg

Here
 we see that the Host is mentioned as google.com which is what we tried 
to access from a browser. The user-Agent field of the HTTP header shows 
the browser details. In my case, it is Mozilla Firefox as evidenced by 
this header. Destination IP 64.233.187.99 should be one of the IP 
addresses assigned to the Google server where the webserver is hosted. 
It can be verified using a very handy utility command “nslookup”. The 
details of the other fields can be explored in the headers of the HTTP, 
TCP, IP, and Ethernet II protocols. Some interesting fields are – 
Differentiated Services Field (also known as QoS field) in the IP 
header, Window size in the TCP header, etc.

So we have seen that 
all those rhetorical concepts of layers etc. do exist in real networks 
also. And it sounds interesting when you dissect all the packets that 
pass through your interface card. By doing so, you can get to know what 
goes/comes through your PC!

The idea of this experiment is to 
provide a conducive platform so that you can explore your own exciting 
world of Networking.  So welcome aboard!
*** Layers of OSI Model
OSI stands for **Open Systems Interconnection**. It has been developed by ISO – ‘**International Organization for Standardization**‘,
 in the year 1984. It is a 7 layer architecture with each layer having 
specific functionality to perform. All these 7 layers work 
collaboratively to transmit the data from one person to another across 
the globe.

> Prerequisite: Basics of Computer Networking
> 

!https://media.geeksforgeeks.org/wp-content/uploads/computer-network-osi-model-layers.png

### **1. Physical Layer (Layer 1) :**

The
 lowest layer of the OSI reference model is the physical layer. It is 
responsible for the actual physical connection between the devices. The 
physical layer contains information in the form of **bits.**
 It is responsible for transmitting individual bits from one node to the
 next. When receiving data, this layer will get the signal received and 
convert it into 0s and 1s and send them to the Data Link layer, which 
will put the frame back together.

!https://media.geeksforgeeks.org/wp-content/uploads/computer-network-osi-model-layers-bits.png

The functions of the physical layer are as follows:

1. **Bit synchronization:** The physical layer provides the synchronization of the bits by
providing a clock. This clock controls both sender and receiver thus
providing synchronization at bit level.
2. **Bit rate control:** The Physical layer also defines the transmission rate i.e. the number of bits sent per second.
3. **Physical topologies:** Physical layer specifies the way in which the different, devices/nodes
are arranged in a network i.e. bus, star, or mesh topology.
4. **Transmission mode:** Physical layer also defines the way in which the data flows between the two connected devices. The various transmission modes possible are
Simplex, half-duplex and full-duplex.

```
Hub, Repeater, Modem, Cables are Physical Layer devices.
*** Network Layer, Data Link Layer, and Physical Layer
are also known asLower Layers orHardware Layers.
```

### **2. Data Link Layer (DLL) (Layer 2) :**

The
 data link layer is responsible for the node-to-node delivery of the 
message. The main function of this layer is to make sure data transfer 
is error-free from one node to another, over the physical layer. When a 
packet arrives in a network, it is the responsibility of DLL to transmit
 it to the Host using its MAC address. Data Link Layer is divided into two sublayers:

1. Logical Link Control (LLC)
2. Media Access Control (MAC)

The
 packet received from the Network layer is further divided into frames 
depending on the frame size of NIC(Network Interface Card). DLL also 
encapsulates Sender and Receiver’s MAC address in the header.

The
 Receiver’s MAC address is obtained by placing an ARP(Address Resolution
 Protocol) request onto the wire asking “Who has that IP address?” and 
the destination host will reply with its MAC address.

!https://media.geeksforgeeks.org/wp-content/uploads/computer-network-osi-model-layers-framing.png

The functions of the Data Link layer are :

1. **Framing:** Framing is a function of the data link layer. It provides a way for a sender to transmit a set of bits that are meaningful to the receiver. This can be accomplished by attaching special bit patterns to the beginning and end of the frame.
2. **Physical addressing:** After
creating frames, the Data link layer adds physical addresses (MAC
address) of the sender and/or receiver in the header of each frame.
3. **Error control:** Data link layer provides the mechanism of error control in which it detects and retransmits damaged or lost frames.
4. **Flow Control:** The data rate must be constant on both sides else the data may get
corrupted thus, flow control coordinates the amount of data that can be
sent before receiving acknowledgement.
5. **Access control:** When a single communication channel is shared by multiple devices, the MAC
sub-layer of the data link layer helps to determine which device has
control over the channel at a given time.

```
 Packet in Data Link layer is referred to asFrame.
 Data Link layer is handled by the NIC (Network Interface Card) and device drivers of host machines.
 Switch & Bridge are Data Link Layer devices.
```

### **3. Network Layer (Layer 3) :**

The
 network layer works for the transmission of data from one host to the 
other located in different networks. It also takes care of packet 
routing i.e. selection of the shortest path to transmit the packet, from
 the number of routes available. The sender & receiver’s IP 
addresses are placed in the header by the network layer.

The functions of the Network layer are :

1. **Routing:** The network layer protocols determine which route is suitable from
source to destination. This function of the network layer is known as
routing.
2. **Logical Addressing:** In order to
identify each device on internetwork uniquely, the network layer defines an addressing scheme. The sender & receiver’s IP addresses are
placed in the header by the network layer. Such an address distinguishes each device uniquely and universally.

```
 Segmentin Network layer is referred to asPacket.
```

!https://media.geeksforgeeks.org/wp-content/uploads/computer-network-osi-model-layers-packet.png

```
*** Network layer is implemented by networking devices such as routers.
```

### **4. Transport Layer (Layer 4) :**

The
 transport layer provides services to the application layer and takes 
services from the network layer. The data in the transport layer is 
referred to as *Segments*. It is responsible for the End to End 
Delivery of the complete message. The transport layer also provides the 
acknowledgement of the successful data transmission and re-transmits the
 data if an error is found.

**At sender’s side:** Transport layer receives the formatted data from the upper layers, performs **Segmentation**, and also implements **Flow & Error control**
 to ensure proper data transmission. It also adds Source and Destination
 port numbers in its header and forwards the segmented data to the 
Network Layer.

> Note: The sender needs to know the port number associated with the receiver’s application.
> 

Generally,
 this destination port number is configured, either by default or 
manually. For example, when a web application makes a request to a web 
server, it typically uses port number 80, because this is the default 
port assigned to web applications. Many applications have default ports 
assigned.

**At receiver’s side:** Transport Layer 
reads the port number from its header and forwards the Data which it has
 received to the respective application. It also performs sequencing and
 reassembling of the segmented data.

The functions of the transport layer are as follows:

1. **Segmentation and Reassembly:** This layer accepts the message from the (session) layer, and breaks the message into smaller units. Each of the segments produced has a header
associated with it. The transport layer at the destination station
reassembles the message.
2. **Service Point Addressing:** In order to deliver the message to the correct process, the transport
layer header includes a type of address called service point address or
port address. Thus by specifying this address, the transport layer makes sure that the message is delivered to the correct process.

The services provided by the transport layer :

**A. Connection-Oriented Service:** It is a three-phase process that includes

– Connection Establishment – Data Transfer – Termination / disconnection

In
 this type of transmission, the receiving device sends an 
acknowledgement, back to the source after a packet or group of packets 
is received. This type of transmission is reliable and secure.

**B. Connectionless service:**
 It is a one-phase process and includes Data Transfer. In this type of 
transmission, the receiver does not acknowledge receipt of a packet. 
This approach allows for much faster communication between devices. 
Connection-oriented service is more reliable than connectionless 
Service.

- *Data in the Transport Layer is called as **Segments**. * Transport layer is operated by the Operating System. It is a part of
the OS and communicates with the Application Layer by making system
calls. Transport Layer is called as **Heart of OSI** model.*

### **5. Session Layer (Layer 5) :**

This
 layer is responsible for the establishment of connection, maintenance 
of sessions, authentication, and also ensures security. The functions of the session layer are :

1. **Session establishment, maintenance, and termination:** The layer allows the two processes to establish, use and terminate a connection.
2. **Synchronization:** This layer allows a process to add checkpoints which are considered
synchronization points into the data. These synchronization points help
to identify the error so that the data is re-synchronized properly, and
ends of the messages are not cut prematurely and data loss is avoided.
3. **Dialog Controller:** The session layer allows two systems to start communication with each other in half-duplex or full-duplex.
- **All the below 3 layers(including Session Layer) are integrated as a single layer in the TCP/IP model as “Application Layer”. *Implementation of these 3 layers is done by the network application itself. These are also known as **Upper Layers** or **Software Layers**.*

### Scenario:

Let
 us consider a scenario where a user wants to send a message through 
some Messenger application running in his browser. The “Messenger” here 
acts as the application layer which provides the user with an interface 
to create the data. This message or so-called Data is compressed, 
encrypted (if any secure data), and converted into bits (0’s and 1’s) so
 that it can be transmitted.

!https://media.geeksforgeeks.org/wp-content/uploads/computer-network-osi-model-layers-session.png

### **6. Presentation Layer (Layer 6):**

The presentation layer is also called the **Translation layer**.
 The data from the application layer is extracted here and manipulated 
as per the required format to transmit over the network. The functions of the presentation layer are :

- **Translation:** For example, ASCII to EBCDIC.
- **Encryption/ Decryption:** Data encryption translates the data into another form or code. The
encrypted data is known as the ciphertext and the decrypted data is
known as plain text. A key value is used for encrypting as well as
decrypting data.
- **Compression:** Reduces the number of bits that need to be transmitted on the network.

### **7. Application Layer (Layer 7) :**

At
 the very top of the OSI Reference Model stack of layers, we find the 
Application layer which is implemented by the network applications. 
These applications produce the data, which has to be transferred over 
the network. This layer also serves as a window for the application 
services to access the network and for displaying the received 
information to the user.

Example: Application – Browsers, Skype Messenger, etc.

```
**Application Layer is also called Desktop Layer.
```

!https://media.geeksforgeeks.org/wp-content/uploads/computer-network-osi-model-layers-application.png

The functions of the Application layer are :

1. Network Virtual Terminal
2. FTAM-File transfer access and management
3. Mail Services
4. Directory Services

**OSI model**
 acts as a reference model and is not implemented on the Internet 
because of its late invention. The current model being used is the 
TCP/IP model.

**OSI model in a nutshell**

!https://media.geeksforgeeks.org/wp-content/uploads/20220511230638/OSImodelakhilabhilash01.png

OSI model summarized (table form)
*** TCP,IP Model
Prerequisite – [Layers of OSI Model](https://www.geeksforgeeks.org/layers-osi-model)

The **OSI Model**
 we just looked at is just a reference/logical model. It was designed to
 describe the functions of the communication system by dividing the 
communication procedure into smaller and simpler components. But when we
 talk about the TCP/IP model, it was designed and developed by 
Department of Defense (DoD) in 1960s and is based on standard protocols.
 It stands for Transmission Control Protocol/Internet Protocol. The **TCP/IP model** is a concise version of the OSI model. It contains four layers, unlike seven layers in the OSI model. The layers are:

1. Process/Application Layer
2. Host-to-Host/Transport Layer
3. Internet Layer
4. Network Access/Link Layer

The diagrammatic comparison of the TCP/IP and OSI model is as follows :

!https://media.geeksforgeeks.org/wp-content/uploads/tcpAndOSI.png

Difference between TCP/IP and OSI Model:

[Untitled Database](https://www.notion.so/c2cd74a70a394eeb841f955d9bb59049?pvs=21)

The
 first layer is the Process layer on the behalf of the sender and 
Network Access layer on the behalf of the receiver. During this article,
 we will be talking on the behalf of the receiver.

### 1. Network Access Layer –

This
 layer corresponds to the combination of Data Link Layer and Physical 
Layer of the OSI model. It looks out for hardware addressing and the 
protocols present in this layer allows for the physical transmission of 
data.We just talked about ARP being a protocol of Internet layer, 
but there is a conflict about declaring it as a protocol of Internet 
Layer or Network access layer. It is described as residing in layer 3, 
being encapsulated by layer 2 protocols.

### 2. Internet Layer –

This
 layer parallels the functions of OSI’s Network layer. It defines the 
protocols which are responsible for logical transmission of data over 
the entire network. The main protocols residing at this layer are :

1. **IP –** stands for Internet Protocol and it is responsible for delivering
packets from the source host to the destination host by looking at the
IP addresses in the packet headers. IP has 2 versions:IPv4 and IPv6. IPv4 is the one that most of the websites are using currently. But IPv6 is growing as the number of IPv4 addresses are limited in number when
compared to the number of users.
2. **ICMP –** stands
for Internet Control Message Protocol. It is encapsulated within IP
datagrams and is responsible for providing hosts with information about
network problems.
3. **ARP –** stands for Address
Resolution Protocol. Its job is to find the hardware address of a host
from a known IP address. ARP has several types: Reverse ARP, Proxy ARP,
Gratuitous ARP and Inverse ARP.

### 3. Host-to-Host Layer –

This
 layer is analogous to the transport layer of the OSI model. It is 
responsible for end-to-end communication and error-free delivery of 
data. It shields the upper-layer applications from the complexities of 
data. The two main protocols present in this layer are :

1. **Transmission Control Protocol (TCP) –** It is known to provide reliable and error-free communication between
end systems. It performs sequencing and segmentation of data. It also
has acknowledgment feature and controls the flow of the data through
flow control mechanism. It is a very effective protocol but has a lot of overhead due to such features. Increased overhead leads to increased
cost.
2. **User Datagram Protocol (UDP) –** On the
other hand does not provide any such features. It is the go-to protocol
if your application does not require reliable transport as it is very
cost-effective. Unlike TCP, which is connection-oriented protocol, UDP
is connectionless.
    
    ### 4. Application Layer –
    
    This layer 
    performs the functions of top three layers of the OSI model: 
    Application, Presentation and Session Layer. It is responsible for 
    node-to-node communication and controls user-interface specifications. 
    Some of the protocols present in this layer are: HTTP, HTTPS, FTP, TFTP,
     Telnet, SSH, SMTP, SNMP, NTP, DNS, DHCP, NFS, X Window, LPD. Have a 
    look at [Protocols in Application Layer](https://www.geeksforgeeks.org/protocols-application-layer/) for some information about these protocols. Protocols other than those present in the linked article are :
    
    1. **HTTP and HTTPS –** HTTP stands for Hypertext transfer protocol. It is used by the World
    Wide Web to manage communications between web browsers and servers.
    HTTPS stands for HTTP-Secure. It is a combination of HTTP with
    SSL(Secure Socket Layer). It is efficient in cases where the browser
    need to fill out forms, sign in, authenticate and carry out bank
    transactions.
    2. **SSH –** SSH stands for Secure
    Shell. It is a terminal emulations software similar to Telnet. The
    reason SSH is more preferred is because of its ability to maintain the
    encrypted connection. It sets up a secure session over a TCP/IP
    connection.
    3. **NTP –** NTP stands for Network Time
    Protocol. It is used to synchronize the clocks on our computer to one
    standard time source. It is very useful in situations like bank
    transactions. Assume the following situation without the presence of
    NTP. Suppose you carry out a transaction, where your computer reads the
    time at 2:30 PM while the server records it at 2:28 PM. The server can
    crash very badly if it’s out of sync.
** PHYSICAL LAYER
*** Network Devices (Hub, Repeater, Bridge, Switch, Router, Gateways and Brouter)
**1. Repeater** – A repeater operates at the physical 
layer. Its job is to regenerate the signal over the same network before 
the signal becomes too weak or corrupted so as to extend the length to 
which the signal can be transmitted over the same network. An important 
point to be noted about repeaters is that they do not amplify the 
signal. When the signal becomes weak, they copy the signal bit by bit 
and regenerate it at the original strength. It is a 2 port device.

**2. Hub**
 –  A hub is basically a multiport repeater. A hub connects multiple 
wires coming from different branches, for example, the connector in star
 topology which connects different stations. Hubs cannot filter data, so
 data packets are sent to all connected devices.  In other words, the [collision domain](https://en.wikipedia.org/wiki/Collision_domain)
 of all hosts connected through Hub remains one.  Also, they do not have
 the intelligence to find out the best path for data packets which leads
 to inefficiencies and wastage.

**Types of Hub**

- **Active Hub:-** These are the hubs that have their own power supply and can clean, boost, and relay the signal along with the network. It serves both as a repeater
as well as a wiring center. These are used to extend the maximum
distance between nodes.
- **Passive Hub :-** These
are the hubs that collect wiring from nodes and power supply from the
active hub. These hubs relay signals onto the network without cleaning
and boosting them and can’t be used to extend the distance between
nodes.
- **Intelligent Hub :-** It works like active
hubs and includes remote management capabilities. They also provide
flexible data rates to network devices. It also enables an administrator to monitor the traffic passing through the hub and to configure each
port in the hub.

**3. Bridge**
 – A bridge operates at the data link layer. A bridge is a repeater, 
with add on the functionality of filtering content by reading the MAC 
addresses of source and destination. It is also used for interconnecting
 two LANs working on the same protocol. It has a single input and single
 output port, thus making it a 2 port device.

**Types of Bridges**

- **Transparent Bridges:-** These are the bridge in which the stations are completely unaware of
the bridge’s existence i.e. whether or not a bridge is added or deleted
from the network, reconfiguration of the stations is unnecessary. These
bridges make use of two processes i.e. bridge forwarding and bridge
learning.
- **Source Routing Bridges:-** In these
bridges, routing operation is performed by the source station and the
frame specifies which route to follow. The host can discover the frame
by sending a special frame called the discovery frame, which spreads
through the entire network using all possible paths to the destination.

**4. Switch**
 – A switch is a multiport bridge with a buffer and a design that can 
boost its efficiency(a large number of ports imply less traffic) and 
performance. A switch is a data link layer device. The switch can 
perform error checking before forwarding data, which makes it very 
efficient as it does not forward packets that have errors and forward 
good packets selectively to the correct port only.  In other words, the 
switch divides the collision domain of hosts, but [broadcast domain](https://en.wikipedia.org/wiki/Broadcast_domain) remains the same.   **5. [Routers](https://www.geeksforgeeks.org/network-devices-hub-repeater-bridge-switch-router-gateways/#Routers)**
 – A router is a device like a switch that routes data packets based on 
their IP addresses. The router is mainly a Network Layer device. Routers
 normally connect LANs and WANs together and have a dynamically updating
 routing table based on which they make decisions on routing the data 
packets. Router divide broadcast domains of hosts connected through it.

!https://media.geeksforgeeks.org/wp-content/cdn-uploads/Network_devices.jpg

**6. Gateway**
 – A gateway, as the name suggests, is a passage to connect two networks
 together that may work upon different networking models. They basically
 work as the messenger agents that take data from one system, interpret 
it, and transfer it to another system. Gateways are also called protocol
 converters and can operate at any network layer. Gateways are generally
 more complex than switches or routers. Gateway is also called a 
protocol converter.

**7. Brouter** – It is also 
known as the bridging router is a device that combines features of both 
bridge and router. It can work either at the data link layer or a 
network layer. Working as a router, it is capable of routing packets 
across networks, and working as the bridge, it is capable of filtering 
local area network traffic.

**8. NIC** – NIC or 
network interface card is a network adapter that is used to connect the 
computer to the network. It is installed in the computer to establish a 
LAN.  It has a unique id that is written on the chip, and it has a 
connector to connect the cable to it. The cable acts as an interface 
between the computer and router or modem. NIC card is a layer 2 device 
which means that it works on both physical and data link layer of the 
network model.   **References** :**[Data Communications and Networking](https://amzn.to/3vDy7ka)**
*** Types of Transmission Media
In data communication terminology, a transmission medium is a 
physical path between the transmitter and the receiver i.e. it is the 
channel through which data is sent from one place to another. 
Transmission Media is broadly classified into the following types:

!https://media.geeksforgeeks.org/wp-content/uploads/20201030064943/TypesOfTransmissionMedia.jpg

**1. Guided Media:** It
 is also referred to as Wired or Bounded transmission media. Signals 
being transmitted are directed and confined in a narrow pathway by using
 physical links. Features:

- High Speed
- Secure
- Used for comparatively shorter distances

There are 3 major types of Guided Media:

**(i) Twisted Pair Cable –** It
 consists of 2 separately insulated conductor wires wound about each 
other. Generally, several such pairs are bundled together in a 
protective sheath. They are the most widely used Transmission Media. 
Twisted Pair is of two types:

- **Unshielded Twisted Pair (UTP):** UTP consists of two insulated copper wires twisted around one another. This type of cable has the ability to block interference and does not depend on a physical shield for this purpose. It is used for telephonic
applications.

!https://media.geeksforgeeks.org/wp-content/uploads/20210716183350/UntitledDiagram321-200x140.png

**Advantages:**

⇢ Least expensive

⇢ Easy to install

⇢ High-speed capacity

⇢ Susceptible to external interference

⇢ Lower capacity and performance in comparison to STP

⇢ Short distance transmission due to attenuation

- **Shielded Twisted Pair (STP):** This type of cable consists of a special jacket (a copper braid covering or a foil shield) to block external interference. It is used in
fast-data-rate Ethernet and in voice and data channels of telephone
lines.

!https://media.geeksforgeeks.org/wp-content/uploads/20210716184259/UntitledDiagram331-300x138.png

**Advantages:**

⇢ Better performance at a higher data rate in comparison to UTP

⇢ Eliminates crosstalk

⇢ Comparatively faster

⇢ Comparatively difficult to install and manufacture

⇢ More expensive

⇢ Bulky

**(ii) Coaxial Cable –** It
 has an outer plastic covering containing an insulation layer made of 
PVC or Teflon and 2 parallel conductors each having a separate insulated
 protection cover. The coaxial cable transmits information in two modes:
 Baseband mode(dedicated cable bandwidth) and Broadband mode(cable 
bandwidth is split into separate ranges). Cable TVs and analog 
television networks widely use Coaxial cables.

!https://media.geeksforgeeks.org/wp-content/uploads/20211109184950/UntitledDiagram72-300x156.png

Advantages:

- High Bandwidth
- Better noise Immunity
- Easy to install and expand
- Inexpensive

Disadvantages:

- Single cable failure can disrupt the entire network

**(iii) Optical Fiber Cable –** It
 uses the concept of reflection of light through a core made up of glass
 or plastic. The core is surrounded by a less dense glass or plastic 
covering called the cladding. It is used for the transmission of large 
volumes of data.

The cable can be unidirectional or 
bidirectional. The WDM (Wavelength Division Multiplexer) supports two 
modes, namely unidirectional and bidirectional mode.

!https://media.geeksforgeeks.org/wp-content/uploads/20210716190121/UntitledDiagram62-300x196.png

Advantages:

- Increased capacity and bandwidth
- Lightweight
- Less signal attenuation
- Immunity to electromagnetic interference
- Resistance to corrosive materials

Disadvantages:

- Difficult to install and maintain
- High cost
- Fragile

**(iv) Stripline**

Stripline
 is a transverse electromagnetic (TEM) transmission line medium invented
 by Robert M. Barrett of the Air Force Cambridge Research Centre in the 
1950s. Stripline is the earliest form of the planar transmission line. 
It uses a conducting material to transmit high-frequency waves it is 
also called a waveguide. This conducting material is sandwiched between 
two layers of the ground plane which are usually shorted to provide EMI 
immunity.

**(v) Microstripline**

In this, the conducting material is separated from the ground plane by a layer of dielectric.

**2. Unguided Media:** It
 is also referred to as Wireless or Unbounded transmission media. No 
physical medium is required for the transmission of electromagnetic 
signals.

Features:

- The signal is broadcasted through air
- Less Secure
- Used for larger distances

There are 3 types of Signals transmitted through unguided media:

**(i) Radio waves –** These
 are easy to generate and can penetrate through buildings. The sending 
and receiving antennas need not be aligned. Frequency Range:3KHz – 1GHz.
 AM and FM radios and cordless phones use Radio waves for transmission.

!https://media.geeksforgeeks.org/wp-content/uploads/20210716190536/radiowave3-300x164.png

Further Categorized as (i) Terrestrial and (ii) Satellite.

**(ii) Microwaves –** It
 is a line of sight transmission i.e. the sending and receiving antennas
 need to be properly aligned with each other. The distance covered by 
the signal is directly proportional to the height of the antenna. 
Frequency Range:1GHz – 300GHz. These are majorly used for mobile phone 
communication and television distribution.

!https://media.geeksforgeeks.org/wp-content/cdn-uploads/20220228132246/microwave.png

**(iii) Infrared –** Infrared
 waves are used for very short distance communication. They cannot 
penetrate through obstacles. This prevents interference between systems.
 Frequency Range:300GHz – 400THz. It is used in TV remotes, wireless 
mouse, keyboard, printer, etc.

!https://media.geeksforgeeks.org/wp-content/uploads/20210716190816/infrared1-227x300.png
*** Transmission Modes in Computer Networks (Simplex, Half-Duplex and Full-Duplex)
Transmission mode means transferring data between two devices. It is 
also known as a communication mode. Buses and networks are designed to 
allow communication to occur between individual devices that are 
interconnected. There are three types of transmission mode:-  

!https://media.geeksforgeeks.org/wp-content/uploads/transmissionmodes.png

These are explained as following below.

**1. Simplex Mode** **–**In
 Simplex mode, the communication is unidirectional, as on a one-way 
street. Only one of the two devices on a link can transmit, the other 
can only receive. The simplex mode can use the entire capacity of the 
channel to send data in one direction. Example: Keyboard and traditional monitors. The keyboard can only introduce input, the monitor can only give the output.

!https://media.geeksforgeeks.org/wp-content/uploads/SiMpleduplex.png

**2. Half-Duplex Mode** **–**In
 half-duplex mode, each station can both transmit and receive, but not 
at the same time. When one device is sending, the other can only 
receive, and vice versa. The half-duplex mode is used in cases where 
there is no need for communication in both directions at the same time. 
The entire capacity of the channel can be utilized for each direction. Example: Walkie-talkie in which message is sent one at a time and messages are sent in both directions.

```
Channel capacity=Bandwidth * Propagation Delay
```

!https://media.geeksforgeeks.org/wp-content/uploads/halfduplex.png

**3. Full-Duplex Mode** **–**In
 full-duplex mode, both stations can transmit and receive 
simultaneously. In full_duplex mode, signals going in one direction 
share the capacity of the link with signals going in another direction, 
this sharing can occur in two ways:

- Either the link must contain two physically separate transmission paths, one for sending and the other for receiving.
- Or the capacity is divided between signals traveling in both directions.

Full-duplex
 mode is used when communication in both directions is required all the 
time. The capacity of the channel, however, must be divided between the 
two directions. Example: Telephone Network in which there is 
communication between two persons by a telephone line, through which 
both can talk and listen at the same time.

```
Channel Capacity=2* Bandwidth*propagation Delay
```

!https://media.geeksforgeeks.org/wp-content/uploads/fullduplex.png

**References-** Data Communication and Network,5th Edition, Behrouz A.Forouzan.

*** ANALOG TO DIGITAL CONVERSION
**Digital Signal:** A digital signal is a signal that 
represents data as a sequence of discrete values; at any given time it 
can only take on one of a finite number of values.

**Analog Signal:**
 An analog signal is any continuous signal for which the time varying 
feature of the signal is a representation of some other time varying 
quantity i.e., analogous to another time varying signal.

The following techniques can be used for Analog to Digital Conversion:

### a. PULSE CODE MODULATION:

The
 most common technique to change an analog signal to digital data is 
called pulse code modulation (PCM). A PCM encoder has the following 
three processes:

1. Sampling
2. Quantization
3. Encoding

**Low pass filter :**The
 low pass filter eliminates the high frequency components present in the
 input analog signal to ensure that the input signal to sampler is free 
from the unwanted frequency components.This is done to avoid aliasing of
 the message signal.

1. **Sampling –** The first step in PCM is sampling. Sampling is a process of measuring the
amplitude of a continuous-time signal at discrete instants, converting
the continuous signal into a discrete signal. There are three sampling
methods:
    
    **(i) Ideal Sampling:** In ideal Sampling also known as 
    Instantaneous sampling pulses from the analog signal are sampled. This 
    is an ideal sampling method and cannot be easily implemented.
    
    **(ii) Natural Sampling:**
     Natural Sampling is a practical method of sampling in which pulse have 
    finite width equal to T.The result is a sequence of samples that retain 
    the shape of the analog signal.
    
    !https://media.geeksforgeeks.org/wp-content/uploads/n5.jpg
    
    **(iii) Flat top sampling:**
     In comparison to natural sampling flat top sampling can be easily 
    obtained. In this sampling technique, the top of the samples remains 
    constant by using a circuit. This is the most common sampling method 
    used.
    
    !https://media.geeksforgeeks.org/wp-content/uploads/n3.jpg
    
    **Nyquist Theorem:**One
     important consideration is the sampling rate or frequency. According to
     the Nyquist theorem, the sampling rate must be at least 2 times the 
    highest frequency contained in the signal. It is also known as the 
    minimum sampling rate and given by:Fs =2*fh
    
2. **Quantization –**The result of sampling is a series of pulses with amplitude values between
the maximum and minimum amplitudes of the signal. The set of amplitudes
can be infinite with non-integral values between two limits.
    
    The following are the steps in Quantization:
    
    1. We assume that the signal has amplitudes between Vmax and Vmin
    2. We divide it into L zones each of height d where,d= (Vmax- Vmin)/ L
        
        !https://media.geeksforgeeks.org/wp-content/uploads/DigitalElect1.png
        
    3. The value at the top of each sample in the graph shows the actual amplitude.
    4. The normalized pulse amplitude modulation(PAM) value is calculated using the formula amplitude/d.
    5. After this we calculate the quantized value which the process selects from the middle of each zone.
    6. The Quantized error is given by the difference between quantised value and normalised PAM value.
    7. The Quantization code for each sample based on quantization levels at the left of the graph.
3. **Encoding –**The digitization of the analog signal is done by the encoder. After each
sample is quantized and the number of bits per sample is decided, each
sample can be changed to an n bit code. Encoding also minimizes the
bandwidth used.

### b. DELTA MODULATION :

Since PCM is a
 very complex technique, other techniques have been developed to reduce 
the complexity of PCM. The simplest is delta Modulation. Delta 
Modulation finds the change from the previous value.

**Modulator –**
 The modulator is used at the sender site to create a stream of bits 
from an analog signal. The process records a small positive change 
called delta. If the delta is positive, the process records a 1 else the
 process records a 0. The modulator builds a second signal that 
resembles a staircase. The input signal is then compared with this 
gradually made staircase signal.

!https://media.geeksforgeeks.org/wp-content/uploads/DigitalElect.png

We have the following rules for output:

1. If the input analog signal is higher than the last value of the staircase
signal, increase delta by 1, and the bit in the digital data is 1.
2. If the input analog signal is lower than the last value of the staircase
signal, decrease delta by 1, and the bit in the digital data is 0.

!https://media.geeksforgeeks.org/wp-content/uploads/n2.jpg

### c. ADAPTIVE DELTA MODULATION:

The
 performance of a delta modulator can be improved significantly by 
making the step size of the modulator assume a time-varying form. A 
larger step-size is needed where the message has a steep slope of 
modulating signal and a smaller step-size is needed where the message 
has a small slope. The size is adapted according to the level of the 
input signal. This method is known as adaptive delta modulation (ADM).

!https://media.geeksforgeeks.org/wp-content/uploads/n1.jpg
*** DIGITAL TO ANALOG CONVERSION
**Digital Signal –** A digital signal is a signal that 
represents data as a sequence of discrete values; at any given time it 
can only take on one of a finite number of values.

**Analog Signal –** An
 analog signal is any continuous signal for which the time varying 
feature of the signal is a representation of some other time varying 
quantity i.e., analogous to another time varying signal.

The following techniques can be used for Digital to Analog Conversion:

**1. Amplitude Shift keying –**
 Amplitude Shift Keying is a technique in which carrier signal is analog
 and data to be modulated is digital. The amplitude of analog carrier 
signal is modified to reflect binary data.

The binary signal when 
modulated gives a zero value when the binary data represents 0 while 
gives the carrier output when data is 1. The frequency and phase of the 
carrier signal remain constant.

!https://media.geeksforgeeks.org/wp-content/cdn-uploads/wave_ask2-300x290.jpg

**Advantages of amplitude shift Keying –**

- It can be used to transmit digital data over optical fiber.
- The receiver and transmitter have a simple design which also makes it comparatively inexpensive.
- It uses lesser bandwidth as compared to FSK thus it offers high bandwidth efficiency.

**Disadvantages of amplitude shift Keying –**

- It is susceptible to noise interference and entire transmissions could be lost due to this.
- It has lower power efficiency.

**2. Frequency Shift keying –** In this modulation the frequency of analog carrier signal is modified to reflect binary data.

The
 output of a frequency shift keying modulated wave is high in frequency 
for a binary high input and is low in frequency for a binary low input. 
The amplitude and phase of the carrier signal remain constant.

!https://media.geeksforgeeks.org/wp-content/cdn-uploads/wave_fsk2-300x298.jpg

**Advantages of frequency shift Keying –**

- Frequency shift keying modulated signal can help avoid the noise problems beset by ASK.
- It has lower chances of an error.
- It provides high signal to noise ratio.
- The transmitter and receiver implementations are simple for low data rate application.

**Disadvantages of frequency shift Keying –**

- It uses larger bandwidth as compared to ASK thus it offers less bandwidth efficiency.
- It has lower power efficiency.

**3. Phase Shift keying –** In
 this modulation the phase of the analog carrier signal is modified to 
reflect binary data.The amplitude and frequency of the carrier signal 
remains constant.

!https://media.geeksforgeeks.org/wp-content/cdn-uploads/wave_psk2-300x298.jpg

It is further categorized as follows:

1. **Binary Phase Shift Keying (BPSK):**BPSK also known as phase reversal keying or 2PSK is the simplest form of
phase shift keying. The Phase of the carrier wave is changed according
to the two binary inputs. In Binary Phase shift keying, difference of
180 phase shift is used between binary 1 and binary 0.
    
    This is regarded as the most robust digital modulation technique and is used for long distance wireless communication.
    
2. **Quadrature phase shift keying:**This technique is used to increase the bit rate i.e we can code two bits
onto one single element. It uses four phases to encode two bits per
symbol. QPSK uses phase shifts of multiples of 90 degrees.
    
    It has double data rate carrying capacity compare to BPSK as two bits are mapped on each constellation points.
    

**Advantages of phase shift Keying –**

- It is a more power efficient modulation technique as compared to ASK and FSK.
- It has lower chances of an error.
- It allows data to be carried along a communication signal much more efficiently as compared to FSK.

**Disadvantages of phase shift Keying –**

- It offers low bandwidth efficiency.
- The detection and recovery algorithms of binary data is very complex.
- It is a non coherent reference signal.

**Reference –**[Digital-to-analog converter – Wikipedia](https://en.wikipedia.org/wiki/Digital-to-analog_converter)
*** WIRELESS COMMUNICATION
Before talking about wireless medium, we need to talk about the wired
 medium. Wired network is a bounded medium. Data travel over a path that
 a wire or cable takes.In modern era of advanced and enormous no of 
devices, wired medium of communication imposes a restriction on fluent 
communication. There are various problems with wired networks. Consider a
 situation, you want to connect to 10 or more devices around you.

You
 need exact same no of ports to be able to connect to devices but large 
no of ports seems to be impractical but with wireless network, it can be
 easily done

As its name, wireless network eliminates needs to be 
tethered with wire or cable. Convenience and Mobility becomes its main 
characteristics. Many different wireless devices can connect to network 
easily and seamlessly. As wireless data travel through air, there must 
be some constraints within which wireless communication takes place.These are:

- All wireless devices must follow a common standard i.e, IEEE 802.11
- Wireless coverage must be there where devices are expected to use.

**Note –**

- Wired network comes under IEEE standard 802.3
- wireless network comes under IEEE standard 802.11

> IEEE stands for “Institute of Electrical and Electronics Engineers”, is an organization composed of engineers that issues and manages standards for electrical and electronic devices.
> 

**Basics of Wireless Communication :**Wireless communication takes places over free space through RF (radio frequency), one device, **Transmitter** send signal to other device, **Receiver**.
 Two devices (transmitter and receiver) must use same frequency (or 
channel) to be able to communicate with each other. If a large number of
 wireless devices communicate at same time, radio frequency can cause 
interference with each other.Interference increases as no of devices 
increases.

!https://media.geeksforgeeks.org/wp-content/uploads/20200426115854/unidirectional-comm.png

!https://media.geeksforgeeks.org/wp-content/uploads/20200426115845/Bidirectional-comm.png

!https://media.geeksforgeeks.org/wp-content/uploads/20200426115851/interference.png

Wireless
 devices share airtime just like wired devices connect to shared media 
and share common bandwidth. For effective use of media, all wireless 
devices operate in half duplex mode to avoid collision or interference. 
Before the transmission begins, devices following IEEE 802.11 standard 
must check whether channel is available and clear.

**Note –**Wireless
 communication is always half duplex as transmission uses same frequency
 or channel. To achieve full duplex mode, devices uses different 
frequency or channel of transmission andreceiving of signals. You can say that wireless communication is Full-duplex but technically it is not.

**Radio Frequency :**In
 free space, the sender (transmitter) send an alternating current into a
 section of wire (an antenna). This sets up a moving electric and 
magnetic field that away as travelling waves. The electric and magnetic 
field moves along each other at a right angle to each other as shown. 
The signal must keep changing or alternating by cycle up and down to 
keep electric and magnetic field cyclic and pushing forward. The no of 
cycles a wave taking in a second is called Frequency of the wave.So,

```
frequency = no of cycles per second
```

!https://media.geeksforgeeks.org/wp-content/uploads/20200426115848/frequency.png

Electromagnetic
 waves do not travel in a straight line. they travel by expanding in all
 direction away from antenna. Like you have seen waves travelling in 
water when you drop or throw a stone in a water body.

!https://media.geeksforgeeks.org/wp-content/uploads/20200426115901/wave-propagation.png

**Frequency Unit Names :**

UnitAbbreviationMeaningHertzHzCycles per secondKilohertzKHz1000 HzMegahertzMHz1, 000, 000 HzGigahertzGHz1, 000, 000, 000 Hz


Prerequisite – [Wireless Communication | Set 1](https://www.geeksforgeeks.org/wireless-communication-set-1/)

**Basic Service Set :**We
 know that wireless communication takes place over the Air. To regulate 
connection to devices, we need to make every wireless service area a 
closed group of mobile devices that form around a fixed device. Before 
mobile devices start data communication, they must advertise their 
capabilities, and then permission to join should be granted. There is a 
term defined to such arrangement, IEEE calls this standard a Basic 
service set (**BSS**).

At the center of every BSS, there is an access point (**AP**),
 it provides services that are necessary to form the infrastructure of 
Wireless communication. The AP operates in an infrastructure mode and 
uses a single wireless channel. All devices that want to connect to AP 
must use that same channel.

Because the operation of BSS depends 
on AP, BSS is bounded to the area covered by the AP i.e, the area up to 
which AP’s signal is reachable. This area is called the Basic Service 
Area (BSA) or cell. The cell is usually a circular shape with the center
 as AP. The AP serves as a single point of contact for the BSS. The AP 
uses a unique BSS identifier (**BSSID**) based on its own MAC address to advertise it’s existence to all devices in the cell.

The AP also advertises a human-readable text string called Service Set identifier (**SSID**)
 to uniquely identify the AP. You can say BSSID as a machine-readable 
unique tag to identify a wireless service and SSID a human-readable 
service tag.

!https://media.geeksforgeeks.org/wp-content/uploads/20200404145044/BSS1.png

Membership
 of mobile devices with BSS is called Association. Once associated, the 
device becomes a BSS client or an 802.11 station (STA). As long as 
devices are connected to AP, all data communication passes through AP 
using BSSID as a source and destination address. You can think why all 
traffic must pass through AP? They can simply communicate with other 
devices directly without AP as a middleman. If we don’t do so then the 
whole point of wireless service will go in vain. Sending data through AP
 make it stable and controllable

!https://media.geeksforgeeks.org/wp-content/uploads/20200404145618/BSS-traffic-flow1.png

**Repeater :**An
 AP in wireless infrastructure usually connected back to the switched 
networks. BSS has a limited signal coverage area, (BSA). To extend the 
signal coverage, we can add additional AP but in some scenarios, it is 
not possible to add additional AP. The solution in such a situation is a
 Repeater. The repeater is just an AP configured in Repeater mode. A 
wireless repeater takes a signal as an input and retransmits signals in a
 new cell around Repeater. The repeater uses two transmitters and 
receiver to keep the original and repeated signals isolated on a 
different channel.

!https://media.geeksforgeeks.org/wp-content/uploads/20200404150052/repeater2.png
*** Analog to Analog Conversion (Modulation)
**Analog Signal:**
 An analog signal is any continuous signal for which the time varying 
feature of the signal is a representation of some other time varying 
quantity i.e., analogous to another time varying Signal.

**Analog to Analog Conversion –**

Analog-to-analog
 conversion, or modulation, is the representation of analog information 
by an analog signal. It is a process by virtue of which a characteristic
 of carrier wave is varied according to the instantaneous amplitude of 
the modulating signal. This modulation is generally needed when a **bandpass channel** is
 required. Bandpass is a range of frequencies which are transmitted 
through a bandpass filter which is a filter allowing specific 
frequencies to pass preventing signals at unwanted frequencies.

Analog to Analog conversion can be done in three ways:

1. Amplitude Modulation
2. Frequency Modulation
3. Phase Modulation

**1. AMPLITUDE MODULATION:**

The
 modulation in which the amplitude of the carrier wave is varied 
according to the instantaneous amplitude of the modulating signal 
keeping phase and frequency as constant. The figure below shows the 
concept of amplitude modulation:

!https://media.geeksforgeeks.org/wp-content/uploads/Amplitue_Modulation.png

AM
 is normally implemented by using a simple multiplier because the 
amplitude of the carrier signal needs to be changed according to the 
amplitude of the modulating signal.

**AM bandwidth:**The
 modulation creates a bandwidth that is twice the bandwidth of the 
modulating signal and covers a range centered on the carrier frequency.**Bandwidth= 2fm**

**2. FREQUENCY MODULATION –**

The
 modulation in which the frequency of the carrier wave is varied 
according to the instantaneous amplitude of the modulating signal 
keeping phase and amplitude as constant. The figure below shows the 
concept of frequency modulation:

!https://media.geeksforgeeks.org/wp-content/uploads/Frequency_Modulation.png

FM
 is normally implemented by using a voltage-controlled oscillator as 
with FSK. The frequency of the oscillator changes according to the input
 voltage which is the amplitude of the modulating signal.

**FM bandwidth:**

1. The bandwidth of a frequency modulated signal varies with both deviation and modulating frequency.If modulating frequency (Mf) 0.5, wide band Fm signal.
2. For a narrow band Fm signal, bandwidth required is twice the maximum
frequency of the modulation, however for a wide band Fm signal the
required bandwidth can be very much larger, with detectable sidebands
spreading out over large amounts of the frequency spectrum.

**3. PHASE MODULATION:**The
 modulation in which the phase of the carrier wave is varied according 
to the instantaneous amplitude of the modulating signal keeping 
amplitude and frequency as constant. The figure below shows the concept 
of frequency modulation:

!https://media.geeksforgeeks.org/wp-content/uploads/Phase_modulation.png

Phase
 modulation is practically similar to Frequency Modulation, but in Phase
 modulation frequency of the carrier signal is not increased. It is 
normally implemented by using a voltage-controlled oscillator along with
 a derivative. The frequency of the oscillator changes according to the 
derivative of the input voltage which is the amplitude of the modulating
 signal.

**PM bandwidth:**

1. For small
amplitude signals, PM is similar to amplitude modulation (AM) and
exhibits its unfortunate doubling of baseband bandwidth and poor
efficiency.
2. For a single large sinusoidal signal, PM is similar to FM, and its bandwidth is approximately, **2 (h+1) Fm** where h= modulation index.

Thus,
 Modulation allows us to send a signal over a bandpass frequency range. 
If every signal gets its own frequency range, then we can transmit 
multiple signals simultaneously over a single channel, all using 
different frequency ranges.

!https://media.geeksforgeeks.org/wp-content/post-ads-banner/2022-05-25-15-57-36-InterviewSeriesPrepareInArticleAd.webp
*** Difference between Broadband and Baseband Transmission
**Broadband**
 systems use modulation techniques to reduce the effect of noise in the 
environment. Broadband transmission employs multiple channel 
unidirectional transmission using a combination of phase and amplitude 
modulation.

**Baseband**
 is a digital signal transmitted on the medium using one of the signal 
codes like NRZ, RZ Manchester biphase-M code, etc. called baseband 
transmission.

These are the following differences between Broadband and Baseband transmission.

**Baseband transmission:**

1. Digital signaling.
2. Frequency division multiplexing is not possible.
3. Baseband is the bi-directional transmission.
4. A short-distance signal traveling.
5. The entire bandwidth is for single signal transmission.
6. Example: Ethernet is using Basebands for LAN.

**Broadband transmission:**

1. Analog signaling.
2. The transmission of data is unidirectional.
3. Signal traveling distance is long.
4. Frequency division multiplexing is possible.
5. Simultaneous transmission of multiple signals over different frequencies.
6. Example: Used to transmit cable TV to premises.

[Untitled Database](https://www.notion.so/3f1fd4b23e1a48ed86f0d7c81dbf30ac?pvs=21)
*** Design Issues in Physical Layer
**Physical layer** co-ordinates the functions required 
to transmit a bit stream over a physical medium. It deals with the 
mechanical and electrical specifications of the interface and 
transmission medium.

!https://media.geeksforgeeks.org/wp-content/uploads/computer-network-osi-model-layers.png

The lowest layer of the [OSI reference model](https://www.geeksforgeeks.org/layers-of-osi-model/)
 is the physical layer. It is responsible for the actual physical 
connection between the devices. The physical layer contains information 
in the form of bits. It is responsible for transmitting individual bits 
from one node to the next.

**Functions of physical layer :**

1. **Data Rate –**This layer defines the rate of transmission which is the number of bits per second.
2. **Interface –**The physical layer defines the transmission interface between devices and transmission medium.
3. **Representation of Bits –**Data in this layer consist of stream of bits. The bits must be encoded into
signals for transmission.It defines the type of encoding i.e.how 0’s and 1’s are changed to signals.
4. **Line configuration –**This layer connects devices with the medium either it can be point to point configuration or Multipoint configuration.
5. **Transmission Modes –**Physical layer defines the direction of transmission between two devices such as Simplex, Half duplex, Full duplex.
6. **Topologies –**Devices must be connected through any topologies either it can be Mesh, Star, Bus And Ring.

**Design Issues in Physical Layer :**

- The physical layer is basically concerned with transmitting raw bits over a communication channel.
- Mainly the design issues here deal with electrical, mechanical, timing
interfaces, and the physical transmission medium, which lies below the
physical layer.
- Design issue has to do with making sure that
when 1 bit send from one side, it is received 1 bit by other side also
not as a 0 bit.

Some questions are here like :

1. How many nanoseconds a bit lasts ?
2. How many volts should be use to represent a 1 bit and how many for a 0 ?
3. How many pins the network connector has and what each pin is used for ?
** DATA LINK LAYER
*** Multiple Access Protocols in Computer Network
The Data Link Layer is responsible for transmission of data between two nodes. Its main functions are-

- Data Link Control
- Multiple Access Control

!https://media.geeksforgeeks.org/wp-content/uploads/1-49.jpg

**Data Link control –** The
 data link control is responsible for reliable transmission of message 
over transmission channel by using techniques like framing, error 
control and flow control. For Data link control refer to – [Stop and Wait ARQ](https://www.geeksforgeeks.org/stop-and-wait-arq/)

**Multiple Access Control –** If
 there is a dedicated link between the sender and the receiver then data
 link control layer is sufficient, however if there is no dedicated link
 present then multiple stations can access the channel simultaneously. 
Hence multiple access protocols are required to decrease collision and 
avoid crosstalk. For example, in a classroom full of students, when a 
teacher asks a question and all the students (or stations) start 
answering simultaneously (send data at same time) then a lot of chaos is
 created( data overlap or data lost) then it is the job of the teacher 
(multiple access protocols) to manage the students and make them answer 
one at a time.

Thus, protocols are required for sharing data on 
non dedicated channels. Multiple access protocols can be subdivided 
further as – 

!https://media.geeksforgeeks.org/wp-content/uploads/2-44.jpg

**1. Random Access Protocol:**
 In this, all stations have same superiority that is no station has more
 priority than another station. Any station can send data depending on 
medium’s state( idle or busy). It has two features:

1. There is no fixed time for sending data
2. There is no fixed sequence of stations sending data

The Random access protocols are further subdivided as:

**(a) ALOHA –**
 It was designed for wireless LAN but is also applicable for shared 
medium. In this, multiple stations can transmit data at the same time 
and can hence lead to collision and data being garbled.

- **Pure Aloha:** When a station sends data it waits for an acknowledgement. If the
acknowledgement doesn’t come within the allotted time then the station
waits for a random amount of time called back-off time (Tb) and re-sends the data. Since different stations wait for different amount of time,
the probability of further collision decreases.

```
Vulnerable Time = 2* Frame transmission time
Throughput =  G exp{-2*G}
Maximum throughput = 0.184 for G=0.5
```

- **Slotted Aloha:** It is similar to pure aloha, except that we divide time into slots and
sending of data is allowed only at the beginning of these slots. If a
station misses out the allowed time, it must wait for the next slot.
This reduces the probability of collision.

```
Vulnerable Time =  Frame transmission time
Throughput =  G exp{-*G}
Maximum throughput = 0.368 for G=1
```

For more information on ALOHA refer – [LAN Technologies](https://www.geeksforgeeks.org/local-area-network-lan-technologies/)

**(b) CSMA –**
 Carrier Sense Multiple Access ensures fewer collisions as the station 
is required to first sense the medium (for idle or busy) before 
transmitting data. If it is idle then it sends data, otherwise it waits 
till the channel becomes idle. However there is still chance of 
collision in CSMA due to propagation delay. For example, if station A 
wants to send data, it will first sense the medium.If it finds the 
channel idle, it will start sending data. However, by the time the first
 bit of data is transmitted (delayed due to propagation delay) from 
station A, if station B requests to send data and senses the medium it 
will also find it idle and will also send data. This will result in 
collision of data from station A and B.

CSMA access modes-

- **1-persistent:** The node senses the channel, if idle it sends the data, otherwise it
continuously keeps on checking the medium for being idle and transmits
unconditionally(with 1 probability) as soon as the channel gets idle.
- **Non-Persistent:** The node senses the channel, if idle it sends the data, otherwise it
checks the medium after a random amount of time (not continuously) and
transmits when found idle.
- **P-persistent:** The
node senses the medium, if idle it sends the data with p probability. If the data is not transmitted ((1-p) probability) then it waits for some
time and checks the medium again, now if it is found idle then it send
with p probability. This repeat continues until the frame is sent. It is used in Wifi and packet radio systems.
- **O-persistent:** Superiority of nodes is decided beforehand and transmission occurs in
that order. If the medium is idle, node waits for its time slot to send
data.

**(c) CSMA/CD –** Carrier sense multiple
 access with collision detection. Stations can terminate transmission of
 data if collision is detected. For more details refer – [Efficiency of CSMA/CD](https://www.geeksforgeeks.org/computer-network-efficiency-csmacd/)

**(d) CSMA/CA –** Carrier
 sense multiple access with collision avoidance. The process of 
collisions detection involves sender receiving acknowledgement signals. 
If there is just one signal(its own) then the data is successfully sent 
but if there are two signals(its own and the one with which it has 
collided) then it means a collision has occurred. To distinguish between
 these two cases, collision must have a lot of impact on received 
signal. However it is not so in wired networks, so CSMA/CA is used in 
this case.

CSMA/CA avoids collision by:

1. **Interframe space –** Station waits for medium to become idle and if found idle it does not
immediately send data (to avoid collision due to propagation delay)
rather it waits for a period of time called Interframe space or IFS.
After this time it again checks the medium for being idle. The IFS
duration depends on the priority of station.
2. **Contention Window –** It is the amount of time divided into slots. If the sender is ready to
send data, it chooses a random number of slots as wait time which
doubles every time medium is not found idle. If the medium is found busy it does not restart the entire process, rather it restarts the timer
when the channel is found idle again.
3. **Acknowledgement –** The sender re-transmits the data if acknowledgement is not received before time-out.

**2. Controlled Access:** In this, the data is sent by that station which is approved by all other stations. For further details refer – [Controlled Access Protocols](https://www.geeksforgeeks.org/computer-network-controlled-access-protocols/)

**3. Channelization:** In
 this, the available bandwidth of the link is shared in time, frequency 
and code to multiple stations to access channel simultaneously.

- **Frequency Division Multiple Access (FDMA) –** The available bandwidth is divided into equal bands so that each station
can be allocated its own band. Guard bands are also added so that no two bands overlap to avoid crosstalk and noise.
- **Time Division Multiple Access (TDMA) –** In this, the bandwidth is shared between multiple stations. To avoid
collision time is divided into slots and stations are allotted these
slots to transmit data. However there is a overhead of synchronization
as each station needs to know its time slot. This is resolved by adding
synchronization bits to each slot. Another issue with TDMA is
propagation delay which is resolved by addition of guard bands. For more details refer – [Circuit Switching](https://www.geeksforgeeks.org/computer-network-circuit-switching/)
- **Code Division Multiple Access (CDMA) –** One channel carries all transmissions simultaneously. There is neither
division of bandwidth nor division of time. For example, if there are
many people in a room all speaking at the same time, then also perfect
reception of data is possible if only two person speak the same
language. Similarly, data from different stations can be transmitted
simultaneously in different code languages.
*** P2P(Peer To Peer) File Sharing
**Introduction** In Computer Networking, P2P is a 
file-sharing technology, allowing the users to access mainly the 
multimedia files like videos, music, e-books, games, etc. The individual
 users in this network are referred to as **peers**. The peers request files from other peers by establishing TCP or UDP connections.

**How P2P works(Overview)** A
 peer-to-peer network allows computer hardware and software to 
communicate without the need for a server. Unlike client-server 
architecture, there is no central server for processing requests in a 
P2P architecture. The peers directly interact with one another without 
the requirement of a central server.

Now, when one peer makes a 
request, it is possible that multiple peers have a copy of that 
requested object. Now the problem is how to get the IP addresses of all 
those peers. This is decided by the underlying architecture supported by
 the P2P systems. By means of one of these methods, the client peer can 
get to know about all the peers which have the requested object/file and
 the file transfer takes place directly between these two peers.

**Three such Architectures exist:** 

1. Centralized Directory
2. Query Flooding
3. Exploiting Heterogeneity

**1. Centralized Directory** 

- It is somewhat similar to client-server architecture in the sense that it
maintains a huge central server to provide directory service.
- All the peers inform this central server of their IP address and the files they are making available for sharing.
- The server queries the peers at regular intervals to make sure if the peers are still connected or not.
- So basically this server maintains a huge database regarding which file is present at which IP addresses.

**Working** 

- Now whenever a requesting peer comes in, it sends its query to the server.
- Since the server has all the information of its peers, so it returns the IP
addresses of all the peers having the requested file to the peer.
- Now the file transfer takes place between these two peers.

The first system which made use of this method was **Napster**, for the purpose of Mp3 distribution. 

!https://media.geeksforgeeks.org/wp-content/uploads/TCP-2.png

The
 major problem with such an architecture is that there is a single point
 of failure. If the server crashes, the whole P2P network crashes. Also,
 since all of the processing is to be done by a single server so a huge 
amount of the database has to be maintained and regularly updated.

**2. Query Flooding** 

- Unlike the centralized approach, this method makes use of distributed systems.
- In this, the peers are supposed to be connected to an overlay network. It
means if a connection/path exists from one peer to another, it is a part of this overlay network.
- In this overlay network, peers are
called nodes, and the connection between peers is called an edge between the nodes, thus resulting in a graph-like structure.

**Working** 

- Now when one peer requests for some file, this request is sent to all its
neighboring nodes i.e. to all nodes which are connected to this node. If those nodes don’t have the required file, they pass on the query to
their neighbors and so on. This is called query flooding.
- When
the peer with the requested file is found (referred to as query hit),
the query flooding stops and it sends back the file name and file size
to the client, thus following the reverse path.
- If there are multiple query hits, the client selects from one of these peers.

**Gnutella** was the first decentralized peer-to-peer network.

!https://media.geeksforgeeks.org/wp-content/uploads/TCP-1-1.png

This
 method also has some disadvantages like, the query has to be sent to 
all the neighboring peers unless a match is found. This increases 
traffic in the network.

**3. Exploiting heterogeneity** 

- This P2P architecture makes use of both the above-discussed systems.
- It resembles a distributed system like Gnutella because there is no central server for query processing.
- But unlike Gnutella, it does not treat all its peers equally. The peers
with higher bandwidth and network connectivity are at a higher priority
and are called **group leaders/supernodes**. The rest of the peers are assigned to these supernodes.
- These supernodes are interconnected and the peers under these supernodes
inform their respective leaders about their connectivity, IP address,
and the files available for sharing.

**KaZaA** technology is such an example that makes use of Napster and Gnutella. Thus,
 the individual group leaders along with their child peers from a 
Napster-like structure. These group leaders then interconnect among 
themselves to resemble a Gnutella-like structure.

**Working** 

- This structure can process the queries in two ways.
- The first one is that the supernodes could contact other super nodes and
merge their databases with their own database. Thus, this supernode now
has information of a large number of peers.
- Another approach is
that when a query comes in, it is forwarded to the neighboring super
nodes until a match is found, just like in Gnutella. Thus query flooding exists but with limited scope as each supernode has many child peers.
Hence, such a system exploits the heterogeneity of the peers by
designating some of them as group leaders/supernodes and others as their child peers.

!https://media.geeksforgeeks.org/wp-content/uploads/TCP_new.png

References- Computer Networking: A Top-down Approach By James F. Kurose
*** Framing in Data Link Layer
Frames are the units of digital transmission, particularly in 
computer networks and telecommunications. Frames are comparable to the 
packets of energy called photons in the case of light energy. Frame is 
continuously used in Time Division Multiplexing process.

Framing
 is a point-to-point connection between two computers or devices 
consists of a wire in which data is transmitted as a stream of bits. 
However, these bits must be framed into discernible blocks of 
information. Framing is a function of the data link layer. It provides a
 way for a sender to transmit a set of bits that are meaningful to the 
receiver. Ethernet, token ring, frame relay, and other data link layer 
technologies have their own frame structures. Frames have headers that 
contain information such as error-checking codes.

!https://media.geeksforgeeks.org/wp-content/cdn-uploads/1-30.png

At
 the data link layer, it extracts the message from the sender and 
provides it to the receiver by providing the sender’s and receiver’s 
addresses. The advantage of using frames is that data is broken up into 
recoverable chunks that can easily be checked for corruption.

**Problems in Framing –**

- **Detecting start of the frame:** When a frame is transmitted, every station must be able to detect it.
Station detects frames by looking out for a special sequence of bits
that marks the beginning of the frame i.e. SFD (Starting Frame
Delimiter).
- **How does the** **station detect a frame:** Every station listens to link for SFD pattern through a sequential circuit.
If SFD is detected, sequential circuit alerts station. Station checks
destination address to accept or reject frame.
- **Detecting end of frame:** When to stop reading the frame.

**Types of framing –** There are two types of framing:

**1. Fixed size –**
 The frame is of fixed size and there is no need to provide boundaries 
to the frame, the length of the frame itself acts as a delimiter.

- **Drawback:** It suffers from internal fragmentation if the data size is less than the frame size
- **Solution:** Padding

**2. Variable size –**
 In this, there is a need to define the end of the frame as well as the 
beginning of the next frame to distinguish. This can be done in two 
ways: 

1. **Length field –** We can introduce a length field in the frame to indicate the length of the frame. Used in **Ethernet(802.3)**. The problem with this is that sometimes the length field might get corrupted.
2. **End Delimiter (ED) –** We can introduce an ED(pattern) to indicate the end of the frame. Used in **Token Ring**. The problem with this is that ED can occur in the data. This can be solved by:
    
    **1. Character/Byte Stuffing:** Used when frames consist of characters. If data contains ED then, a byte is stuffed into data to differentiate it from ED.
    
    Let ED = “$” –> if data contains ‘$’ anywhere, it can be escaped using ‘\O’ character. –> if data contains ‘\O$’ then, use ‘\O\O\O$'($ is escaped using \O and \O is escaped using \O).
    

!https://media.geeksforgeeks.org/wp-content/cdn-uploads/2-14.png

**Disadvantage –** It is very costly and obsolete method.

**2. Bit Stuffing:** Let ED = 01111 and if data = 01111 **–>** Sender stuffs a bit to break the pattern i.e. here appends a 0 in data = 0111**0**1. **–>** Receiver receives the frame. **–>** If data contains 011101, receiver removes the 0 and reads the data.

!https://media.geeksforgeeks.org/wp-content/cdn-uploads/3-12.png

**Examples –**

- If Data –> 011100011110 and ED –> 0111 then, find data after bit stuffing?
    
    –> 011**0**100011**0**11**0**0 
    
- If Data –> 110001001 and ED –> 1000 then, find data after bit stuffing?
    
    –> 1100**1**0100**1**1 
    
- [Gate CS 2014](https://www.geeksforgeeks.org/gate-gate-cs-2014-set-3-question-34/)
- [Gate IT 2004](https://www.geeksforgeeks.org/gate-gate-it-2004-question-80/)
*** LAN Technologies | ETHERNET
A local Area Network (LAN) is a data communication network connecting
 various terminals or computers within a building or limited 
geographical area. The connection among the devices could be wired or 
wireless. Ethernet, Token Ring and Wireless LAN using IEEE 802.11 are 
examples of standard LAN technologies. **LAN has the following topologies:** 

- Star Topology
- Bus Topology
- Ring Topology
- Mesh Topology
- Hybrid Topology
- Tree Topology

**Ethernet:-** Ethernet
 is the most widely used LAN technology, which is defined under IEEE 
standards 802.3. The reason behind its wide usability is Ethernet is 
easy to understand, implement, maintain, and allows low-cost network 
implementation. Also, Ethernet offers flexibility in terms of topologies
 that are allowed. Ethernet generally uses Bus Topology. Ethernet 
operates in two layers of the OSI model, Physical Layer, and Data Link 
Layer. For Ethernet, the protocol data unit is Frame since we mainly 
deal with DLL. In order to handle collision, the Access control 
mechanism used in Ethernet is CSMA/CD. Manchester Encoding Technique is used in Ethernet. 

!https://media.geeksforgeeks.org/wp-content/uploads/ETHERNET_1.jpg

Since
 we are talking about IEEE 802.3 standard Ethernet, therefore, 0 is 
expressed by a high-to-low transition, a 1 by the low-to-high 
transition. In both Manchester Encoding and Differential Manchester, the
 Encoding Baud rate is double of bit rate.

**Advantages of Ethernet:**

**Speed:** When
 compared to a wireless connection, Ethernet provides significantly more
 speed. Because Ethernet is a one-to-one connection, this is the case. 
As a result, speeds of up to 10 Gigabits per second (Gbps) or even 100 
Gigabits per second (Gbps) are possible.

**Efficiency:** An
 Ethernet cable, such as Cat6, consumes less electricity, even less than
 a wifi connection. As a result, these ethernet cables are thought to be
 the most energy-efficient.

**Good data transfer quality:** Because it is resistant to noise, the information transferred is of high quality.

```
 Baud rate = 2* Bit rate
```

Ethernet LANs consist of network nodes and interconnecting media or links. The network nodes can be of two types: **Data Terminal Equipment (DTE):-**
 Generally, DTEs are the end devices that convert the user information 
into signals or reconvert the received signals. DTEs devices are: 
personal computers, workstations, file servers or print servers also 
referred to as end stations. These devices are either the source or the 
destination of data frames. The data terminal equipment may be a single 
piece of equipment or multiple pieces of equipment that are 
interconnected and perform all the required functions to allow the user 
to communicate. A user can interact with DTE or DTE may be a user.

**Data Communication Equipment (DCE):-**
 DCEs are the intermediate network devices that receive and forward 
frames across the network. They may be either standalone devices such as
 repeaters, network switches, routers, or maybe communications interface
 units such as interface cards and modems. The DCE performs functions 
such as signal conversion, coding, and maybe a part of the DTE or 
intermediate equipment.

Currently, these data rates are defined for operation over optical fibres and twisted-pair cables: **i) Fast Ethernet** Fast Ethernet refers to an Ethernet network that can transfer data at a rate of 100 Mbit/s.

**ii) Gigabit Ethernet** Gigabit Ethernet delivers a data rate of 1,000 Mbit/s (1 Gbit/s).

**iii) 10 Gigabit Ethernet** 10
 Gigabit Ethernet is the recent generation and delivers a data rate of 
10 Gbit/s (10,000 Mbit/s). It is generally used for backbones in 
high-end applications requiring high data rates.

**ALOHA** The
 Aloha protocol was designed as part of a project at the University of 
Hawaii. It provided data transmission between computers on several of 
the Hawaiian Islands involving packet radio networks. Aloha is a 
multiple access protocol at the data link layer and proposes how 
multiple terminals access the medium without interference or collision.

There are two different versions of ALOHA: **1. Pure Aloha** Pure
 Aloha is an un-slotted, decentralized, and simple to implement the 
protocol. In pure ALOHA, the stations simply transmit frames whenever 
they want data to send. It does not check whether the channel is busy or
 not before transmitting. In case, two or more stations transmit 
simultaneously, the collision occurs and frames are destroyed. Whenever 
any station transmits a frame, it expects acknowledgement from the 
receiver. If it is not received within a specified time, the station 
assumes that the frame or acknowledgement has been destroyed. Then, the 
station waits for a random amount of time and sends the frame again. 
This randomness helps in avoiding more collisions. This scheme works 
well in small networks where the load is not much. But in largely loaded
 networks, this scheme fails poorly. This led to the development of 
Slotted Aloha. To assure pure aloha: Its throughput and rate of transmission of the frame to be predicted. For that to make some assumptions: i) All the frames should be the same length. ii) Stations can not generate frames while transmitting or trying to transmit frames. iii)The
 population of stations attempts to transmit (both new frames and old 
frames that collided) according to a Poisson distribution. 

!https://media.geeksforgeeks.org/wp-content/uploads/ETHERNET_2.jpg

```
 Vulnerable Time = 2 * Tt
```

**The efficiency of Pure ALOHA:** 

```
Spure= G * e^-2G
where G is number of stations wants to transmit in Tt slot.Maximum Efficiency:
Maximum Efficiency will be obtained when G=1/2

(Spure)max = 1/2 * e^-1
           = 0.184

Which means, in Pure ALOHA, only about 18.4% of the time is used for successful transmissions.
```

**2. Slotted Aloha** This
 is quite similar to Pure Aloha, differing only in the way transmissions
 take place. Instead of transmitting right at demand time, the sender 
waits for some time. In slotted ALOHA, the time of the shared channel is
 divided into discrete intervals called *Slots*. The stations are 
eligible to send a frame only at the beginning of the slot and only one 
frame per slot is sent. If any station is not able to place the frame 
onto the channel at the beginning of the slot, it has to wait until the 
beginning of the next time slot. There is still a possibility of 
collision if two stations try to send at the beginning of the same time 
slot. But still, the number of collisions that can possibly take place 
is reduced by a large margin and the performance becomes much well 
compared to Pure Aloha.

!https://media.geeksforgeeks.org/wp-content/uploads/ETHERNET_3.jpg

Collision is possible for only the current slot. Therefore, Vulnerable Time is Tt.

**The efficiency of Slotted ALOHA:** 

```
Sslotted = G * e^-G

Maximum Efficiency:
(Sslotted)max = 1 * e^-1
              = 1/e = 0.368
Maximum Efficiency, in Slotted ALOHA, is 36.8%.
```

Image Reference: [Wikipedia](https://en.wikipedia.org/wiki/Manchester_code#/media/File:Manchester_encoding_both_conventions.svg), [Technical University of Munich](https://www.lkn.ei.tum.de/mmprog/mac/protocols/collision/aloha2.htm)
*** What is Ethernet?
ReadDiscuss

A local Area Network (LAN)
 is a data communication network connecting various terminals or 
computers within a building or limited geographical area. The connection
 between the devices could be wired or wireless. [Ethernet](https://www.geeksforgeeks.org/what-is-ethernet/), [Token rings](https://www.geeksforgeeks.org/efficiency-of-token-ring/), and [Wireless LAN](https://www.geeksforgeeks.org/difference-between-lan-and-wlan/) using [IEEE 802.11](https://www.geeksforgeeks.org/ieee-802-11-mac-frame/) are examples of standard [LAN technologies](https://www.geeksforgeeks.org/lan-switching/).

## What is Ethernet?

Ethernet is the most widely used [LAN](https://) technology
 and is defined under IEEE standards 802.3. The reason behind its wide 
usability is that Ethernet is easy to understand, implement, and 
maintain, and allows low-cost network implementation. Also, Ethernet 
offers flexibility in terms of the topologies that are allowed. Ethernet
 generally uses a bus topology. Ethernet operates in two layers of the [OSI model](https://www.geeksforgeeks.org/layers-of-osi-model/), the physical layer and the [data link layer](https://www.geeksforgeeks.org/data-link-layer/).
 For Ethernet, the protocol data unit is a frame since we mainly deal 
with DLLs. In order to handle collisions, the Access control mechanism 
used in [Ethernet](https://www.geeksforgeeks.org/what-is-ethernet/) is [CSMA/CD.](https://www.geeksforgeeks.org/collision-detection-csmacd/)

Although Ethernet has been largely replaced by wireless networks, wired networking still uses Ethernet more frequently. [Wi-Fi](https://www.geeksforgeeks.org/what-is-wi-fiwireless-fidelity/)
 eliminates the need for cables by enabling users to connect their 
smartphones or laptops to a network wirelessly. The 802.11ac Wi-Fi 
standard offers faster maximum data transfer rates when compared to 
Gigabit Ethernet. However, wired connections are more secure and less 
susceptible to interference than wireless networks. This is the main 
justification for why so many companies and organizations continue to 
use Ethernet.

## History of Ethernet

Robert
 Metcalfe’s invention of Ethernet in 1973 completely changed computer 
networking. With Ethernet Version 2’s support for 10 Mbps and an initial
 data rate of 2.94 Mbps, it first gained popularity in 1982. Ethernet’s 
adoption was accelerated by the IEEE 802.3 standardization in 1983. 
Local area networks (LANs) and the internet were able to expand quickly 
thanks to the rapid evolution and advancement of Ethernet, which over 
time reached speeds of 100 Mbps, 1 Gbps, 10 Gbps, and higher. It evolved
 into the standard technology for wired network connections, enabling 
dependable and quick data transmission for private residences, 
commercial buildings, and data centers all over the world.

There are different types of Ethernet networks that are used to connect devices and transfer data.

Let’s discuss them in simple terms:

**1. Fast Ethernet:** This
 type of Ethernet network uses cables called twisted pair or CAT5. It 
can transfer data at a speed of around 100 Mbps (megabits per second). 
Fast Ethernet uses both fiber optic and twisted pair cables to enable 
communication. There are three categories of Fast Ethernet: 100BASE-TX, 
100BASE-FX, and 100BASE-T4.

**2. Gigabit Ethernet:**
 This is an upgrade from Fast Ethernet and is more common nowadays. It 
can transfer data at a speed of 1000 Mbps or 1 Gbps (gigabit per 
second). Gigabit Ethernet also uses fiber optic and twisted pair cables 
for communication. It often uses advanced cables like CAT5e, which can 
transfer data at a speed of 10 Gbps.

**3.10-Gigabit Ethernet:**
 This is an advanced and high-speed network that can transmit data at a 
speed of 10 gigabits per second. It uses special cables like CAT6a or 
CAT7 twisted-pair cables and fiber optic cables. With the help of fiber 
optic cables, this network can cover longer distances, up to around 
10,000 meters.

**4. Switch Ethernet:** This
 type of network involves using switches or hubs to improve network 
performance. Each workstation in this network has its own dedicated 
connection, which improves the speed and efficiency of data transfer. 
Switch Ethernet supports a wide range of speeds, from 10 Mbps to 10 
Gbps, depending on the version of Ethernet being used.

In
 summary, Fast Ethernet is the basic version with a speed of 100 Mbps, 
Gigabit Ethernet is faster with a speed of 1 Gbps, 10-Gigabit Ethernet 
is even faster with a speed of 10 Gbps, and Switch Ethernet uses 
switches or hubs to enhance network performance.

The [Manchester Encoding](https://www.geeksforgeeks.org/manchester-encoding-in-computer-network/) Technique is used in [Ethernet](https://www.geeksforgeeks.org/what-is-ethernet/).

Using
 Manchester encoding, data can be transmitted over a physical medium in 
communication systems. It is a type of line coding where the signal 
transitions, as opposed to the absolute voltage levels, serve as the 
data representation.

Each bit of information is split into two equal time periods, or “halves,” in [Manchester encoding](https://www.geeksforgeeks.org/manchester-encoding-in-computer-network/).
 If the signal level is higher during the first half of the bit period 
than it is during the second, the result is a logic high (typically 1), 
or vice versa.

!https://media.geeksforgeeks.org/wp-content/uploads/ETHERNET_1.jpg

Since
 we are talking about IEEE 802.3 standard Ethernet, therefore, 0 is 
expressed by a high-to-low transition, a 1 by the low-to-high 
transition. In both Manchester Encoding and Differential Manchester, the
 Encoding Baud rate is double of bit rate.

## Key Features of Ethernet

1. **Speed:** Ethernet is capable of transmitting data at high speeds, with current Ethernet standards supporting speeds of up to 100 Gbps.
2. **Flexibility:** Ethernet is a flexible technology that can be used with a wide range of devices and operating systems. It can also be easily scaled to
accommodate a growing number of users and devices.
3. **Reliability:** Ethernet is a reliable technology that uses error-correction techniques to
ensure that data is transmitted accurately and efficiently.
4. **Cost-effectiveness:** Ethernet is a cost-effective technology that is widely available and
easy to implement. It is also relatively low-maintenance, requiring
minimal ongoing support.
5. **Interoperability:** Ethernet is an interoperable technology that allows devices from different
manufacturers to communicate with each other seamlessly.
6. **Security:** Ethernet includes built-in security features, including encryption and authentication, to protect data from unauthorized access.
7. **Manageability:** Ethernet networks are easily managed, with various tools available to
help network administrators monitor and control network traffic.
8. **Compatibility:** Ethernet is compatible with a wide range of other networking technologies,
making it easy to integrate with other systems and devices.
9. **Availability:** Ethernet is a widely available technology that can be used in almost
any setting, from homes and small offices to large data centers and
enterprise-level networks.
10. **Simplicity:** Ethernet is a simple technology that is easy to understand and use. It
does not require specialized knowledge or expertise to set up and
configure, making it accessible to a wide range of users.
11. **Standardization:** Ethernet is a standardized technology, which means that all Ethernet devices and systems are designed to work together seamlessly. This makes it easier
for network administrators to manage and troubleshoot Ethernet networks.
12. **Scalability:** Ethernet is highly scalable, which means it can easily accommodate the
addition of new devices, users, and applications without sacrificing
performance or reliability.
13. **Broad compatibility:** Ethernet is compatible with a wide range of protocols and technologies, including TCP/IP, HTTP, FTP, and others. This makes it a versatile
technology that can be used in a variety of settings and applications.
14. **Ease of integration:** Ethernet can be easily integrated with other networking technologies,
such as Wi-Fi and Bluetooth, to create a seamless and integrated network environment.
15. **Ease of troubleshooting:** Ethernet networks are easy to troubleshoot and diagnose, thanks to a
range of built-in diagnostic and monitoring tools. This makes it easier
for network administrators to identify and resolve issues quickly and
efficiently.
16. **Support for multimedia:** Ethernet supports multimedia applications, such as video and audio
streaming, making it ideal for use in settings where multimedia content
is a key part of the user experience.Ethernet is a reliable,
cost-effective, and widely used [LAN technology](https://www.geeksforgeeks.org/what-is-ethernet/) that offers high-speed connectivity and easy manageability for local networks.

## Advantages of Ethernet

**Speed:** When
 compared to a wireless connection, Ethernet provides significantly more
 speed. Because Ethernet is a one-to-one connection, this is the case. 
As a result, speeds of up to 10 Gigabits per second (Gbps) or even 100 
Gigabits per second (Gbps) are possible.

**Efficiency:** An
 Ethernet cable, such as Cat6, consumes less electricity, even less than
 a wifi connection. As a result, these ethernet cables are thought to be
 the most energy-efficient.

**Good data transfer quality:** Because it is resistant to noise, the information transferred is of high quality.

```
 Baud rate = 2* Bit rate
```

Ethernet LANs consist of network nodes and interconnecting media, or links.

The network nodes can be of two types:

**Data Terminal Equipment (DTE):** Media,
 Generally, DTEs are the end devices that convert the user information 
into signals or reconvert the received signals. DTE devices are: 
personal computers, workstations, file servers or print servers also 
referred to as end stations. These devices are either the source or the 
destination of data frames. The data terminal equipment may be a single 
piece of equipment or multiple pieces of equipment that are 
interconnected and perform all the required functions to allow the user 
to communicate. A user can interact with DTE or DTE may be a user.

**Data Communication Equipment (DCE):-**
 DCEs are the intermediate network devices that receive and forward 
frames across the network. They may be either standalone devices such as
 repeaters, network switches, or [routers](https://www.geeksforgeeks.org/implementation-of-rip-routing-in-cisco-for-connecting-two-routers/),
 or maybe communications interface units such as interface cards and 
modems. The DCE performs functions such as signal conversion, coding, 
and maybe a part of the DTE or intermediate equipment.

## Disadvantages of Ethernet

**Distance limitations:** Ethernet
 has distance limitations, with the maximum cable length for a standard 
Ethernet network being 100 meters. This means that it may not be 
suitable for larger networks that require longer distances.

**Bandwidth sharing:** Ethernet
 networks share bandwidth among all connected devices, which can result 
in reduced network speeds as the number of devices increases.

**Security vulnerabilities:**
 Although Ethernet includes built-in security features, it is still 
vulnerable to security breaches, including unauthorized access and data 
interception.

**Complexity:** Ethernet networks can be complex to set up and maintain, requiring specialized knowledge and expertise.

**Compatibility issues:**
 While Ethernet is generally interoperable with other networking 
technologies, compatibility issues can arise when integrating with older
 or legacy systems.

**Cable installation:** Ethernet networks require the installation of physical cables, which can be time-consuming and expensive to install.

**Physical limitations:** Ethernet networks require physical connections between devices, which can limit mobility and flexibility in network design.

## **ALOHA**

The [Aloha protocol](https://www.geeksforgeeks.org/what-is-pure-aloha/) was
 designed as part of a project at the University of Hawaii. It provided 
data transmission between computers on several of the Hawaiian Islands 
using packet radio networks. Aloha is a multiple access protocol at the [data link layer](https://www.geeksforgeeks.org/data-link-layer/) and proposes how multiple terminals can access the medium without interference or collision.

There are two different versions of Aloha:

### **1. Pure Aloha**

Pure
 Aloha is an un-slotted, decentralized, and simple-to-implement 
protocol. In pure Aloha, the stations simply transmit frames whenever 
they want data to send. It does not check whether the channel is busy or
 not before transmitting. In the event that two or more stations 
transmit simultaneously, a collision occurs and frames are destroyed. 
Whenever any station transmits a frame, it expects acknowledgment from 
the receiver. If it is not received within a specified time, the station
 assumes that the frame or acknowledgment has been destroyed. Then, the 
station waits for a random amount of time and sends the frame again. 
This randomness helps in avoiding more collisions. This scheme works 
well in small networks where the load is not much. But in largely loaded
 networks, this scheme fails poorly. This led to the development of [Slotted Aloha.](https://www.geeksforgeeks.org/what-is-slotted-aloha/)

To assure pure aloha: Its throughput and rate of transmission of the frame are to be predicted.

For that, let’s make some assumptions:

- All the frames should be the same length.
- Stations can not generate frames while transmitting or trying to transmit frames.
- The population of stations attempts to transmit (both new frames and old frames that collided) according to a [Poisson distribution.](https://www.geeksforgeeks.org/poisson-distribution-formula/)

!https://media.geeksforgeeks.org/wp-content/uploads/20230710122406/ETHERNET_2.webp

```
 Vulnerable Time = 2 * Tt
```

**The efficiency of Pure ALOHA:**

```
Pure Aloha= G * e^-2G
where G is number of stations wants to transmit in Tt slot.

Maximum Efficiency:
Maximum Efficiency will be obtained when G=1/2

(pure aloha)max = 1/2 * e^-1
           = 0.184

Which means, in Pure ALOHA, only about 18.4% of the time is used for successful transmissions.

```

**2. Slotted Aloha**

This
 is quite similar to Pure Aloha, differing only in the way transmissions
 take place. Instead of transmitting right at the demand time, the 
sender waits for some time. In [slotted ALOHA](https://www.geeksforgeeks.org/what-is-slotted-aloha/), the time of the shared channel is divided into discrete intervals called *Slots*.
 The stations are eligible to send a frame only at the beginning of the 
slot and only one frame per slot is sent. If any station is not able to 
place the frame onto the channel at the beginning of the slot, it has to
 wait until the beginning of the next time slot. There is still a 
possibility of collision if two stations try to send at the beginning of
 the same time slot. But still, the number of collisions that can 
possibly take place is reduced by a large margin and the performance 
becomes much well compared to Pure Aloha.

![https://media.geeksforgeeks.org/wp-content/uploads/20230710130831/ETHERNET_3-(1).webp](https://media.geeksforgeeks.org/wp-content/uploads/20230710130831/ETHERNET_3-(1).webp)

Collision is possible only in the current slot. Therefore, Vulnerable Time is Tt.

**The efficiency of Slotted Aloha**

```
slotted Aloha= G * e^-G

Maximum Efficiency:
(slotted)max = 1 * e^-1
              = 1/e = 0.368
Maximum Efficiency, in Slotted ALOHA, is 36.8%.

```

## How Ethernet Works?

In
 the Open Systems Interconnection (OSI) model, the Ethernet is located 
in the lower layers and facilitates the operation of the physical and 
data link layers. The [OSI model](https://www.geeksforgeeks.org/layers-of-osi-model/) consists of seven layers, which are as follows.

The topmost layer, known as the application layer, is what enables users to download and access data from [email](https://www.geeksforgeeks.org/what-is-an-email/)
 clients or web browsers. With the aid of the application, users enter 
their queries, and the request is then sent to the following layer, 
which is known as a “packet.” The packet contains data about the sender 
and the destination web address. The packet is transmitted from the 
application layer until it reaches the bottom layer, also known as the 
Ethernet frame.

## How do I connect an Ethernet Cable?

1. Locate the Ethernet ports on both the connected devices and then identify
them. These ports are typically marked with an “Ethernet” or “LAN”
symbol and resemble slightly larger telephone jacks.
2. Verify the cable: Make certain you have the correct Ethernet cable. Cat5e,
Cat6, or Cat6a cables are common names for Ethernet cables. These cables are typically terminated with an [RJ-45](https://www.geeksforgeeks.org/rj45-color-code/) connector and contain four pairs of twisted wires.
3. Remove any protective caps from the connectors on the Ethernet cable to
prepare the cable. Look over the cable carefully for any flaws like cuts or frayed wires. It is best to use a new cable if the one you have is
damaged.
4. Take the Ethernet cable’s one end and insert it to complete the connection.
5. Verify the cable: Make certain you have the correct Ethernet cable. Cat5e,
Cat6, or Cat6a cables are common names for Ethernet cables. These cables are typically terminated with an RJ-45 connector and contain four pairs of twisted wires.
6. Remove any protective
caps from the connectors on the Ethernet cable to prepare the cable.
Look over the cable carefully for any flaws like cuts or frayed wires.
It is best to use a new cable if the one you have is damaged.
*** Ethernet Frame Format
**Prerequisite –** [Introduction to Ethernet](https://www.geeksforgeeks.org/local-area-network-lan-technologies/)

Basic frame format which is required for all MAC implementation is defined in **IEEE 802.3 standard**. Though several optional formats are being used to extend the protocol’s basic capability.Ethernet
 frame starts with Preamble and SFD, both works at the physical layer. 
Ethernet header contains both Source and Destination MAC address, after 
which the payload of the frame is present. The last field is CRC which 
is used to detect the error. Now, let’s study each field of basic frame 
format.

### Ethernet (IEEE 802.3) Frame Format –

!https://media.geeksforgeeks.org/wp-content/uploads/IEEE-802.3-Ethernet-Frame-Format.png

- **PREAMBLE –** Ethernet frame starts with 7-Bytes Preamble. This is a pattern of
alternative 0’s and 1’s which indicates starting of the frame and allow
sender and receiver to establish bit synchronization. Initially, PRE
(Preamble) was introduced to allow for the loss of a few bits due to
signal delays. But today’s high-speed Ethernet don’t need Preamble to
protect the frame bits.PRE (Preamble) indicates the receiver that
frame is coming and allow the receiver to lock onto the data stream
before the actual frame begins.
- **Start of frame delimiter (SFD) –** This is a 1-Byte field which is always set to 10101011. SFD indicates
that upcoming bits are starting of the frame, which is the destination
address. Sometimes SFD is considered the part of PRE, this is the reason Preamble is described as 8 Bytes in many places. The SFD warns station
or stations that this is the last chance for synchronization.
- **Destination Address –** This is 6-Byte field which contains the MAC address of machine for which data is destined.
- **Source Address –** This is a 6-Byte field which contains the MAC address of source
machine. As Source Address is always an individual address (Unicast),
the least significant bit of first byte is always 0.
- **Length –** Length is a 2-Byte field, which indicates the length of entire Ethernet frame. This 16-bit field can hold the length value between 0 to 65534,
but length cannot be larger than 1500 because of some own limitations of Ethernet.
- **Data –** This is the place where actual data is inserted, also known as **Payload**. Both IP header and data will be inserted here if Internet Protocol is
used over Ethernet. The maximum data present may be as long as 1500
Bytes. In case data length is less than minimum length i.e. 46 bytes,
then padding 0’s is added to meet the minimum possible length.
- **Cyclic Redundancy Check (CRC) –** CRC is 4 Byte field. This field contains a 32-bits hash code of data,
which is generated over the Destination Address, Source Address, Length, and Data field. If the checksum computed by destination is not the same as sent checksum value, data received is corrupted.

**Note –** Size of frame of Ethernet IEEE 802.3 varies 64 bytes to 1518 bytes including data length (46 to 1500 bytes).

### Brief overview on Extended Ethernet Frame (Ethernet II Frame) :

Standard
 IEEE 802.3 basic frame format is discussed above in detail. Now let’s 
see the extended Ethernet frame header, using which we can get Payload 
even larger than 1500 Bytes.

!https://media.geeksforgeeks.org/wp-content/uploads/Proposed-ETHERNET-Frame-Extension.png

**DA**

[Destination MAC Address] :

***6 bytes***

**SA**

[Source MAC Address] :

***6 bytes***

**Type**

[0x8870 (Ethertype)] :

***2 bytes***

**DSAP**

[802.2 Destination Service Access Point] :

***1 byte***

**SSAP**

[802.2 Source Service Access Point] :

***1 byte***

**Ctrl**

[802.2 Control Field] :

***1 byte***

**Data**

[Protocol Data] :

***> 46 bytes***

**FCS**

[Frame Checksum] :

***4 bytes***

Although
 length field is missing in Ethernet II frame, the frame length is known
 by virtue of the frame being accepted by the network interface.

**GATE CS Corner Questions**

Practicing
 the following questions will help you test your knowledge. All 
questions have been asked in GATE in previous years or in GATE Mock 
Tests. It is highly recommended that you practice them.

1. [GATE CS 2007, Question 85](https://www.geeksforgeeks.org/gate-gate-cs-2007-question-19/)
2. [GATE CS 2005, Question 74](https://www.geeksforgeeks.org/gate-gate-cs-2005-question-74/)
3. [GATE CS 2004, Question 90](https://www.geeksforgeeks.org/gate-gate-cs-2004-question-54/)
4. [GATE IT 2005, Question 27](https://www.geeksforgeeks.org/gate-gate-it-2005-question-27/)
5. [GATE CS 2016 (Set 2), Question 34](https://www.geeksforgeeks.org/gate-gate-cs-2016-set-2-question-34/)

**References –**

[Extended Ethernet Frame Size Support](https://www.ietf.org/proceedings/46/I-D/draft-kaplan-isis-ext-eth-00.txt)[ciscopress](http://www.ciscopress.com/articles/article.asp?p=2348264)[IEEE 802.3 and Ethernet](https://www.cse.iitk.ac.in/users/dheeraj/cs425/lec06.html) 
*** Token Ring frame format
Prerequisite – [Ethernet Frame Format](https://www.geeksforgeeks.org/computer-network-ethernet-frame-format/)

- **Topology –** Ring topology
- **Transmission –** Unidirectional
- **Encoding –** Differential Manchester encoding
- **Access control –** Token passing
- **Data rates –** 4 Mbps, 16 Mbps

### Token Ring Frame format:

!https://media.geeksforgeeks.org/wp-content/uploads/tok-3.png

!https://media.geeksforgeeks.org/wp-content/uploads/tok-2.png

- **Start frame delimiter (SFD) –** Alerts each station for the arrival of token(or data frame) or start of the frame. It is used to synchronize clocks.
- **Access control (AC) –**
    
    !https://media.geeksforgeeks.org/wp-content/uploads/tok.png
    
    **Priority bits** and **reservation bits**
     help in implementing priority. Priority bits = reservation bits = 3. 
    Eg:- server is given priority = 7 and client is given priority = 0.
    
    **Token bit** is used to indicate presence of token frame. If token bit = 1 –> token frame and if token bit = 0 –> not a token frame.
    
    **Monitor bit** helps
     in solving orphan packet problem. It is covered by CRC as monitor are 
    powerful machines which can recalculate CRC when modifying monitor bit. 
    If monitor bit = 1 –> stamped by monitor and if monitor bit = 0 –>
     not yet stamped by monitor.
    
- **Frame control (FC) –** First 2 bits indicates whether the frame contains data or control
information. In control frames, this byte specifies the type of control
information.
    
    !https://media.geeksforgeeks.org/wp-content/uploads/tok-1.png
    
- **Destination address (DA) and Source address (SA) –** consist of two 6-byte fields which is used to indicate MAC address of source and destination.
- **Data –** Data length can vary from 0 to maximum token holding time (THT)
according to token reservation strategy adopted. Token ring imposes no
lower bound on size of data i.e. an advantage over Ethernet.
- **Cyclic redundancy check (CRC) –** 32 bit CRC which is used to check for errors in the frame, i.e.,
whether the frame is corrupted or not. If the frame is corrupted, then
its discarded.
- **End delimiter (ED) –**
It is used to mark the end of frame. In Ethernet, length field is used
for this purpose. It also contains bits to indicate a damaged frame and
identify the frame that is the last in a logical sequence.
- **Frame status (FS) –** It Is a 1-byte field terminating a data frame.It makes use of 2 copies of AC bits are used as a error detection
mechanism (100% redundancy) as CRC does not cover FS byte so that
destination does not have to recalculate CRC when modifying AC bits.
    
    !https://media.geeksforgeeks.org/wp-content/uploads/tok-4.png
    
*** Bit Stuffing in Computer Network
Data link layer is responsible for something called Framing, which is
 the division of stream of bits from network layer into manageable units
 (called frames). Frames could be of fixed size or variable size. In 
variable-size framing, we need a way to define the end of the frame and 
the beginning of the next frame.

**Bit stuffing** is the insertion of non information bits into data. Note that stuffed bits should not be confused with overhead bits. **Overhead bits** are non-data bits that are necessary for transmission (usually as part of headers, checksums etc.).

!https://media.geeksforgeeks.org/wp-content/uploads/Bit_Byte_Stuffing_2.jpg

**Applications of Bit Stuffing –**

1. synchronize several channels before multiplexing
2. rate-match two single channels to each other
3. run length limited coding

**Run length limited coding –**
 To limit the number of consecutive bits of the same value(i.e., binary 
value) in the data to be transmitted. A bit of the opposite value is 
inserted after the maximum allowed number of consecutive bits.

Bit
 stuffing technique does not ensure that the sent data is intact at the 
receiver side (i.e., not corrupted by transmission errors). It is merely
 a way to ensure that the transmission starts and ends at the correct 
places.

**Disadvantages of Bit Stuffing –**The code rate is unpredictable; it depends on the data being transmitted.

**Example of bit stuffing –**Bit sequence: 110101111101011111101011111110 (without bit stuffing)Bit sequence: 1101011111**0**01011111**0**101011111**0**110 (with bit stuffing)

After 5 consecutive 1-bits, a 0-bit is stuffed. Stuffed bits are marked bold.

Refer for [difference between Byte stuffing and Bit stuffing](https://www.geeksforgeeks.org/computer-network-difference-byte-stuffing-bit-stuffing/)
*** Difference between Byte stuffing and Bit stuffing
Data link layer is responsible for something called Framing, which is
 the division of stream of bits from the network layer into manageable 
units (called frames). Each frame consists of the sender’s address and a
 destination address. The destination address defines where the packet 
is to go and the sender’s address helps the recipient acknowledge the 
receipt.

Frames could be
 of fixed size or variable size. In fixed-size framing, there is no need
 for defining the boundaries of the frames as the size itself can be 
used to define the end of the frame and the beginning of the next frame.
 But, in variable-size framing, we need a way to define the end of the 
frame and the beginning of the next frame.

To separate one frame 
from the next, an 8-bit (or 1-byte) flag is added at the beginning and 
the end of a frame. But the problem with that is, any pattern used for 
the flag could also be part of the information. So, there are two ways 
to overcome this problem:

1. Using Byte stuffing (or character stuffing)
2. Using Bit stuffing

**Byte stuffing –**A
 byte (usually escape character(ESC)), which has a predefined bit 
pattern is added to the data section of the frame when there is a 
character with the same pattern as the flag. Whenever the receiver 
encounters the ESC character, it removes from the data section and 
treats the next character as data, not a flag.

But the problem 
arises when the text contains one or more escape characters followed by a
 flag. To solve this problem, the escape characters that are part of the
 text are marked by another escape character i.e., if the escape 
character is part of the text, an extra one is added to show that the 
second one is part of the text.Example:

!https://media.geeksforgeeks.org/wp-content/uploads/Bit_Byte_Stuffing_1.jpg

**Note –** Point-to-Point Protocol (PPP) is a byte-oriented protocol.

**Bit stuffing –**Mostly flag is a special 8-bit pattern “01111110” used to define the beginning and the end of the frame.Problem
 with the flag is the same as that was in case of byte stuffing. So, in 
this protocol what we do is, if we encounter 0 and five consecutive 1 
bits, an extra 0 is added after these bits. This extra stuffed bit is 
removed from the data by the receiver.

The extra bit is added 
after one 0 followed by five 1 bits regardless of the value of the next 
bit. Also, as the sender side always knows which sequence is data and 
which is flag it will only add this extra bit in the data sequence, not 
in the flag sequence.Example:

!https://media.geeksforgeeks.org/wp-content/uploads/Bit_Byte_Stuffing_2.jpg

**Note –** High-Level Data Link Control(HDLC) is a bit-oriented protocol.

**Reference –**[Data Communications and Networking](https://www.amazon.in/COMMUNICATIONS-NETWORKING-UPDATE-Behrouz-Forouzan/dp/0070499357?tag=googinhydr18418-21&tag=googinkenshoo-21&ascsubtag=f648c41b-4e1c-497e-9a52-031912e87d54) By Behrouz A. Forouzan (Book).
*** Hamming Code in Computer Network
Hamming code is a set of error-correction codes that can be used to **detect and correct the errors** that can occur when the data is moved or stored from the sender to the receiver. It is **technique developed by R.W. Hamming for error correction**.

**Redundant bits –**

Redundant
 bits are extra binary bits that are generated and added to the 
information-carrying bits of data transfer to ensure that no bits were 
lost during the data transfer.The number of redundant bits can be calculated using the following formula:

```
 2^r ≥ m + r + 1
 where, r = redundant bit, m = data bit

```

Suppose the number of data bits is 7, then the number of redundant bits can be calculated using:= 2^4 ≥ 7 + 4 + 1Thus, the number of redundant bits= 4

**Parity bits –**A
 parity bit is a bit appended to a data of binary bits to ensure that 
the total number of 1’s in the data is even or odd. Parity bits are used
 for error detection. There are two types of parity bits:

1. **Even parity bit:**In the case of even parity, for a given set of bits, the number of 1’s are counted. If that count is odd, the parity bit value is set to 1, making the total count of occurrences of 1’s an even number. If the total
number of 1’s in a given set of bits is already even, the parity bit’s
value is 0.
2. **Odd Parity bit –**In the case of
odd parity, for a given set of bits, the number of 1’s are counted. If
that count is even, the parity bit value is set to 1, making the total
count of occurrences of 1’s an odd number. If the total number of 1’s in a given set of bits is already odd, the parity bit’s value is 0.

**General Algorithm of Hamming code –**The Hamming Code is simply the use of extra parity bits to allow the identification of an error.

1. Write the bit positions starting from 1 in binary form (1, 10, 11, 100, etc).
2. All the bit positions that are a power of 2 are marked as parity bits (1, 2, 4, 8, etc).
3. All the other bit positions are marked as data bits.
4. Each data bit is included in a unique set of parity bits, as determined its bit position in binary form.**a.** Parity bit 1 covers all the bits positions whose binary representation includes a 1 in the least significantposition (1, 3, 5, 7, 9, 11, etc).**b.** Parity bit 2 covers all the bits positions whose binary representation includes a 1 in the second position fromthe least significant bit (2, 3, 6, 7, 10, 11, etc).**c.** Parity bit 4 covers all the bits positions whose binary representation includes a 1 in the third position fromthe least significant bit (4–7, 12–15, 20–23, etc).**d.** Parity bit 8 covers all the bits positions whose binary representation includes a 1 in the fourth position fromthe least significant bit bits (8–15, 24–31, 40–47, etc).**e.** In general, each parity bit covers all bits where the bitwise AND of the parity position and the bit position isnon-zero.
5. Since we check for even parity set a parity bit to 1 if the total number of ones in the positions it checks isodd.
6. Set a parity bit to 0 if the total number of ones in the positions it checks is even.

!https://media.geeksforgeeks.org/wp-content/uploads/20200424184419/hamming_code.png

**Determining the position of redundant bits –**These redundancy bits are placed at the positions which correspond to the power of 2.As in the above example:

1. The number of data bits = 7
2. The number of redundant bits = 4
3. The total number of bits = 11
4. The redundant bits are placed at positions corresponding to power of 2- 1, 2, 4, and 8

!https://media.geeksforgeeks.org/wp-content/uploads/array-2.jpg

Suppose the data to be transmitted is 1011001, the bits will be placed as follows:

!https://media.geeksforgeeks.org/wp-content/uploads/array2.jpg

**Determining the Parity bits –**

1. R1 bit is calculated using parity check at all the bits positions whose
binary representation includes a 1 in the least significant position.
    
    R1: bits 1, 3, 5, 7, 9, 11
    
    !https://media.geeksforgeeks.org/wp-content/uploads/arra2.jpg
    
    To
     find the redundant bit R1, we check for even parity. Since the total 
    number of 1’s in all the bit positions corresponding to R1 is an even 
    number the value of R1 (parity bit’s value) = 0
    
2. R2 bit is
calculated using parity check at all the bits positions whose binary
representation includes a 1 in the second position from the least
significant bit.
    
    R2: bits 2,3,6,7,10,11
    
    !https://media.geeksforgeeks.org/wp-content/uploads/r2arra.jpg
    
    To
     find the redundant bit R2, we check for even parity. Since the total 
    number of 1’s in all the bit positions corresponding to R2 is odd the 
    value of R2(parity bit’s value)=1
    
3. R4 bit is calculated using parity check at all the bits positions whose binary representation
includes a 1 in the third position from the least significant bit.
    
    R4: bits 4, 5, 6, 7
    
    !https://media.geeksforgeeks.org/wp-content/cdn-uploads/20190325132552/hamming.png
    
    To
     find the redundant bit R4, we check for even parity. Since the total 
    number of 1’s in all the bit positions corresponding to R4 is odd the 
    value of R4(parity bit’s value) = 1
    
4. R8 bit is calculated
using parity check at all the bits positions whose binary representation includes a 1 in the fourth position from the least significant bit.
    
    R8: bit 8,9,10,11
    
    !https://media.geeksforgeeks.org/wp-content/uploads/r8araa.jpg
    
    To
     find the redundant bit R8, we check for even parity. Since the total 
    number of 1’s in all the bit positions corresponding to R8 is an even 
    number the value of R8(parity bit’s value)=0.
    
    Thus, the data transferred is:
    
    !https://media.geeksforgeeks.org/wp-content/uploads/norarra.jpg
    

**Error detection and correction –**Suppose
 in the above example the 6th bit is changed from 0 to 1 during data 
transmission, then it gives new parity values in the binary number:

!https://media.geeksforgeeks.org/wp-content/uploads/20200122012046/edited2.png

‘

The
 bits give the binary number as 0110 whose decimal representation is 6. 
Thus, the bit 6 contains an error. To correct the error the 6th bit is 
changed from 1 to 0. 
*** Carrier Sense Multiple Access (CSMA)
This method was developed to decrease the chances of collisions when 
two or more stations start sending their signals over the data link 
layer. Carrier Sense multiple access requires that each station **first check the state of the medium** before sending.

```
Prerequisite -Multiple Access Protocols
```

**Vulnerable Time:**

```
 Vulnerable time = Propagation time (Tp)
```

!https://media.geeksforgeeks.org/wp-content/uploads/11-19.png

The persistence methods can be applied to help the station take action when the channel is busy/idle.

### 1. Carrier Sense Multiple Access with Collision Detection (CSMA/CD):

In
 this method, a station monitors the medium after it sends a frame to 
see if the transmission was successful. If successful, the station is 
finished, if not, the frame is sent again.

!https://media.geeksforgeeks.org/wp-content/uploads/22-8.png

In the diagram, *starts*
 sending the first bit of its frame at t1 and since C sees the channel 
idle at t2, starts sending its frame at t2. C detects A’s frame at t3 
and aborts transmission. A detects C’s frame at t4 and aborts its 
transmission. Transmission time for C’s frame is, therefore, t3-t2      
   and for A’s frame is t4-t1

So, the **frame transmission time (Tfr) should be at least twice the maximum propagation time (Tp)**. This can be deduced when the two stations involved in a collision are a maximum distance apart.

**Process:** The entire process of collision detection can be explained as follows:

!https://media.geeksforgeeks.org/wp-content/uploads/33-1-2.png

**Throughput and Efficiency:** The throughput of CSMA/CD is much greater than pure or slotted ALOHA.

- For the 1-persistent method, throughput is 50% when G=1.
- For the non-persistent method, throughput can go up to 90%.

### 2. Carrier Sense Multiple Access with Collision Avoidance (CSMA/CA) –

The
 basic idea behind CSMA/CA is that the station should be able to receive
 while transmitting to detect a collision from different stations. In 
wired networks, if a collision has occurred then the energy of the 
received signal almost doubles, and the station can sense the 
possibility of collision. In the case of wireless networks, most of the 
energy is used for transmission, and the energy of the received signal 
increases by only 5-10% if a collision occurs. It can’t be used by the 
station to sense collision. Therefore **CSMA/CA has been specially designed for wireless networks**.

These are three types of strategies:

1. **InterFrame Space (IFS):** When a station finds the channel busy it senses the channel again, when the
station finds a channel to be idle it waits for a period of time called **IFS time**. IFS can also be used to define the priority of a station or a frame. Higher the IFS lower is the priority.
2. **Contention Window:** It is the amount of time divided into slots. A station that is ready to send frames chooses a random number of slots as **wait time**.
3. **Acknowledgments:** The positive acknowledgments and time-out timer can help guarantee a successful transmission of the frame.

**Process:** The entire process of collision avoidance can be explained as follows:

!https://media.geeksforgeeks.org/wp-content/uploads/20200420165042/article9.png

**Types of CSMA Access Modes:**

There
 are 4 types of access modes available in CSMA. It is also referred as 4
 different types of CSMA protocols which decides time to start sending 
data across a shared media.

1. **1-Persistent:** It senses the shared channel first and delivers the data right away if the channel is idle. If not, it must wait and ***continuously*** track for the channel to become idle and then broadcast the frame
without condition as soon as it does. It is an aggressive transmission
algorithm.
2. **Non-Persistent:**  It first assesses the channel before transmitting data; if the channel
is idle, the node transmits data right away. If not, the station must
wait for an arbitrary amount of time (***not continuously***), and when it discovers the channel is empty, it sends the frames.
3. **P-Persistent:** It consists of the 1-Persistent and Non-Persistent modes combined. Each
node observes the channel in the P-Persistent mode, and if the channel
is idle, it sends a frame with a P probability. If the data is not
transferred, the frame restarts with the following time slot after
waiting for a (q = 1-p probability) random period.
4. **O-Persistent:** A supervisory node gives each node a transmission order. Nodes wait for
their time slot according to their allocated transmission sequence when
the transmission medium is idle.
*** Controlled Access Protocols in Computer Network
In controlled access, the stations seek information from one another 
to find which station has the right to send. It allows only one node to 
send at a time, to avoid collision of messages on shared medium. The 
three controlled-access methods are:

1. Reservation
2. Polling
3. Token Passing

## Reservation

- In the reservation method, a station needs to make a reservation before sending data.
- The time line has two kinds of periods:
    1. Reservation interval of fixed time length
    2. Data transmission period of variable frames.
- If there are M stations, the reservation interval is divided into M slots, and each station has one slot.
- Suppose if station 1 has a frame to send, it transmits 1 bit during the slot 1. No other station is allowed to transmit during this slot.
- In general, i  station may announce that it has a frame to send by inserting a 1 bit into i  slot. After all N slots have been checked, each station knows which stations wish to transmit.
    
    th
    
    th
    
- The stations which have reserved their slots transfer their frames in that order.
- After data transmission period, next reservation interval begins.
- Since everyone agrees on who goes next, there will never be any collisions.

The
 following figure shows a situation with five stations and a five-slot 
reservation frame. In the first interval, only stations 1, 3, and 4 have
 made reservations. In the second interval, only station 1 has made a 
reservation.

!https://media.geeksforgeeks.org/wp-content/uploads/re.png

## Polling

- Polling process is similar to the roll-call performed in class. Just like the
teacher, a controller sends a message to each node in turn.
- In
this, one acts as a primary station(controller) and the others are
secondary stations. All data exchanges must be made through the
controller.
- The message sent by the controller contains the address of the node being selected for granting access.
- Although all nodes receive the message but the addressed one responds to it and
sends data, if any. If there is no data, usually a “poll reject”(NAK)
message is sent back.
- Problems include high overhead of the polling messages and high dependence on the reliability of the controller.

!https://media.geeksforgeeks.org/wp-content/uploads/poll2-275x300.png

!https://media.geeksforgeeks.org/wp-content/uploads/poll1-300x260.png

**Efficiency** Let Tpoll be the time for polling and Tt be the time required for transmission of data. Then,

```
 Efficiency = Tt/(Tt + Tpoll)
```

## Token Passing

- In token passing scheme, the stations are connected logically to each
other in form of ring and access to stations is governed by tokens.
- A token is a special bit pattern or a small message, which circulate from one station to the next in some predefined order.
- In Token ring, token is passed from one station to another adjacent
station in the ring whereas incase of Token bus, each station uses the
bus to send the token to the next station in some predefined order.
- In both cases, token represents permission to send. If a station has a
frame queued for transmission when it receives the token, it can send
that frame before it passes the token to the next station. If it has no
queued frame, it passes the token simply.
- After sending a frame, each station must wait for all N stations (including itself) to send
the token to their neighbours and the other N – 1 stations to send a
frame, if they have one.
- There exists problems like duplication
of token or token is lost or insertion of new station, removal of a
station, which need be tackled for correct and reliable operation of
this scheme.

!https://media.geeksforgeeks.org/wp-content/uploads/token.png

**Performance** Performance of token ring can be concluded by 2 parameters:-

1. **Delay**, which is a measure of time between when a packet is ready and when it
is delivered. So, the average time (delay) required to send a token to
the next station = a/N.
2. **Throughput**, which is a measure of the successful traffic.

```
 Throughput, S = 1/(1 + a/N) for a<1
```

and

```
           S = 1/{a(1 + 1/N)} for a>1.
       where N = number of stations
             a = Tp/Tt
(Tp = propagation delay and Tt = transmission delay)
```
*** Back-off Algorithm for CSMA,,CD
Prerequisite – [Basics of CSMA/ CD](https://www.geeksforgeeks.org/computer-networks-gate-notes-set-1-data-link-layer/), [Collision Detection in CSMA/CD](https://www.geeksforgeeks.org/collision-detection-csmacd/)Back-off algorithm is a **collision resolution**
 mechanism which is used in random access MAC protocols (CSMA/CD). This 
algorithm is generally used in Ethernet to schedule re-transmissions 
after collisions.

If a 
collision takes place between 2 stations, they may restart transmission 
as soon as they can after the collision. This will always lead to 
another collision and form an infinite loop of collisions leading to a 
deadlock. To prevent such scenario back-off algorithm is used.

Let us consider an scenario of 2 stations A and B transmitting some data:

!https://media.geeksforgeeks.org/wp-content/uploads/qw-1.png

After a collision, time is divided into discrete slots (**Tslot**) whose length is equal to 2t, where t is the maximum propagation delay in the network.

The
 stations involved in the collision randomly pick an integer from the 
set K i.e {0, 1}. This set is called the contention window. If the 
sources collide again because they picked the same integer, the 
contention window size is doubled and it becomes {0, 1, 2, 3}. Now the 
sources involved in the second collision randomly pick an integer from 
the set {0, 1, 2, 3} and wait for that number of time slots before 
trying again. Before they try to transmit, they listen to the channel 
and transmit only if the channel is idle. This causes the source which 
picked the smallest integer in the contention window to succeed in 
transmitting its frame.

So, Back-off algorithm defines a *waiting time for the stations involved in collision*, i.e. for how much time the station should wait to re-transmit.

```
Waiting time = back–off time
Let n = collision number or re-transmission serial number.
Then,
Waiting time = K * Tslot
where K = [0, 2n – 1 ]

```

**Example –**

**Case-1 :**Suppose 2 
stations A and B start transmitting data (Packet 1) at the same time 
then, collision occurs. So, the collision number n for both their data 
(Packet 1) = 1. Now, both the station randomly pick an integer from the 
set K i.e. {0, 1}.

!https://media.geeksforgeeks.org/wp-content/uploads/qw1-1.png

- **When both A and B choose K = 0**–> Waiting time for A = 0 * T = 0Waiting time for B = 0 * T = 0
    
    slot
    
    slot
    
    Therefore, both stations will transmit at the same time and hence collision occurs.
    
- **When A chooses K = 0 and B chooses K = 1**–> Waiting time for A = 0 * T = 0Waiting time for B = 1 * T = T
    
    slot
    
    slot
    
    slot
    
    Therefore, A transmits the packet and B waits for time Tslot for transmitting and hence A wins.
    
- **When A chooses K = 1 and B chooses K = 0**–> Waiting time for A = 1 * T = TWaiting time for B = 0 * T = 0
    
    slot
    
    slot
    
    slot
    
    Therefore, B transmits the packet and A waits for time Tslot for transmitting and hence B wins.
    
- **When both A and B choose K = 1**–> Waiting time for A = 1 * T = TWaiting time for B = 1 * T = T
    
    slot
    
    slot
    
    slot
    
    slot
    
    Therefore, both will wait for the same time Tslot and then transmit. Hence, collision occurs.
    

```
Probability that A wins = 1/4
Probability that B wins = 1/4
Probability of collision  = 2/4

```

**Case-2 :**Assume that A wins in Case 1 and 
transmitted its data(Packet 1). Now, as soon as B transmits its packet 
1, A transmits its packet 2. Hence, collision occurs. Now collision no. n
 becomes 1 for packet 2 of A and becomes 2 for packet 1 of B.For packet 2 of A, K = {0, 1}For packet 1 of B, K = {0, 1, 2, 3}

!https://media.geeksforgeeks.org/wp-content/uploads/qw2-1.png

```
Probability that A wins = 5/8
Probability that B wins = 1/8
Probability of collision  = 2/8

```

So, the probability of collision decreases as compared to Case 1.

**Advantage –**

- Collision probability decreases exponentially.

**Disadvantages –**

- **Capture effect:** Station who wins ones keeps on winning.
- Works only for 2 stations or hosts.

**GATE Practice Question –**

1. [GATE-CS-2004 | Question 90](https://www.geeksforgeeks.org/gate-gate-cs-2004-question-54/)
2. [GATE-CS-2016 (Set 2) | Question 34](https://www.geeksforgeeks.org/gate-gate-cs-2016-set-2-question-34/)
3. [GATE-IT-2004 | Question 85](https://www.geeksforgeeks.org/gate-gate-it-2004-question-85/)
*** Collision Detection in CSMA,,CD
CSMA/CD
 (Carrier Sense Multiple Access/ Collision Detection) is a media access 
control method that was widely used in Early Ethernet technology/LANs 
When there used to be shared Bus Topology and each node ( Computers)
 were connected By Coaxial Cables. Now a Days Ethernet is Full Duplex 
and CSMA/CD is not used as Topology is either Star (connected via Switch
 or Router) or Point to Point ( Direct Connection) but they are still supported though.

Consider
 a scenario where there are ‘n’ stations on a link and all are waiting 
to transfer data through that channel. In this case, all ‘n’ stations 
would want to access the link/channel to transfer their own data. 
Problem arises when more than one station transmits the data at the 
moment. In this case, there will be collisions in the data from 
different stations.

CSMA/CD is one such technique where different
 stations that follow this protocol agree on some terms and collision 
detection measures for effective transmission. This protocol decides 
which station will transmit when so that data reaches the destination 
without corruption.

**How CSMA/CD works?**

- **Step 1:** Check if the sender is ready for transmitting data packets.
- **Step 2:** Check if the transmission link is idle? Sender has to keep on checking if the transmission link/medium is idle. For
this, it continuously senses transmissions from other nodes. Sender
sends dummy data on the link. If it does not receive any collision
signal, this means the link is idle at the moment. If it senses that the carrier is free and there are no collisions, it sends the data.
Otherwise, it refrains from sending data.
- **Step 3:** Transmit the data & check for collisions. Sender transmits its data on the link. CSMA/CD does not use an
‘acknowledgment’ system. It checks for successful and unsuccessful
transmissions through collision signals. During transmission, if a
collision signal is received by the node, transmission is stopped. The
station then transmits a jam signal onto the link and waits for random
time intervals before it resends the frame. After some random time, it
again attempts to transfer the data and repeats the above process.
- **Step 4:** If no collision was detected in propagation, the sender completes its frame transmission and resets the counters.

**How does a station know if its data collide?** 

!https://media.geeksforgeeks.org/wp-content/uploads/COLL1.png

Consider the above situation. Two stations, A & B. Propagation Time: Tp = 1 hr ( Signal takes 1 hr to go from A to B)

```
At time t=0, A transmits its data.
        t= 30 mins : Collision occurs.
```

After the collision 
occurs, a collision signal is generated and sent to both A & B to 
inform the stations about a collision. Since the collision happened 
midway, the collision signal also takes 30 minutes to reach A & B.

```
Therefore, t=1 hr: A & B receive collision signals.
```

This collision signal is received by all the stations on that link. Then,

**How to ensure that it is our station’s data that collided?** For this, Transmission time (Tt) > Propagation Time (Tp) [Rough bound] This
 is because, we want that before we transmit the last bit of our data 
from our station, we should at least be sure that some of the bits have 
already reached their destination. This ensures that the link is not 
busy and collisions will not occur. But, above is a loose bound. We 
have not taken the time taken by the collision signal to travel back to 
us. For this consider the worst-case scenario.

Consider the above system again.

!https://media.geeksforgeeks.org/wp-content/uploads/COLL2.png

```
At time t=0, A transmits its data.
        t= 59:59 mins : Collision occurs
```

This collision occurs 
just before the data reaches B. Now the collision signal takes 59:59 
minutes again to reach A. Hence, A receives the collision information 
approximately after 2 hours, that is, after 2 * Tp.

```
Hence, to ensure tighter bound, to detect the collision completely,
  Tt > >= 2 * Tp
```

This is the maximum collision time that a system can take to detect if the collision was of its own data.

**What should be the minimum length of the packet to be transmitted?** Transmission Time = Tt = Length of the packet/ Bandwidth of the link [Number of bits transmitted by sender per second] Substituting above, we get, Length of the packet/ Bandwidth of the link>= 2 * Tp

```
Length of the packet >= 2 * Tp * Bandwidth of the link
```

Padding
 helps in the cases where we do not have such long packets. We can pad 
extra characters to the end of our data to satisfy the above condition.

Read next – [Efficiency of CSMA/CD](https://www.geeksforgeeks.org/computer-network-efficiency-csmacd/)
*** Efficiency of CSMA,,CD
**Prerequisite –** [Introduction to Ethernet](https://www.geeksforgeeks.org/local-area-network-lan-technologies/), [Basics of CSMA/ CD](https://www.geeksforgeeks.org/computer-networks-gate-notes-set-1-data-link-layer/) **Carrier sense multiple access with collision detection (CSMA/CD) –**
 The CSMA method does not tell us what to do in case there is a 
collision. Carrier sense multiple access with collision detection 
(CSMA/CD) adds to the CSMA algorithm to deal with the collision. In 
CSMA/CD, the size of a frame must be large enough so that collision can 
be detected by the sender while sending the frame. So, the frame 
transmission delay must be at least *two times* the maximum 
propagation delay. Assume some station transmitted data packet and 
successfully get to the destination but it is just the *Best Case*, so we have to take the *Worst Case*
 scenario in which there will be contention slots. Contention slots are 
those slots that are not able to transmit their journey due to the 
collision. Suppose A station transmitted data but collide and the 
worst-case time wasted is **2Tp** and then some station B found out a way to transmit the data so it took (As shown in Figure)

```
Tp ( propagation delay) + Tt(transmission time)
```

Now we don’t know how many contention slots, so we consider the worst-case to be of **n** contention slots.

```
Efficiency = Tt / ( C*2*Tp + Tt + Tp)
Tt ? transmission time
Tp ? propagation time
C  ? number of collision
```

!https://media.geeksforgeeks.org/wp-content/uploads/CSMA_CD-Diagram.png

In CSMA/CD, for success, only 1 station should transmit while others 
shouldn’t. Let p be the probability to transmit data successfully.

```
P(success) = nC1 * p * (1-p)n-1 (by using Binomial distribution)
```

For max P(success), differentiate with respect to p and equate to zero (to get maxima and minima).

```
We get P(max) = 1/e
```

Number of times we need to try before getting 1st success

```
1/P(MAX) = 1/(1/e) = e
```

Here number of times we need to try (C) = e. Put a = Tt/Tp and divide by T in Efficiency = Tt / (C* 2 * Tp + Tt + Tp) We get,

```
Efficiency = 1/(e*2a + 1 + a)
a = Tp/Tt
e = 2.72

Now
Efficiency = 1/( 1 + 6.44a)
```

**Further Analysis of Efficiency :**

```
Efficiency = 1/ (1 + 6.44a)

           = 1/ {1 + 6.44(Tp/Tt)}

           = 1/ {1 + 6.44((distance/speed)/(packet length/Bandwidth))}

           = 1/ {1+ 6.44 ((distance * bandwidth)/ (speed*packet length))}
```

From this derivation, we can conclude many relations :

- If distance increases, the efficiency of CSMA decreases.
- CSMA is not suitable for long-distance networks like WAN but works optimally for LAN.
- If the length of the packet is bigger, the efficiency of CSMA also increases; but the maximum limit for length is 1500 Bytes.
- Transmission Time >= 2*Propagation Time

**GATE CS Corner Questions**
 Practicing the following questions will help you test your knowledge. 
All questions have been asked in GATE in previous years or in GATE Mock 
Tests. It is highly recommended that you practice them.

1. [GATE CS 2003, Question 90](https://www.geeksforgeeks.org/gate-gate-cs-2003-question-83/)
2. [GATE CS 2015 (Set 3), Question 65](https://www.geeksforgeeks.org/gate-gate-cs-2015-set-3-question-16/)
3. [GATE IT 2005, Question 27](https://www.geeksforgeeks.org/gate-gate-it-2005-question-27/)
4. [GATE IT 2005, Question 71](https://www.geeksforgeeks.org/gate-gate-it-2005-question-71/)
5. [GATE CS 2016 (Set 2), Question 63](https://www.geeksforgeeks.org/gate-gate-cs-2016-set-2-question-63/)
6. [GATE IT 2008, Question 63](https://www.geeksforgeeks.org/gate-gate-it-2008-question-63/)
*** Efficiency Of Token Ring
**Token Ring**
 protocol is a communication protocol used in Local Area Network (LAN). 
In a token ring protocol, the topology of the network is used to define 
the order in which stations send. The stations are connected to one 
another in a single ring. It uses a special three-byte frame called a **“token”** that travels around a ring. It makes use of [Token Passing](https://www.geeksforgeeks.org/computer-network-controlled-access-protocols/)
 controlled access mechanism. Frames are also transmitted in the 
direction of the token. This way they will circulate around the ring and
 reach the station which is the destination.

!https://media.geeksforgeeks.org/wp-content/uploads/token-1.png

**Ring Latency –** The time taken by a single bit to travel around the ring is known as ring latency.

!https://media.geeksforgeeks.org/wp-content/uploads/1a-300x169.png

Where, d = length of the ring v = velocity of data in ring N = no. of stations in ring b = time taken by each station to hold the bit before transmitting it (bit delay)

**Converting N*b into sec –** 

```
RL = d/v + (N*b)/B  (B – bandwidth)
```

**Converting d/v into bits –** 

```
RL = (d/v)*B + N*b  (B – bandwidth)
```

**Cycle Time –** The time taken by the token to complete one revolution of the ring is known as cycle time. 

```
Cycle time = Tp + (THT*N)
Where, THT - Token Holding Time
Tp - Propagation delay(d/v)
```

**Token Holding Time (THT) –** The
 maximum time a token frame can be held by a station is known as THT, by
 default it is set to 10msec. No station can hold the token beyond THT.

**Calculating THT:**

!https://media.geeksforgeeks.org/wp-content/uploads/1b.png

**1. Delayed token reinsertion (DTR) –** 

- In this, the sender transmit the data packet and waits till the time the
whole packet takes the round trip of the ring and return to it. When the whole packet is received by the sender, then it releases the token
- There is only one packet in the ring at an instance
- More reliable than ETR

!https://media.geeksforgeeks.org/wp-content/uploads/1c.png

In this case, 

```
THT = Tt + RL
    = Tt + Tp + N*b   (In most cases, bit delay is 0)
So, THT = Tt + Tp
 where Tt = transmission delay
       Tp = propagation delay
```

**2. Early token reinsertion (ETR) –** 

- Sender does not wait for the data packet to complete revolution before
releasing the token. Token is released as soon as the data is
transmitted
- Multiple packets present in the ring
- Less reliable than DTR

!https://media.geeksforgeeks.org/wp-content/uploads/1d-1.png

**Station 1:** Receives the token and transmits data D1 and then, releases the token. **Station 2:** Receives D1 (puts it onto the other end) and the token and then, transmits data D2 and releases the token. **Station 3:** Receives D1 –> transmits D1 Receives D2 –> transmits D2 Receives token –> transmits D3 Releases token. **Station 4:** Receives D1 –> transmits D1 Receives D2 –> transmits D2 Receives D3 –> transmits D3 Receives token –> transmits D4 Releases token.

**Station 1:** Receives D1 –> discards D1 as D1 has completed its journey Receives D2 –> transmits D2 Receives D3 –> transmits D3 Receives D4 –> transmits D4 Receives token –> transmits D1(new) Releases token. (and the cycle continues so on…..)

In this case, 

```
 THT = Tt
 where Tt = transmission delay
       Tp = propagation delay
```

**Efficiency –** Efficiency, e = useful time/ total time

useful time = N*Tt total time = cycle time = Tp + (THT*N)

So, e = (N*Tt)/(Tp + (THT*N))

**1. Delayed token reinsertion –** In this case, THT = Tt + Tp So, cycle time = Tp + N*(Tt + Tp) 

```
Efficiency, e = (N*Tt)/(Tp + N*(Tt + Tp))               = 1/(1 + a*((N+1)/N))where a = Tp/Tt
```

**2. Early token reinsertion –** In this case, THT = Tt So, cycle time = Tp + N*(Tt) 

```
Efficiency, e = (N*Tt)/(Tp + N*(Tt))               = 1/(1 + a*(1/N))where a = Tp/Tt
```

**GATE Practice Questions –** 

1. [GATE-CS-2014-(Set-1) | Question 65](https://www.geeksforgeeks.org/gate-gate-cs-2014-set-1-question-36/)
2. [GATE-CS-2014-(Set-2) | Question 35](https://www.geeksforgeeks.org/gate-gate-cs-2014-set-2-question-35/)
3. [GATE IT 2007 | Question 72](https://www.geeksforgeeks.org/gate-gate-it-2007-question-72/)
4. [GATE IT 2007 | Question 73](https://www.geeksforgeeks.org/gate-gate-it-2007-question-73/)
5. [GATE-IT-2004 | Question 82](https://www.geeksforgeeks.org/gate-gate-it-2004-question-82/)
*** Error Detection in Computer Networks
**Error**A
 condition when the receiver’s information does not match with the 
sender’s information. During transmission, digital signals suffer from 
noise that can introduce errors in the binary bits travelling from 
sender to receiver. That means a 0 bit may change to 1 or a 1 bit may 
change to 0. **Error Detecting Codes (Implemented either at Data link layer or Transport Layer of OSI Model)**Whenever
 a message is transmitted, it may get scrambled by noise or data may get
 corrupted. To avoid this, we use error-detecting codes which are 
additional data added to a given digital message to help us detect if 
any error has occurred during transmission of the message. Basic
 approach used for error detection is the use of redundancy bits, where 
additional bits are added to facilitate detection of errors.

Some popular techniques for error detection are:1. Simple Parity check2. Two-dimensional Parity check3. Checksum4. Cyclic redundancy check

**1. Simple Parity check**Blocks of data from the source are subjected to a check bit or parity bit generator form, where a parity of :

- 1 is added to the block if it contains odd number of 1’s, and
- 0 is added if it contains even number of 1’s

This scheme makes the total number of 1’s even, that is why it is called even parity checking.

!https://media.geeksforgeeks.org/wp-content/uploads/detect12.jpg

**2. Two-dimensional Parity check**Parity
 check bits are calculated for each row, which is equivalent to a simple
 parity check bit. Parity check bits are also calculated for all 
columns, then both are sent along with the data. At the receiving end 
these are compared with the parity bits calculated on the received data.

!https://media.geeksforgeeks.org/wp-content/uploads/detect11.jpg

**3. Checksum**

- In checksum error detection scheme, the data is divided into k segments each of m bits.
- In the sender’s end the segments are added using 1’s complement arithmetic to get the sum. The sum is complemented to get the checksum.
- The checksum segment is sent along with the data segments.
- At the receiver’s end, all received segments are added using 1’s complement arithmetic to get the sum. The sum is complemented.
- If the result is zero, the received data is accepted; otherwise discarded.

!https://media.geeksforgeeks.org/wp-content/uploads/detect13.jpg

**4. Cyclic redundancy check (CRC)**

- Unlike checksum scheme, which is based on addition, CRC is based on binary division.
- In CRC, a sequence of redundant bits, called cyclic redundancy check bits, are appended to the end of data unit so that the resulting data unit
becomes exactly divisible by a second, predetermined binary number.
- At the destination, the incoming data unit is divided by the same number.
If at this step there is no remainder, the data unit is assumed to be
correct and is therefore accepted.
- A remainder indicates that the data unit has been damaged in transit and therefore must be rejected.

**Example :** Previous year GATE questions based on error detection:[GATE CS 2009 Question 48](https://www.geeksforgeeks.org/gate-gate-cs-2009-question-48/)[GATE CS 2007 Question 68](https://www.geeksforgeeks.org/gate-gate-cs-2007-question-68/)

!https://media.geeksforgeeks.org/wp-content/uploads/detect14.jpg

!https://media.geeksforgeeks.org/wp-content/uploads/detect15.jpg
*** Stop and Wait ARQ
### Characteristics

- Used in Connection-oriented communication.
- It offers error and flows control
- It is used in Data Link and Transport Layers
- Stop and Wait for ARQ mainly implements the Sliding Window Protocol concept with Window Size 1

### Useful Terms:

- **Propagation Delay:** Amount of time taken by a packet to make a physical journey from one router to another router.

Propagation Delay = (Distance between routers) / (Velocity of propagation)

- RoundTripTime (**RTT**) = 2* Propagation Delay
- TimeOut (**TO**) = 2* RTT
- Time To Live (**TTL**) = 2* TimeOut. (Maximum TTL is 180 seconds)

### Simple Stop and Wait

### Sender:

Rule 1) Send one data packet at a time. Rule 2) Send the next packet only after receiving acknowledgement for the previous. 

### Receiver:

Rule 1) Send acknowledgement after receiving and consuming a data packet. Rule 2) After consuming packet acknowledgement need to be sent (Flow Control)

!https://media.geeksforgeeks.org/wp-content/uploads/Stop-and-Wait-ARQ.png

## Problems :

**1. Lost Data** 

!https://media.geeksforgeeks.org/wp-content/uploads/Stop-and-Wait-ARQ-2.png

**2. Lost Acknowledgement:** 

!https://media.geeksforgeeks.org/wp-content/uploads/Stop-and-Wait-ARQ-3.png

**3. Delayed Acknowledgement/Data:**
 After a timeout on the sender side, a long-delayed acknowledgement 
might be wrongly considered as acknowledgement of some other recent 
packet.

### Stop and Wait for ARQ (Automatic Repeat Request)

The
 above 3 problems are resolved by Stop and Wait for ARQ (Automatic 
Repeat Request) that does both error control and flow control. 

!https://media.geeksforgeeks.org/wp-content/uploads/Stop-and-Wait-ARQ-4.png

**1. Time Out:** 

!https://media.geeksforgeeks.org/wp-content/uploads/Stop-and-Wait-ARQ-5.png

**2. Sequence Number (Data)** 

!https://media.geeksforgeeks.org/wp-content/uploads/Stop-and-Wait-ARQ-6.png

**3. Delayed Acknowledgement:** This is resolved by introducing sequence numbers for acknowledgement also. 

### Working of Stop and Wait for ARQ:

1) Sender A sends a data frame or packet with sequence number 0. 2)
 Receiver B, after receiving the data frame, sends an acknowledgement 
with sequence number 1 (the sequence number of the next expected data 
frame or packet) There is only a one-bit sequence number that implies that both sender and receiver have a buffer for one frame or packet only.

!https://media.geeksforgeeks.org/wp-content/uploads/Stop-and-Wait-ARQ-7.png

### Characteristics of Stop and Wait ARQ:

- It uses a link between sender and receiver as a half-duplex link
- Throughput = 1 Data packet/frame per RTT
- If the Bandwidth*Delay product is very high, then they stop and wait for
protocol if it is not so useful. The sender has to keep waiting for
acknowledgements before sending the processed next packet.
- It is an example of “**Closed Loop OR connection-oriented** “ protocols
- It is a special category of SWP where its window size is 1
- Irrespective of the number of packets sender is having stop and wait for protocol requires only 2 sequence numbers 0 and 1

The
 Stop and Wait ARQ solves the main three problems but may cause big 
performance issues as the sender always waits for acknowledgement even 
if it has the next packet ready to send. Consider a situation where you 
have a high bandwidth connection and propagation delay is also high (you
 are connected to some server in some other country through a high-speed
 connection). To solve this problem, we can send more than one packet at
 a time with a larger sequence number. We will be discussing these 
protocols in the next articles.

So Stop and Wait ARQ may work 
fine where propagation delay is very less for example LAN connections 
but performs badly for distant connections like satellite connections.
*** Sliding Window Protocol | Set 1 (Sender Side)
Prerequisite : [Stop and Wait ARQ](https://www.geeksforgeeks.org/stop-and-wait-arq/)

The
 Stop and Wait ARQ offers error and flow control, but may cause big 
performance issues as sender always waits for acknowledgement even if it
 has next packet ready to send. Consider a situation where you have a 
high bandwidth connection and propagation delay is also high (you are 
connected to some server in some other country through a high-speed 
connection), you can’t use this full speed due to limitations of stop 
and wait.

Sliding Window protocol handles this efficiency issue by
 sending more than one packet at a time with a larger sequence number. 
The idea is same as pipelining in architecture.

## **Few Terminologies :**

**Transmission Delay (Tt)**
 – Time to transmit the packet from host to the outgoing link. If B is 
the Bandwidth of the link and D is the Data Size to transmit

```
    Tt = D/B
```

**Propagation Delay (Tp)**
 – It is the time taken by the first bit transferred by the host onto 
the outgoing link to reach the destination. It depends on the distance d
 and the wave propagation speed s (depends on the characteristics of the
 medium).

```
   Tp = d/s
```

**Efficiency** – It is defined as the ratio of total useful time to the total cycle time of a packet. For stop and wait protocol,

```
Total cycle time = Tt(data) + Tp(data) +
                    Tt(acknowledgement) + Tp(acknowledgement)
              =  Tt(data) + Tp(data) + Tp(acknowledgement)
         =   Tt + 2*Tp

```

Since acknowledgements are very less in size, their transmission delay can be neglected.

```
Efficiency = Useful Time / Total Cycle Time
           = Tt/(Tt + 2*Tp) (For Stop and Wait)
           = 1/(1+2a)  [ Using a = Tp/Tt ]

```

**Effective Bandwidth(EB) or Throughput** – Number of bits sent per second.

```
EB = Data Size(D) / Total Cycle time(Tt + 2*Tp)
Multiplying and dividing by Bandwidth (B),
       =  (1/(1+2a)) * B   [ Using a = Tp/Tt ]
       =  Efficiency * Bandwidth

```

**Capacity of link** – If a channel is Full 
Duplex, then bits can be transferred in both the directions and without 
any collisions. Number of bits a channel/Link can hold at maximum is its
 capacity.

```
 Capacity = Bandwidth(B) * Propagation(Tp)

 For Full Duplex channels,
 Capacity = 2*Bandwidth(B) * Propagation(Tp)

```

## Concept Of Pipelining

In Stop and Wait protocol, only 1
 packet is transmitted onto the link and then sender waits for 
acknowledgement from the receiver. The problem in this setup is that 
efficiency is very less as we are not filling the channel with more 
packets after 1st packet has been put onto the link. Within the total 
cycle time of Tt + 2*Tp units, we will now calculate the maximum number 
of packets that sender can transmit on the link before getting an 
acknowledgement.

```
 In Tt units ----> 1 packet is Transmitted.
 In 1 units  ----> 1/Tt packet can be Transmitted.
 In  Tt + 2*Tp units ----->  (Tt + 2*Tp)/Tt
                             packets can be Transmitted
                ------>  1 + 2a  [Using a = Tp/Tt]

```

Maximum packets That can be Transmitted in total cycle time = 1+2*a

Let me explain now with the help of an example.

Consider Tt = 1ms, Tp = 1.5ms.

In
 the picture given below, after sender has transmitted packet 0, it will
 immediately transmit packets 1, 2, 3. Acknowledgement for 0 will arrive
 after 2*1.5 = 3ms. In Stop and Wait, in time 1 + 2*1.5 = 4ms, we were 
transferring one packet only. Here we keep a **window of packets that we have transmitted but not yet acknowledged**.

!https://media.geeksforgeeks.org/wp-content/cdn-uploads/Sliding_Window_Protocol_1.jpg

After
 we have received the Ack for packet 0, window slides and the next 
packet can be assigned sequence number 0. We reuse the sequence numbers 
which we have acknowledged so that header size can be kept minimum as 
shown in the diagram given below.

!https://media.geeksforgeeks.org/wp-content/cdn-uploads/Sliding_Window_Protocol_2.jpg

## Minimum Number Of Bits For Sender window (Very Important For GATE)

As we have seen above,

```
 Maximum window size = 1 + 2*a    where a = Tp/Tt

 Minimum sequence numbers required = 1 + 2*a.
```

All the packets 
in the current window will be given a sequence number. Number of bits 
required to represent the sender window = ceil(log2(1+2*a)).

But 
sometimes number of bits in the protocol headers is pre-defined. Size of
 sequence number field in header will also determine the maximum number 
of packets that we can send in total cycle time. If N is the size of 
sequence number field in the header in bits, then we can have 2N sequence numbers.

Window Size ws = min(1+2*a, 2N)

If you want to calculate minimum bits required to represent sequence numbers/sender window, it will be **ceil(log2(ws))**.
*** Sliding Window Protocol | Set 2 (Receiver Side)
Please refer this as a prerequisite article: [Sliding Window Protocol (sender side)| set 1](https://www.geeksforgeeks.org/sliding-window-protocol-set-1/)

**Sliding Window Protocol**
 is actually a theoretical concept in which we have only talked about 
what should be the sender window size (1+2a) in order to increase the 
efficiency of stop and wait arq. Now we will talk about the practical 
implementations in which we take care of what should be the size of 
receiver window. Practically it is implemented in two protocols namely :

1. Go Back N (GBN)
2. Selective Repeat (SR)

In
 this article, we will explain you about the first protocol which is GBN
 in terms of three main characteristic features and in the next part we 
will be discussing SR as well as comparison of both these protocols

### Go Back N (GBN) Protocol

The three main characteristic features of GBN are:

1. **Sender Window Size (WS)**It is N itself. If we say the protocol is GB10, then Ws = 10. N should be
always greater than 1 in order to implement pipelining. For N = 1, it
reduces to Stop and Wait protocol.
    
    ```
    Efficiency Of GBN = N/(1+2a)
    where a = Tp/Tt
    ```
    
    If B is the bandwidth of the channel, then
    
    ```
    Effective Bandwidth or Throughput
     = Efficiency * Bandwidth
     = (N/(1+2a)) * B
    ```
    
2. **Receiver Window Size (WR)**
    
    ```
    WR is always 1 in GBN.
    ```
    
    Now
     what exactly happens in GBN, we will explain with a help of example. 
    Consider the diagram given below. We have sender window size of 4. 
    Assume that we have lots of sequence numbers just for the sake of 
    explanation. Now the sender has sent the packets 0, 1, 2 and 3. After 
    acknowledging the packets 0 and 1, receiver is now expecting packet 2 
    and sender window has also slided to further transmit the packets 4 and 
    5. Now suppose the packet 2 is lost in the network, Receiver will 
    discard all the packets which sender has transmitted after packet 2 as 
    it is expecting sequence number of 2. On the sender side for every 
    packet send there is a time out timer which will expire for packet 
    number 2. Now from the last transmitted packet 5 sender will go back to 
    the packet number 2 in the current window and transmit all the packets 
    till packet number 5. That’s why it is called Go Back N. Go back means 
    sender has to go back N places from the last transmitted packet in the 
    unacknowledged window and not from the point where the packet is lost.
    
    !https://www.geeksforgeeks.org/wp-content/uploads/Sliding_SET_2-1.jpg
    
3. **Acknowledgements**There are 2 kinds of acknowledgements namely:
    - **Cumulative Ack**: One acknowledgement is used for many packets. The main advantage is
    traffic is less. A disadvantage is less reliability as if one ack is the loss that would mean that all the packets sent are lost.
    - **Independent Ack**: If every packet is going to get acknowledgement independently.
    Reliability is high here but a disadvantage is that traffic is also high since for every packet we are receiving independent ack.
    
    !https://media.geeksforgeeks.org/wp-content/cdn-uploads/Sliding_SET_2-2.jpg
    
    **GBN uses Cumulative Acknowledgement**.
     At the receiver side, it starts a acknowledgement timer whenever 
    receiver receives any packet which is fixed and when it expires, it is 
    going to send a cumulative Ack for the number of packets received in 
    that interval of timer. If receiver has received N packets, then the 
    Acknowledgement number will be N+1. Important point is Acknowledgement 
    timer will not start after the expiry of first timer but after receiver 
    has received a packet.*Time out timer at the sender side should be greater than Acknowledgement timer*.
    

**Relationship Between Window Sizes and Sequence Numbers**We already know that sequence numbers required should always be equal to the size of window in any sliding window protocol.

```
Minimum sequence numbers required in GBN = N + 1
```

```
Bits Required in GBN = ceil(log2 (N + 1))

The extra 1 is required in order to
avoid the problem of duplicate packets
as described below.
```

**Example: Consider an example of GB4.**

- Sender window size is 4 therefore we require a minimum of 4 sequence numbers to label each packet in the window.
- Now suppose receiver has received all the packets(0, 1, 2 and 3 sent by
sender) and hence is now waiting for packet number 0 again (We can not
use 4 here as we have only 4 sequence numbers available since N = 4).
- Now suppose the cumulative ack for the above 4 packets is lost in the network.
- On sender side, there will be timeout for packet 0 and hence all the 4 packets will be transmitted again.
- Problem now is receiver is waiting for new set of packets which should have
started from 0 but now it will receive the duplicate copies of the
previously accepted packets.
- In order to avoid this, we need one extra sequence number.
- Now the receiver could easily reject all the duplicate packets which were
starting from 0 because now it will be waiting for packet number 4 (We
have added an extra sequence number now).

This is explained with the help of the illustrations below.

**Trying with Sequence numbers 4.**

!https://www.geeksforgeeks.org/wp-content/uploads/Sliding_SET_2-3.jpg

**Now Trying with one extra Sequence Number.**

!https://www.geeksforgeeks.org/wp-content/uploads/Sliding_SET_2-4.jpg

Now it is clear as to why we need an extra 1 bit in the GBN protocol.

In the next article, we will explain Selective repeat and comparison between the 2 protocols.
*** Sliding Window Protocol | Set 3 (Selective Repeat)
Prerequisite : [Sliding Window Protocol – Set 1 (Sender Side)](https://www.geeksforgeeks.org/sliding-window-protocol-set-1/), [Set 2 (Receiver Side)](https://www.geeksforgeeks.org/sliding-window-protocol-set-2-receiver-side/) **Why Selective Repeat Protocol?**
 The go-back-n protocol works well if errors are less, but if the line 
is poor it wastes a lot of bandwidth on retransmitted frames. An 
alternative strategy, the selective repeat protocol, is to allow the 
receiver to accept and buffer the frames following a damaged or lost 
one. Selective Repeat attempts to retransmit only those packets that are
 actually lost (due to errors) :

- Receiver must be able to accept packets out of order.
- Since receiver must release packets to higher layer in order, the receiver must be able to buffer some packets.

**Retransmission requests :**

- **Implicit –** The receiver acknowledges every good packet, packets that are not ACKed before a time-out are assumed lost or in error.Notice that this
approach must be used to be sure that every packet is eventually
received.
- **Explicit –** An explicit NAK (selective reject) can request retransmission of just one packet. This approach
can expedite the retransmission but is not strictly needed.
- One or both approaches are used in practice.

**Selective Repeat Protocol (SRP) :**
 This protocol(SRP) is mostly identical to GBN protocol, except that 
buffers are used and the receiver, and the sender, each maintains a 
window of size. SRP works better when the link is very unreliable. 
Because in this case, retransmission tends to happen more frequently, 
selectively retransmitting frames is more efficient than retransmitting 
all of them. SRP also requires full-duplex link. backward 
acknowledgements are also in progress.

- Sender’s Windows ( Ws) = Receiver’s Windows ( Wr).
- Window size should be less than or equal to half the sequence number in SR
protocol. This is to avoid packets being recognized incorrectly. If the
size of the window is greater than half the sequence number space, then
if an ACK is lost, the sender may send new packets that the receiver
believes are retransmissions.
- Sender can transmit new packets as long as their number is with W of all unACKed packets.
- Sender retransmit un-ACKed packets after a timeout – Or upon a NAK if NAK is employed.
- Receiver ACKs all correct packets.
- Receiver stores correct packets until they can be delivered in order to the higher layer.
- In Selective Repeat ARQ, the size of the sender and receiver window must be at most one-half of 2^m.

!https://media.geeksforgeeks.org/wp-content/uploads/Sliding-Window-Protocol.jpg

**Figure –**
 the sender only retransmits frames, for which a NAK is 
receivedEfficiency of Selective Repeat Protocol (SRP) is same as 
GO-Back-N’s efficiency :

```
Efficiency = N/(1+2a)
Where a = Propagation delay / Transmission delay
Buffers = N + N
Sequence number  = N(sender side)  + N  ( Receiver Side)

```
*** Program to remotely Power On a PC over the internet using the Wake-on-LAN protocol
[Wake-on-LAN (WoL)](https://en.wikipedia.org/wiki/Wake-on-LAN) is
 an Ethernet or token ring computer networking standard that allows a 
computer to be turned on or awakened by a network message.

- The message is usually sent to the target computer by a program executed on a device connected to the same local area network, such as a
smartphone.
- It is also possible to initiate the message from another network by using subnet-directed broadcasts or a WOL gateway service.
- Equivalent terms include wake on WAN, remote wake-up, power on by LAN, power up by LAN, resume by LAN, resume on LAN and wake up on LAN.

**Principle of operation**

- Wake-on-LAN (“WOL”) is implemented using a specially designed packet called a magic packet, which is sent to all computers in a network, among them the
computer to be awakened.
- The magic packet contains the MAC
address of the destination computer, an identifying number built into
each network interface card (“NIC”) or other ethernet devices in a
computer, that enables it to be uniquely recognized and addressed on a
network.
- Powered-down or turned-off computers capable of
Wake-on-LAN will contain network devices able to “listen” to incoming
packets in low-power mode while the system is powered down.
- If a magic packet is received that is directed to the device’s MAC address,
the NIC signals the computer’s power supply or motherboard to initiate
system wake-up, much in the same way as pressing the power button would
do.
- The magic packet is sent on the data link layer (layer 2 in
the OSI model) and when sent, is broadcast to all attached devices on a
given network, using the network broadcast address; the IP-address
(layer 3 in the OSI model) is not used.

In order for 
Wake-on-LAN to work, parts of the network interface need to stay on. 
This consumes a small amount of standby power, much less than normal 
operating power. Disabling wake-on-LAN when not needed can therefore 
vary slightly reduce power consumption on computers that are switched 
off but still plugged into a power socket.

**Magic Packet Structure** The
 magic packet is a broadcast frame containing anywhere within its 
payload 6 bytes of all 255 (FF FF FF FF FF FF in hexadecimal), followed 
by sixteen repetitions of the target computer’s 48-bit MAC address, for a
 total of 102 bytes. Since the magic packet is only scanned for the 
string above, and not actually parsed by a full protocol stack, it may 
be sent as any network- and transport-layer protocol, although it is 
typically sent as a UDP datagram to port 0, 7, or 9, or directly over 
Ethernet as EtherType 0x0842.

**A standard magic packet has the following basic limitations:**

1. Requires destination computer MAC address (also may require a SecureOn password).
2. Do not provide a delivery confirmation.
3. May not work outside of the local network.
4. Requires hardware support of Wake-On-LAN on the destination computer.
5. Most 802.11 wireless interfaces do not maintain a link in low power states and cannot receive a magic packet.

The
 Wake-on-LAN implementation is designed to be very simple and to be 
quickly processed by the circuitry present on the network interface card
 with minimal power requirement. Because Wake-on-LAN operates below the 
IP protocol layer the MAC address is required and makes IP addresses and
 DNS names meaningless.

`// C program to remotely Power On a PC over the`

`// internet using the Wake-on-LAN protocol.`

`#include <stdio.h>`

`#include <stdlib.h>`

`#include <unistd.h>`

`#include <sys/socket.h>`

`#include <netinet/in.h>`

`#include <arpa/inet.h>`

`#include <string.h>`

`#include <sys/types.h>`

`int` `main()`

`{`

`int` `i;`

`unsigned char` `toSend[102],mac[6];`

`struct` `sockaddr_in udpClient, udpServer;`

`int` `broadcast = 1 ;`

`// UDP Socket creation`

`int` `udpSocket = socket(AF_INET, SOCK_DGRAM, 0);`

`// Manipulating the Socket`

`if` `(setsockopt(udpSocket, SOL_SOCKET, SO_BROADCAST,`

`&broadcast, sizeof` `broadcast) == -1)`

`{`

`perror("setsockopt (SO_BROADCAST)");`

`exit(EXIT_FAILURE);`

`}`

`udpClient.sin_family = AF_INET;`

`udpClient.sin_addr.s_addr = INADDR_ANY;`

`udpClient.sin_port = 0;`

`//Binding the socket`

`bind(udpSocket, (struct` `sockaddr*)&udpClient, sizeof(udpClient));`

`for` `(i=0; i<6; i++)`

`toSend[i] = 0xFF;`

`// Let the MAC Address be ab:cd:ef:gh:ij:kl`

`mac[0] = 0xab;  // 1st octet of the MAC Address`

`mac[1] = 0xcd;  // 2nd octet of the MAC Address`

`mac[2] = 0xef;  // 3rd octet of the MAC Address`

`mac[3] = 0xgh;  // 4th octet of the MAC Address`

`mac[4] = 0xij;  // 5th octet of the MAC Address`

`mac[5] = 0xkl;  // 6th octet of the MAC Address`

`for` `(i=1; i<=16; i++)`

`memcpy(&toSend[i*6], &mac, 6*sizeof(unsigned char));`

`udpServer.sin_family = AF_INET;`

`// Broadcast address`

`udpServer.sin_addr.s_addr = inet_addr("10.89.255.255");`

`udpServer.sin_port = htons(9);`

`sendto(udpSocket, &toSend, sizeof(unsigned char) * 102, 0,`

`(struct` `sockaddr*)&udpServer, sizeof(udpServer));`

`return` `0;`

`}`

Output:

```
This program will power on the switched-off PC
whose MAC Address is used in this program (the
PC and the Host computer must be connected over
LAN).
```

This article is contributed by **[Kishlay Verma](https://www.linkedin.com/in/kishlayverma/)**. If you like GeeksforGeeks and would like to contribute, you can also write an article using [write.geeksforgeeks.org](https://write.geeksforgeeks.org/)
 or mail your article to review-team@geeksforgeeks.org. See your article
 appearing on the GeeksforGeeks main page and help other Geeks.

**Reference :** https://en.wikipedia.org/wiki/Wake-on-LANPlease write comments if you find anything incorrect, or you want to share more information about the topic discussed above.
*** Program to calculate the Round Trip Time (RTT)
**Round trip time(RTT)**
 is the length of time it takes for a signal to be sent plus the length 
of time it takes for an acknowledgment of that signal to be received. 
This time, therefore, consists of the propagation times between the 
two-point of the signal.

On
 the Internet, an end-user can determine the RTT to and from an 
IP(Internet Protocol) address by pinging that address. The result 
depends on various factors:-

- The data rate transfer of the source’s internet connection.
- The nature of transmission medium.
- The physical distance between source and destination.
- The number of nodes between source and destination.
- The amount of traffic on the LAN(Local Area Network) to which end-user is connected.
- The number of other requests being handled by intermediate nodes and the remote server.
- The speed with which the intermediate node and the remote server function.
- The presence of Interference in the circuit.

Examples:

```
Input : www.geeksforgeeks.org
Output : Time in seconds : 0.212174892426

Input : www.cricbuzz.com
Output : Time in seconds : 0.55425786972
```

[Recommended: Please try your approach on ***{IDE}*** first, before moving on to the solution.](https://ide.geeksforgeeks.org/)

`# Python program to calculate RTT`

`import` `time`

`import` `requests`

`# Function to calculate the RTT`

`def` `RTT(url):`

`# time when the signal is sent`

`t1 =` `time.time()`

`r =` `requests.get(url)`

`# time when acknowledgement of signal`

`# is received`

`t2 =` `time.time()`

`# total time taken`

`tim =` `str(t2-t1)`

`print("Time in seconds :"` `+` `tim)`

`# driver program`

`# url address`

`url =` `"[http://www.google.com](http://www.google.com/)"`

`RTT(url)`

**Output:**

```
  Time in seconds :0.0579478740692
```
*** Introduction of MAC Address in Computer Network
In
 order to communicate or transfer the data from one computer to another 
computer, we need some address. In Computer Network various types of 
addresses are introduced; each works at a different layer. Media Access 
Control Address is a physical address that works at the Data Link Layer.
 In this article, we will discuss about addressing DLL, which is MAC 
Address.

### Media Access Control (MAC) Address –

MAC Addresses are unique **48-bits** hardware number of a computer, which is embedded into a network card (known as a **Network Interface Card**) during the time of manufacturing. MAC Address is also known as the **Physical Address** of a network device. In IEEE 802 standard, Data Link Layer is divided into two sublayers –

1. Logical Link Control(LLC) Sublayer
2. Media Access Control(MAC) Sublayer

MAC
 address is used by the Media Access Control (MAC) sublayer of the 
Data-Link Layer. MAC Address is worldwide unique since millions of 
network devices exist and we need to uniquely identify each.

!https://media.geeksforgeeks.org/wp-content/uploads/mac.jpg

### Format of MAC Address –

MAC
 Address is a 12-digit hexadecimal number (6-Byte binary number), which 
is mostly represented by Colon-Hexadecimal notation. The First 6-digits 
(say 00:40:96) of MAC Address identifies the manufacturer, called OUI (**Organizational Unique Identifier**). IEEE [Registration Authority Committee](http://standards.ieee.org/develop/regauth/index.html) assigns these MAC prefixes to its registered vendors.

Here are [some OUI](http://standards-oui.ieee.org/oui/oui.txt) of well-known manufacturers :

```
CC:46:D6 - Cisco
3C:5A:B4 - Google, Inc.
3C:D9:2B - Hewlett Packard
00:9A:CD - HUAWEI TECHNOLOGIES CO.,LTD
```

The rightmost six digits represent **Network Interface Controller**, which is assigned by the manufacturer.

As
 discussed above, the MAC address is represented by Colon-Hexadecimal 
notation. But this is just a conversion, not mandatory. MAC address can 
be represented using any of the following formats:

!https://media.geeksforgeeks.org/wp-content/uploads/mac-notation.jpg

**Note:** Colon-Hexadecimal notation is used by *Linux OS* and Period-separated Hexadecimal notation is used by *Cisco Systems*.

### How to find MAC address –

```
Command for UNIX/Linux -ifconfig -aip link list ip address show

Command forWindows OS - ipconfig /all

MacOS - TCP/IP Control Panel
```

**Note –**
 LAN technologies like Token Ring, and Ethernet use MAC Addresses as 
their Physical address but there are some networks (AppleTalk) that do 
not use MAC addresses.

### Types of MAC Address:

**1. Unicast:** A
 Unicast addressed frame is only sent out to the interface leading to a 
specific NIC. If the LSB (least significant bit) of the first octet of 
an address is set to zero, the frame is meant to reach only one 
receiving NIC. MAC Address of source machine is always Unicast.

!https://media.geeksforgeeks.org/wp-content/uploads/unicast.jpg

**2. Multicast:** The
 multicast address allows the source to send a frame to a group of 
devices. In Layer-2 (Ethernet) Multicast address, LSB (least significant
 bit) of the first octet of an address is set to one. IEEE has allocated
 the address block 01-80-C2-xx-xx-xx (01-80-C2-00-00-00 to 
01-80-C2-FF-FF-FF) for group addresses for use by standard protocols.

!https://media.geeksforgeeks.org/wp-content/uploads/MULTICAST.jpg

**3. Broadcast:** Similar
 to Network Layer, Broadcast is also possible on the underlying layer( 
Data Link Layer). Ethernet frames with ones in all bits of the 
destination address (FF-FF-FF-FF-FF-FF) are referred to as the broadcast
 addresses. Frames that are destined with MAC address FF-FF-FF-FF-FF-FF 
will reach every computer belonging to that LAN segment.

### What is MAC Cloning:

!https://media.geeksforgeeks.org/wp-content/uploads/broadcast.jpg

Some
 ISPs use MAC addresses in order to assign an IP address to the gateway 
device. When a device connects to the ISP, the DHCP server records the 
MAC address and then assigns an IP address. Now the system will be 
identified through the MAC address. When the device gets disconnected, 
it loses the IP address. If the user wants to reconnect, the DHCP server
 checks if the device is connected before. If so, then the server tries 
to assign the same IP address (in case the lease period has not 
expired). In case user changed the router, the user has to inform the 
ISP about new MAC address because the new MAC address is unknown to ISP,
 so the connection cannot be established.

Or the other option is **Cloning**,
 user can simply clone the registered MAC address with ISP. Now router 
keeps reporting the old MAC addresses to ISP and there will be no 
connection issue.

### Characteristics of MAC address:

Media
 Access Control address (MAC address) is a unique identifier assigned to
 most network adapters or network interface cards (NICs) by the 
manufacturer for identification and used in the Media Access Control 
protocol sub-layer.An Ethernet MAC address is a 48-bit binary value 
expressed as 12 hexadecimal digits (4 bits per hexadecimal digit). MAC 
addresses are in a flat structure and thus they are not routable on the 
Internet. Serial interfaces do not use MAC addresses. It does NOT 
contain a network and host portion with the address. It is used to 
deliver the frame to the destination device.
*** Collision Avoidance in wireless networks
We take a close look at so-called WiFi which is also known as IEEE standard 802.11

!https://media.geeksforgeeks.org/wp-content/uploads/HiddenNode.jpg

Consider
 the situation depicted in the figure, where each of four nodes is able 
to send and receive signals that reach just the nodes to its immediate 
left and right.For example, B can exchange frames with A and C but 
it cannot reach D, while C can reach B and D but not A. (A and D’s reach
 is not shown in the figure.) Suppose both A and C want to communicate 
with B and so they each send it a frame. A and C are unaware of each 
other since their signals do not carry that far. These two frames 
collide with each other at B, but unlike an Ethernet, neither A nor C is
 aware of this collision. A and C are said to be hidden nodes with 
respect to each other.

According to Wikipedia, the hidden node problem can be defined as “In wireless networking, the **hidden node problem or hidden terminal problem** occurs when a node is visible to a wireless access point (AP), but not to other nodes communicating with that AP.”

### Collision cannot be detected in hidden node problem

This is because the nodes **A** and **C**
 are out of range of each other(and so cannot detect a collision while 
transmitting). Thus, Carrier sense multiple access with collision 
detection (CSMA/CD) does not work, and collisions occur. The data 
received by the access point is corrupted due to the collision. To 
overcome the hidden node problem, RTS/CTS handshaking (IEEE 802.11 
RTS/CTS) is implemented in addition to the Carrier sense multiple access
 with collision avoidance (CSMA/CA) scheme.

A related problem, called the exposed node problem, occurs under the following stated circumstances:

Suppose
 B is sending to A (as in the above Figure). Node C is aware of this 
communication because it hears B’s transmission. It would be a mistake 
for C to conclude that it cannot transmit to anyone just because it can 
hear B’s transmission.For example, suppose C wants to transmit to 
node D. This is not a problem since C’s transmission to D will not 
interfere with A’s ability to receive from B.

We address these 
problems by an algorithm known as Multiple Access with Collision 
Avoidance (MACA). The sender and receiver exchange frames with each 
other before transmitting data. This informs all nearby nodes that a 
transmission is about to begin. Sender transmits **Request to Send (RTS)** frame to receiver . The receiver then replies with **clear to send (CTS)**
 frame back to the sender. Any node that receives CTS frame knows that 
it is close to the receiver, therefore, cannot transmit a frame. Any 
node that receives RTS frame but not the CTS frame knows that is not 
close to the receiver to interfere with it, So it is free to transmit 
data.
*** Maximum Data Rate (channel capacity) for Noiseless and Noisy channels
As 
early as 1924, an AT&T engineer, Henry Nyquist, realized that even a
 perfect channel has a finite transmission capacity. He derived an 
equation expressing the maximum data rate for a finite-bandwidth 
noiseless channel. In 1948, Claude Shannon carried Nyquist’s work 
further and extended to it the case of a channel subject to random(that 
is, thermodynamic) noise (Shannon, 1948). This paper is the most 
important paper in all of the information theory.

Data
 rate governs the speed of data transmission. A very important 
consideration in data communication is how fast we can send data, in 
bits per second, over a channel. Data rate depends upon 3 factors: 

- The bandwidth available
- Number of levels in digital signal
- The quality of the channel – level of noise

Two
 theoretical formulas were developed to calculate the data rate: one by 
Nyquist for a noiseless channel, another by Shannon for a noisy 
channel. 

**1. Noiseless Channel: Nyquist Bit Rate –** For a noiseless channel, the Nyquist bit rate formula defines the theoretical maximum bit rate ***Nyquist*** proved
 that if an arbitrary signal has been run through a low-pass filter of 
bandwidth, the filtered signal can be completely reconstructed by making
 only 2*Bandwidth (exact) samples per second. Sampling the line faster 
than 2*Bandwidth times per second is pointless because the 
higher-frequency components that such sampling could recover have 
already been filtered out. If the signal consists of L discrete levels, 
Nyquist’s theorem states:

```
BitRate = 2 * Bandwidth * log2(L) bits/sec
```

In
 the above equation, bandwidth is the bandwidth of the channel, L is the
 number of signal levels used to represent data, and BitRate is the bit 
rate in bits per second. Bandwidth is a fixed quantity, so it cannot
 be changed. Hence, the data rate is directly proportional to the number
 of signal levels. **Note –**Increasing the levels of a signal may reduce the reliability of the system.

**Examples:**

**Input1 :**
 Consider a noiseless channel with a bandwidth of 3000 Hz transmitting a
 signal with two signal levels. What can be the maximum bit rate? **Output1 :** BitRate = 2 * 3000 * log2(2) = 6000bps

**Input2 :** We need to send 265 kbps over a noiseless channel with a bandwidth of 20 kHz. How many signal levels do we need? **Output2 :** 265000 = 2 * 20000 * log2(L) log2(L) = 6.625 L = 26.625 = 98.7 levels

> The amount of thermal noise present is measured by the ratio of the signal power to the noise power, called the SNR (Signal-to-Noise Ratio).
> 

**2. Noisy Channel : Shannon Capacity –** In
 reality, we cannot have a noiseless channel; the channel is always 
noisy. Shannon capacity is used, to determine the theoretical highest 
data rate for a noisy channel: 

```
Capacity = bandwidth * log2(1 + SNR) bits/sec
```

In
 the above equation, bandwidth is the bandwidth of the channel, SNR is 
the signal-to-noise ratio, and capacity is the capacity of the channel 
in bits per second. Bandwidth is a fixed quantity, so it cannot be 
changed. Hence, the channel capacity is directly proportional to the 
power of the signal, as SNR = (Power of signal) / (power of noise). The signal-to-noise ratio (S/N) is usually expressed in decibels (dB) given by the formula: 

```
10 * log10(S/N)
```

So for example a signal-to-noise ratio of 1000 is commonly expressed as: 

```
10 * log10(1000) = 30 dB.
```

> This
 tells us the best capacities that real channels can have. For example, 
ADSL (Asymmetric Digital Subscriber Line), which provides Internet 
access over normal telephonic lines, uses a bandwidth of around 1 MHz. 
the SNR depends strongly on the distance of the home from the telephone 
exchange, and an SNR of around 40 dB for short lines of 1 to 2km is very
 good. with these characteristics, the channel can never transmit much 
more than 13Mbps, no matter how many or how few signals level are used 
and no matter how often or how infrequently samples are taken.
> 
> 
> **Examples:**
> 
> **Input1 :**
>  A telephone line normally has a bandwidth of 3000 Hz (300 to 3300 Hz) 
> assigned for data communication. The SNR is usually 3162. What will be 
> the capacity for this channel? **Output1 :** C = 3000 * log2(1 + SNR) = 3000 * 11.62 = 34860 bps
> 
> **Input2 :**
>  The SNR is often given in decibels. Assume that SNR(dB) is 36 and the 
> channel bandwidth is 2 MHz. Calculate the theoretical channel capacity. **Output2 :** SNR(dB) = 10 * log10(SNR) SNR = 10(SNR(dB)/10) SNR = 103.6 = 3981
> 
> Hence, C = 2 * 106 * log2(3982) = 24 MHz 
>
*** Types of switches in Computer Network
Prerequisite – [Network Devices](https://www.geeksforgeeks.org/network-devices-hub-repeater-bridge-switch-router-gateways/), [Switch functions at layer 2](https://www.geeksforgeeks.org/switch-functions-layer-2/), [Difference between layer-2 and layer-3 switches](https://www.geeksforgeeks.org/computer-network-difference-between-layer-2-and-layer-3-switches/) Switches
 are the connectivity points of an Ethernet network. These are small 
devices that can receive data from multiple input ports and send it to 
the specific output port that takes data to its intended destination in 
the network. There are different types of switches in a network. These 
are:

1. **Unmanaged switches –** These are the switches that are mostly used in home networks and small
businesses as they plug in and instantly start doing their job and such
switches do not need to be watched or configured. These require only
small cable connections. It allows devices on a network to connect with
each other such as a computer to a computer or a computer to a printer
in one location. They are the least expensive switches among all
categories. 
2. **Managed switches –** These
types of switches have many features like the highest levels of
security, precision control, and full management of the network. These
are used in organizations containing a large network and can be
customized to enhance the functionality of a certain network. These are
the most costly option but their scalability makes them an ideal option
for a network that is growing. They are achieved by setting a simple
network management protocol(SNMP). They are of two types:
    - **(I) Smart switches:** These switches offer basic management features with the ability to create
    some levels of security but have a simpler management interface than the other managed switches. Thus they are often called partially managed
    switches. These are mostly used in fast and constant LANs which support
    gigabit data transfer and allocations. It can accept the configuration
    of VLANs (Virtual LAN).
    - **(II) Enterprise managed switches:** They have features like the ability to fix, copy, transform and display
    different network configurations, along with a web interface SNMP agent
    and command-line interface. These are also known as fully managed
    switches and are more expensive than smart switches as they have more
    features that can be enhanced. These are used in organizations that
    contain a large number of ports, switches, and nodes.
3. **LAN switches –** These are also known as Ethernet switches or data switches and are used to
reduce network congestion or bottleneck by distributing a package of
data only to its intended recipient. These are used to connect points on a LAN. 
4. **PoE switches –** PoE switches
are used in PoE technology which stands for power over Ethernet that is a technology that integrates data and power on the same cable allowing
power devices to receive data in parallel to power. Thus these switches
provide greater flexibility by simplifying the cabling process.
** NETWORK LAYER
*** Introduction of Internetworking
Internetworking
 is combined of 2 words, inter and networking which implies an 
association between totally different nodes or segments. This connection
 area unit is established through intercessor devices akin to routers or
 gateway. The first term for associate degree internetwork was catenet. 
This interconnection is often among or between public, private, 
commercial, industrial, or governmental networks. Thus, associate degree
 internetwork could be an assortment of individual networks, connected 
by intermediate networking devices, that function as one giant network. 
Internetworking refers to the trade, products, and procedures that meet 
the challenge of making and administering internet works.

To
 enable communication, every individual network node or phase is 
designed with a similar protocol or communication logic, that is 
Transfer Control Protocol (TCP) or Internet Protocol (IP). Once a 
network communicates with another network having constant communication 
procedures, it’s called Internetworking. Internetworking was designed to
 resolve the matter of delivering a packet of information through many 
links.

There is a minute difference between extending the network
 and Internetworking. Merely exploitation of either a switch or a hub to
 attach 2 local area networks is an extension of LAN whereas connecting 
them via the router is an associate degree example of Internetworking. 
Internetworking is enforced in Layer three (Network Layer) of the 
OSI-ISO model. The foremost notable example of internetworking is the 
Internet.

There is chiefly 3 units of Internetworking:

1. Extranet
2. Intranet
3. Internet

Intranets
 and extranets might or might not have connections to the net. If there 
is a connection to the net, the computer network or extranet area unit 
is usually shielded from being accessed from the net if it is not 
authorized. The net isn’t thought-about to be a section of the computer 
network or extranet, though it should function as a portal for access to
 parts of the associate degree extranet.

1. **Extranet –** It’s a network of the internetwork that’s restricted in scope to one
organization or entity however that additionally has restricted
connections to the networks of one or a lot of different sometimes,
however not essential. It’s the very lowest level of Internetworking,
usually enforced in an exceedingly personal area. Associate degree
extranet may additionally be classified as a Man, WAN, or different form of network however it cannot encompass one local area network i.e. it
should have a minimum of one reference to associate degree external
network.
2. **Intranet –** This associate degree
computer network could be a set of interconnected networks, which
exploits the Internet Protocol and uses IP-based tools akin to web
browsers and FTP tools, that are underneath the management of one body
entity. That body entity closes the computer network to the remainder of the planet and permits solely specific users. Most typically, this
network is the internal network of a corporation or different
enterprise. An outsized computer network can usually have its own
internet server to supply users with browsable data.
3. **Internet –** A selected Internetworking, consisting of a worldwide interconnection
of governmental, academic, public, and personal networks based mostly
upon the Advanced analysis comes Agency Network (ARPANET) developed by
ARPA of the U.S. Department of Defense additionally home to the World
Wide Web (WWW) and cited as the ‘Internet’ to differentiate from all
different generic Internetworks. Participants within the web, or their
service suppliers, use IP Addresses obtained from address registries
that manage assignments.

Internetworking has evolved as an 
answer to a few key problems: isolated LANs, duplication of resources, 
and an absence of network management. Isolated LANs created transmission
 problems between totally different offices or departments. Duplication 
of resources meant that constant hardware and code had to be provided to
 every workplace or department, as did a separate support employee. This
 lack of network management meant that no centralized methodology of 
managing and troubleshooting networks existed.

One more form of 
the interconnection of networks usually happens among enterprises at the
 Link Layer of the networking model, i.e. at the hardware-centric layer 
below the amount of the TCP/IP logical interfaces. Such interconnection 
is accomplished through network bridges and network switches. This can 
be typically incorrectly termed internetworking, however, the ensuing 
system is just a bigger, single subnetwork, and no internetworking 
protocol, akin to web Protocol, is needed to traverse these devices.

However,
 one electronic network is also reborn into associate degree 
internetwork by dividing the network into phases and logically dividing 
the segment traffic with routers. The Internet Protocol is meant to 
supply an associate degree unreliable packet service across the network.
 The design avoids intermediate network components maintaining any state
 of the network. Instead, this task is allotted to the endpoints of 
every communication session. To transfer information correctly, 
applications should utilize associate degree applicable Transport Layer 
protocol, akin to Transmission management Protocol (TCP), that provides a
 reliable stream. Some applications use a less complicated, 
connection-less transport protocol, User Datagram Protocol (UDP), for 
tasks that don’t need reliable delivery of information or that need 
period of time service, akin to video streaming or voice chat.

### Internetwork Addressing –

Internetwork
 addresses establish devices severally or as members of a bunch. 
Addressing schemes differ based on the protocol family and therefore the
 OSI layer. Three kinds of internetwork addresses area units are 
ordinarily used: data-link layer addresses, Media Access control (MAC) 
addresses, and network-layer addresses. 

1. **Data Link Layer addresses:** A data-link layer address unambiguously identifies every physical
network association of a network device. Data-link addresses typically
area units cited as physical or hardware addresses. Data-link addresses
sometimes exist among a flat address area and have a pre-established and usually fastened relationship to a selected device. End systems usually have just one physical network association, and therefore have just one data-link address. Routers and different internetworking devices
usually have multiple physical network connections and so eventually
have multiple data-link addresses.
2. **MAC Addresses:** Media Access management (MAC) addresses encompass a set of data-link
layer addresses. MAC addresses establish network entities in LANs that
implement the IEEE MAC addresses of the data-link layer. MAC addresses
different area units distinctively for every local area network
interface. MAC addresses are forty-eight bits long and are expressed in
form of twelve hexadecimal digits. The primary half dozen hexadecimal
digits, which are usually administered by the IEEE, establish the
manufacturer or merchant and therefore comprise the Organizational
Unique Identifier (OUI). The last half dozen positional notation digits
comprise the interface serial variety or another price administered by
the particular merchant. MAC addresses are typically area units referred to as burned-in addresses (BIAs) as a result of being burned into
read-only memory(ROM) and are traced into random-access memory (RAM)
once the interface card initializes.
3. **Network-Layer Addresses:** Network addresses sometimes exist among a gradable address area and
typically area units referred to as virtual or logical addresses. the
connection between a network address and a tool is logical and unfixed,
it usually relies either on physical network characteristics or on
groupings that don’t have any physical basis. finish systems need one
network-layer address for every network-layer protocol they support.
Routers and different Internetworking devices need one network-layer
address per physical network association for every network-layer
protocol supported.

### Challenges to Internetworking –

Implementing
 useful internetwork isn’t at any certainty. There are several 
challenging fields, particularly in the areas of dependableness, 
connectivity, network management, and adaptability, and each and every 
space is essential in establishing associate degree economical and 
effective internetwork. A few of them are:-

- The initial
challenge lies when we are trying to connect numerous systems to support communication between disparate technologies. For example, Totally
different sites might use different kinds of media, or they could
operate at variable speeds.
- Another essential thought is
reliable service that should be maintained in an internetwork.
Individual users and whole organizations depend upon consistent,
reliable access to network resources.
- Network management should
give centralized support associate degree troubleshooting capabilities
on the internetwork. Configuration, security, performance, and different problems should be adequately addressed for the internetwork to perform swimmingly.
- Flexibility, the ultimate concern, is important for network enlargement and new applications and services, among different
factors.
*** Line Configuration in Computer Networks
A 
network is two or more devices connected through a link. A link is a 
communication pathway that transfers data from one device to another. 
Devices can be a computer, printer, or any other device that is capable 
to send and receive data. For visualization purposes, imagine any link 
as a line drawn between two points.

For
 communication to occur, two devices must be connected in some way to 
the same link at the same time. There are two possible types of 
connections:

1. **Point-to-Point Connection**
2. **Multipoint Connection**

**Point-to-Point Connection :**

1. A point-to-point connection provides a dedicated link between two devices.
2. The entire capacity of the link is reserved for transmission between those two devices.
3. Most point-to-point connections use an actual length of wire or cable to
connect the two ends, but other options such as microwave or satellite
links are also possible.
4. Point to point network topology is considered to be one of the easiest and most conventional networks topologies.
5. It is also the simplest to establish and understand.

Example: Point-to-Point connection between the remote control and Television for changing the channels.

!https://media.geeksforgeeks.org/wp-content/uploads/point-to-point-connection.jpg

**Multipoint Connection :**

1. It is also called Multidrop configuration. In this connection, two or more devices share a single link.
2. More than two devices share the link that is the capacity of the channel is
shared now. With shared capacity, there can be two possibilities in a
Multipoint Line configuration:

**Spatial Sharing:** If several devices can share the link simultaneously, it’s called Spatially shared line configuration. **Temporal (Time) Sharing:** If users must take turns using the link, then it’s called Temporally shared or Time Shared Line configuration.

!https://media.geeksforgeeks.org/wp-content/uploads/tempralSharing.jpg

http://mucins.weebly.com/21-line-configuration.html
*** Difference between Unicast, Broadcast and Multicast in Computer Network
The **cast**
 term here signifies some data(stream of packets) is being transmitted 
to the recipient(s) from the client(s) side over the communication 
channel that helps them to communicate. Let’s see some of the “cast” 
concepts that are prevailing in the computer networks field.

### 1. Unicast –

This
 type of information transfer is useful when there is a participation of
 a single sender and a single recipient. So, in short, you can term it 
as a one-to-one transmission. For example, if a device having IP address
 10.1.2.0 in a network wants to send the traffic stream(data packets) to
 the device with IP address 20.12.4.2 in the other network, then unicast
 comes into the picture. This is the most common form of data transfer 
over the networks.

!https://media.geeksforgeeks.org/wp-content/uploads/UNICAST-1.png

### 2. Broadcast –

Broadcasting transfer (one-to-all) techniques can be classified into two types :

- **Limited Broadcasting –** Suppose you have to send a stream of packets to all the devices over the
network that you reside, this broadcasting comes in handy. For this to
achieve, it will append 255.255.255.255 (all the 32 bits of IP address
set to 1) called as **Limited Broadcast Address** in the
destination address of the datagram (packet) header which is reserved
for information transfer to all the recipients from a single client
(sender) over the network.

!https://media.geeksforgeeks.org/wp-content/uploads/NETWORK-CLUSTER.png

- **Direct Broadcasting –** This is useful when a device in one network wants to transfer packet stream
to all the devices over the other network. This is achieved by
translating all the Host ID part bits of the destination address to 1,
referred to as **Direct Broadcast Address** in the datagram header for information transfer.

!https://media.geeksforgeeks.org/wp-content/uploads/DIRECT_BROADAST.png

This mode is mainly utilized by television networks for video and audio distribution. One important protocol of this class in Computer Networks is [Address Resolution Protocol (ARP)](https://www.geeksforgeeks.org/computer-network-arp-works/) which is used for resolving an IP address into a physical address which is necessary for underlying communication.

### 3. Multicast –

In
 multicasting, one/more senders and one/more recipients participate in 
data transfer traffic. In this method traffic recline between the 
boundaries of unicast (one-to-one) and broadcast (one-to-all). Multicast
 lets servers direct single copies of data streams that are then 
simulated and routed to hosts that request it. IP multicast requires the
 support of some other protocols like **IGMP (Internet Group Management Protocol), Multicast routing** for its working. Also in Classful IP addressing **Class D** is reserved for multicast groups.

**Questions Corner –**

Practicing the following questions will help you test your knowledge. It is highly recommended that you practice them.

1. [Direct Broadcast Address](https://www.geeksforgeeks.org/computer-networks-ip-addressing-question-3/)
2. [Direct Broadcast Address](https://www.geeksforgeeks.org/computer-networks-ip-addressing-question-4/)
3. [Direct Broadcast Address](https://www.geeksforgeeks.org/computer-networks-ip-addressing-question-5/)

**References –**

[Difference between Unicast, Broadcast and Multicast](https://serverfault.com/questions/279482/what-is-the-difference-between-unicast-anycast-broadcast-and-multicast-traffic) [erg.abdn.ac.uk](http://www.erg.abdn.ac.uk/users/gorry/course/intro-pages/uni-b-mcast.html) [Difference between Unicast, Multicast, Broadcast](http://www.rfwireless-world.com/Terminology/Unicast-vs-Multicast-vs-Broadcast-transmission-types.html)
*** Collision Domain and Broadcast Domain in Computer Network
**Prerequisite –** [Network Devices](https://www.geeksforgeeks.org/network-devices-hub-repeater-bridge-switch-router-gateways/), [Transmission Modes](https://www.geeksforgeeks.org/transmission-modes-computer-networks/)

The
 most common network devices used are routers and switches. But we still
 hear people talking about hubs, repeaters, and bridges. Do you ever 
wonder why these former devices are preferred over the latter ones? One 
reason could be: ‘because they are more efficient and powerful’. But 
what actually is the reason behind their efficiency? This is when terms 
like **“Collision Domains”** and **“Broadcast Domains”** come into the picture.

Before
 going further, let us recall that a hub is a multiple-port repeater. 
Similarly, a switch is a multiple-port bridge so that you can understand
 why repeaters and bridges are not typically used in production 
networks(because of less number of ports).

Now, narrowing it down to Hubs, Switches and Routers, let us discuss them in reference to the below domains.

1. **Collision Domain –** A Collision Domain is a scenario in which when a device sends out a
message to the network, all other devices which are included in its
collision domain have to pay attention to it, no matter if it was
destined for them or not. This causes a problem because, in a situation
where two devices send out their messages simultaneously, a collision
will occur leading them to wait and re-transmit their respective
messages, one at a time. Remember, it happens only in the case of a
half-duplex mode.
2. **Broadcast Domain –** A
Broadcast Domain is a scenario in which when a device sends out a
broadcast message, all the devices present in its broadcast domain have
to pay attention to it. This creates a lot of congestion in the network, commonly called LAN congestion, which affects the bandwidth of the
users present in that network.
    
    From this, we can realize that the 
    more the number of collision domains and the more the number of 
    broadcast domains, the more efficient is the network providing better 
    bandwidth to all its users.
    

So, which of our network devices break collision domains, and which of them break broadcast domains?

- **HUB –** We start with a hub because we should get rid of it as soon as possible.
The reason being, it neither breaks a collision domain nor a broadcast
domain,i.e a hub is neither a collision domain separator nor a broadcast domain separator. All the devices connected to a hub are in a single
collision and single broadcast domain. Remember, hubs do not segment a
network, they just connect network segments.
- **SWITCH –** Coming to switches, we have an advantage over the hub. Every port on a switch
is in a different collision domain, i.e a switch is a collision domain
separator. So messages that come from devices connected to different
ports never experience a collision. This helps us during designing
networks but there is still a problem with switches. They never break
broadcast domains, which means it is not a broadcast domain separator.
All the ports on the switch are still in a single broadcast domain. If a device sends a broadcast message, it will still cause congestion.
- **ROUTER –** Last, but not least, we have our savior. A router not only breaks collision
domains but also breaks broadcast domains, which means it is both
collisions as well as broadcast domain separators. A router creates a
connection between two networks. A broadcast message from one network
will never reach the other one as the router will never let it pass.

!https://media.geeksforgeeks.org/wp-content/uploads/Computer-Network-Broadcast-Domain-Collision.png

Also,
 as repeaters and bridges differ from hubs and switches only in terms of
 the number of ports, a repeater does not break collision and broadcast 
domains, while a bridge breaks only collision domains.

**References –** [CCNA, Todd Lammle](http://www.innos.in/downloads/CISCO%20-%20640-802-ccna.pdf)
*** Introduction of Classful IP Addressing
IP 
address is an address having information about how to reach a specific 
host, especially outside the LAN. An IP address is a 32 bit unique 
address having an address space of 232.Generally, there are two notations in which IP address is written, dotted decimal notation and hexadecimal notation.

Dotted Decimal Notation:

!https://media.geeksforgeeks.org/wp-content/cdn-uploads/IP_addressing_1.jpg

Hexadecimal Notation:

!https://media.geeksforgeeks.org/wp-content/cdn-uploads/20190909105903/1212.png

Some points to be noted about dotted decimal notation:

1. The value of any segment (byte) is between 0 and 255 (both included).
2. There are no zeroes preceding the value in any segment (054 is wrong, 54 is correct).

**Classful Addressing**The 32 bit IP address is divided into five sub-classes. These are:

- Class A
- Class B
- Class C
- Class D
- Class E

Each
 of these classes has a valid range of IP addresses. Classes D and E are
 reserved for multicast and experimental purposes respectively. The 
order of bits in the first octet determine the classes of IP address.IPv4 address is divided into two parts:

- **Network ID**
- **Host ID**

The
 class of IP address is used to determine the bits used for network ID 
and host ID and the number of total networks and hosts possible in that 
particular class. Each ISP or network administrator assigns IP address 
to each device that is connected to its network.

!https://media.geeksforgeeks.org/wp-content/cdn-uploads/IP_addressing_3.jpg

**Note:** IP addresses are globally managed by Internet Assigned Numbers Authority(IANA) and regional Internet registries(RIR).

**Note:**
 While finding the total number of host IP addresses, 2 IP addresses are
 not counted and are therefore, decreased from the total count because 
the first IP address of any network is the network number and whereas 
the last IP address is reserved for broadcast IP.

**Class A:**

IP address belonging to class A are assigned to the networks that contain a large number of hosts.

- The network ID is 8 bits long.
- The host ID is 24 bits long.

The
 higher order bit of the first octet in class A is always set to 0. The 
remaining 7 bits in first octet are used to determine network ID. The 24
 bits of host ID are used to determine the host in any network. The 
default subnet mask for class A is 255.x.x.x. Therefore, class A has a 
total of:

- 2^7-2= 126 network ID(Here 2 address is subtracted because 0.0.0.0 and 127.x.y.z are special address. )
- 2^24 – 2 = 16,777,214 host ID

IP addresses belonging to class A ranges from 1.x.x.x – 126.x.x.x

!https://media.geeksforgeeks.org/wp-content/cdn-uploads/IP_addressing_4.jpg

**Class B:**

IP address belonging to class B are assigned to the networks that ranges from medium-sized to large-sized networks.

- The network ID is 16 bits long.
- The host ID is 16 bits long.

The
 higher order bits of the first octet of IP addresses of class B are 
always set to 10. The remaining 14 bits are used to determine network 
ID. The 16 bits of host ID is used to determine the host in any network.
 The default sub-net mask for class B is 255.255.x.x. Class B has a 
total of:

- 2^14 = 16384 network address
- 2^16 – 2 = 65534 host address
    
    !https://media.geeksforgeeks.org/wp-content/cdn-uploads/IP_addressing_5.jpg
    
    **Class C:**
    
    IP address belonging to class C are assigned to small-sized networks.
    
    - The network ID is 24 bits long.
    - The host ID is 8 bits long.
    
    The
     higher order bits of the first octet of IP addresses of class C are 
    always set to 110. The remaining 21 bits are used to determine network 
    ID. The 8 bits of host ID is used to determine the host in any network. 
    The default sub-net mask for class C is 255.255.255.x. Class C has a 
    total of:
    
    - 2^21 = 2097152 network address
    - 2^8 – 2 = 254 host address
    
    IP addresses belonging to class C ranges from 192.0.0.x – 223.255.255.x.
    
    !https://media.geeksforgeeks.org/wp-content/cdn-uploads/IP_addressing_6.jpg
    
    **Class D:**
    
    IP
     address belonging to class D are reserved for multi-casting. The higher
     order bits of the first octet of IP addresses belonging to class D are 
    always set to 1110. The remaining bits are for the address that 
    interested hosts recognize.
    
    Class D does not posses any sub-net mask. IP addresses belonging to class D ranges from 224.0.0.0 – 239.255.255.255.
    
    !https://media.geeksforgeeks.org/wp-content/cdn-uploads/IP_addressing_7.jpg
    
    **Class E:**
    
    IP
     addresses belonging to class E are reserved for experimental and 
    research purposes. IP addresses of class E ranges from 240.0.0.0 – 
    255.255.255.254. This class doesn’t have any sub-net mask. The higher 
    order bits of first octet of class E are always set to 1111.
    
    !https://media.geeksforgeeks.org/wp-content/cdn-uploads/IP_addressing_8.jpg
    
    **Range of special IP addresses:**
    
    **169.254.0.0 – 169.254.0.16** : Link local addresses**127.0.0.0 – 127.0.0.8** : Loop-back addresses**0.0.0.0 – 0.0.0.8** : used to communicate within the current network.
    
    **Rules for assigning Host ID:**
    
    Host ID’s are used to identify a host within a network. The host ID are assigned based on the following rules:
    
    - Within any network, the host ID must be unique to that network.
    - Host ID in which all bits are set to 0 cannot be assigned because this host
    ID is used to represent the network ID of the IP address.
    - Host
    ID in which all bits are set to 1 cannot be assigned because this host
    ID is reserved as a broadcast address to send packets to all the hosts
    present on that particular network.
    
    **Rules for assigning Network ID:**
    
    Hosts
     that are located on the same physical network are identified by the 
    network ID, as all host on the same physical network is assigned the 
    same network ID. The network ID is assigned based on the following 
    rules:
    
    - The network ID cannot start with 127 because 127 belongs to class A address and is reserved for internal loop-back functions.
    - All bits of network ID set to 1 are reserved for use as an IP broadcast address and therefore, cannot be used.
    - All bits of network ID set to 0 are used to denote a specific host on the
    local network and are not routed and therefore, aren’t used.
    
    **Summary of Classful addressing :**
    
    !https://media.geeksforgeeks.org/wp-content/cdn-uploads/gq/2015/07/nethostdata.jpg
    
    **Problems with Classful Addressing:**
    
    The
     problem with this classful addressing method is that millions of class A
     address are wasted, many of the class B address are wasted, whereas, 
    number of addresses available in class C is so small that it cannot 
    cater the needs of organizations. Class D addresses are used for 
    multicast routing and are therefore available as a single block only. 
    Class E addresses are reserved.
    
    Since there are these problems, 
    Classful networking was replaced by Classless Inter-Domain Routing 
    (CIDR) in 1993. We will be discussing Classless addressing in next post.
    
    **References:**https://en.wikipedia.org/wiki/Classful_network[TechNet – Microsoft](https://technet.microsoft.com/en-us/library/cc940018.aspx)[Classful network – Wikipedia](https://en.wikipedia.org/wiki/Classful_network)
*** Introduction and IPv4 Datagram Header
The 
network layer is the third layer (from bottom) in the OSI Model. The 
network layer is concerned with the delivery of a packet across multiple
 networks. The network layer is considered the backbone of the OSI 
Model. It selects and manages the best logical path for data transfer 
between nodes. This layer contains hardware devices such as routers, 
bridges, firewalls, and switches, but it actually creates a logical 
image of the most efficient communication route and implements it with a
 physical medium. Network layer protocols exist in every host or router.
 The router examines the header fields of all the IP packets that pass 
through it. Internet Protocol and Netware IPX/SPX are the most common 
protocols associated with the network layer.In the OSI model, the 
network layer responds to requests from the layer above it (transport 
layer) and issues requests to the layer below it (data link layer).

**Responsibilities of Network Layer:**

> Packet forwarding/Routing of packets: Relaying of data packets from one network segment to another by nodes in a computer network
> 
> 
> **Connectionless communication(IP):**
>  A data transmission method used in packet-switched networks in which 
> each data unit is separately addressed and routed based on information 
> carried by it
> 
> **Fragmentation of data packets:** Splitting of data packets that are too large to be transmitted on the network
> 

There are two types of network transmission techniques, circuit switched network and packet switched network.**Circuit Switch vs Packet Switch**In
 circuit switched network, a single path is designated for transmission 
of all the data packets. Whereas in case of a packet-switched network, 
each packet may be sent through a different path to reach the 
destination.

In a circuit switched network, the data packets are 
received in order whereas in a packet switched network, the data packets
 may be received out of order.

The packet switching is further subdivided into Virtual circuits and Datagram.

**IPv4:**IPv4
 is a connectionless protocol used for packet-switched networks. It 
operates on a best effort delivery model, in which neither delivery is 
guaranteed, nor proper sequencing or avoidance of duplicate delivery is 
assured. Internet Protocol Version 4 (IPv4) is the fourth revision of 
the Internet Protocol and a widely used protocol in data communication 
over different kinds of networks. IPv4 is a connectionless protocol used
 in packet-switched layer networks, such as Ethernet. It provides a 
logical connection between network devices by providing identification 
for each device. There are many ways to configure IPv4 with all kinds of
 devices – including manual and automatic configurations – depending on 
the network type.

IPv4 is defined and specified in IETF publication RFC 791.IPv4
 uses 32-bit addresses for Ethernet communication in five classes: A, B,
 C, D and E. Classes A, B and C have a different bit length for 
addressing the network host. Class D addresses are reserved for military
 purposes, while class E addresses are reserved for future use.

IPv4 uses 32-bit (4 byte) addressing, which gives 232
 addresses. IPv4 addresses are written in the dot-decimal notation, 
which comprises of four octets of the address expressed individually in 
decimal and separated by periods, for instance, 192.168.1.5.

**IPv4 Datagram Header**Size of the header is 20 to 60 bytes.

!https://media.geeksforgeeks.org/wp-content/cdn-uploads/20200113154849/ip-v4-datagram-header.png

> VERSION: Version of the IP protocol (4 bits), which is 4 for IPv4
> 
> 
> ***HLEN:***
>  IP header length (4 bits), which is the number of 32 bit words in the 
> header. The minimum value for this field is 5 and the maximum is 15.
> 
> ***Type of service:*** Low Delay, High Throughput, Reliability (8 bits)
> 
> ***Total Length:*** Length of header + Data (16 bits), which has a minimum value 20 bytes and the maximum is 65,535 bytes.
> 
> ***Identification:*** Unique Packet Id for identifying the group of fragments of a single IP datagram (16 bits)
> 
> ***Flags:*** 3 flags of 1 bit each : reserved bit (must be zero), do not fragment flag, more fragments flag (same order)
> 
> ***Fragment Offset:***
>  Represents the number of Data Bytes ahead of the particular fragment in
>  the particular Datagram. Specified in terms of number of 8 bytes, which
>  has the maximum value of 65,528 bytes.
> 
> ***Time to live:***
>  Datagram’s lifetime (8 bits), It prevents the datagram to loop through 
> the network by restricting the number of Hops taken by a Packet before 
> delivering to the Destination.
> 
> ***Protocol:*** Name of the protocol to which the data is to be passed (8 bits)
> 
> ***Header Checksum:*** 16 bits header checksum for checking errors in the datagram header
> 
> ***Source IP address:*** 32 bits IP address of the sender
> 
> ***Destination IP address:*** 32 bits IP address of the receiver
> 
> ***Option:***
>  Optional information such as source route, record route. Used by the 
> Network administrator to check whether a path is working or not.
> 

Due to the presence of options, the size of the datagram header can be of variable length (20 bytes to 60 bytes).

Below questions have been asked in previous GATE exam on above topics.[GATE | GATE CS 2006 | Question 5](https://www.geeksforgeeks.org/gate-gate-cs-2006-question-5/)[GATE | GATE-CS-2010 | Question 15](https://www.geeksforgeeks.org/gate-gate-cs-2010-question-15/)[GATE | GATE-CS-2014 Set 3 | Question 35](https://www.geeksforgeeks.org/gate-gate-cs-2014-set-3-question-35/)[GATE | GATE CS 2015 Set 1| Question 65](https://www.geeksforgeeks.org/gate-gate-cs-2015-set-1-question-32/)
*** IPv4 Datagram Fragmentation and Delays
**Why IPv4 Datagram Fragmentation required?**Different
 Networks may have different maximum transmission unit (MTU), for 
example due to differences in LAN technology. When one network wants to 
transmit datagrams to a network with a smaller MTU, the routers on path 
may fragment and reassemble datagrams.

**How is Fragmentation done?**When
 a packet is received at the router, destination address is examined and
 MTU is determined. If size of the packet is bigger than the MTU, and 
the ‘Do not Fragment (DF)’ bit is set to 0 in header, then the packet is
 fragmented into parts and sent one by one. The maximum size of each 
fragment is the MTU minus the IP header size (Minimum 20 bytes and 
Maximum 60 bytes).

Each fragment is converted to a packet and the following changes happen in the datagram header:

1. The total length field is changed to the size of the fragment.
2. The More Fragment bit (MF bit) is set for all the fragment packets except the last one.
3. The fragment offset field is set, based on the number of fragment that is being set and the MTU.
4. Header Checksum is re-calculated.

**Example:**
 For a data packet of 4000 bytes and MTU of 1500 bytes, we have actual 
data of 3980 bytes that is to be transmitted and 1480 bytes is the 
maximum data size that is permissible to be sent. So, there would be 3 
fragments:For the first fragment, data size = 1480 bytes, offset = 0 and MF flag = 1For the second fragment, data size = 1480 bytes, offset = 1480 and MF flag = 1For the third fragment, data size = 1020 bytes, offset = 2960 and MF flag = 0

An
 important point to be noted here is that all fragments would be having 
same identification number, thus indicating that all the fragments 
belong to the same parent data packet.

**Delays –**Processing delay: Time taken by the routers to process the data packet header.

Queuing delay: Time taken by the data packet in routing queues.

Transmission delay: Time taken to load a data packet onto the transmission channelDt = N/R,N: Number of bits to be transmittedR: Rate or transmission speed of the channel

Propagation delay – Time taken by the data packet to reach from source to destination

Dp = D/S,D: Distance between the source and the destinationS: is the speed of propagation

Below questions have been asked in previous GATE exam on above topics.

1. [GATE CS 2012 | Question 42](https://www.geeksforgeeks.org/gate-gate-cs-2012-question-44/)
2. [GATE-CS-2013 | Question 65](https://www.geeksforgeeks.org/gate-gate-cs-2013-question-37/)
3. [GATE-CS-2014 Set 3 | Question 65](https://www.geeksforgeeks.org/gate-gate-cs-2014-set-3-question-38/)
*** Fragmentation at Network Layer
Prerequisite – [IPv4 Datagram Fragmentation and Delays](https://www.geeksforgeeks.org/network-layer-ipv4-datagram-fragmentation-and-delays/)

**Fragmentation**
 is done by the network layer when the maximum size of datagram is 
greater than maximum size of data that can be held in a frame i.e., its 
Maximum Transmission Unit (MTU). The network layer divides the datagram 
received from the transport layer into fragments so that data flow is 
not disrupted. 

- Since there are 16 bits for total length in IP header so, the maximum size of IP datagram = 2 – 1 = 65, 535 bytes.
    
    16
    
- It is done by the network layer at the destination side and is usually done at routers.
- Source side does not require fragmentation due to wise (good) segmentation by
transport layer i.e. instead of doing segmentation at the transport
layer and fragmentation at the network layer, the transport layer looks
at datagram data limit and frame data limit and does segmentation in
such a way that resulting data can easily fit in a frame without the
need of fragmentation.
- Receiver identifies the frame with the **identification (16 bits)** field in the IP header. Each fragment of a frame has the same identification number.
- Receiver identifies the sequence of frames using the **fragment offset(13 bits)** field in the IP header
- Overhead at the network layer is present due to the extra header introduced due to fragmentation.

### Fields in IP header for fragmentation –

- **Identification (16 bits) –** use to identify fragments of the same frame.
- **Fragment offset (13 bits) –** use to identify the sequence of fragments in the frame. It generally
indicates a number of data bytes preceding or ahead of the fragment. Maximum fragment offset possible = (65535 – 20) = 65515 {where 65535 is the maximum size of datagram and 20 is the minimum size of IP header} So, we need ceil(log65515) = 16 bits for a fragment offset but the fragment offset field has only
13 bits. So, to represent efficiently we need to scale down the fragment offset field by 2/2 = 8 which acts as a
scaling factor. Hence, all fragments except the last fragment should
have data in multiples of 8 so that fragment offset ∈ N.
    
    2
    
    16
    
    13
    
- **More fragments (MF = 1 bit) –** tells if more fragments are ahead of this fragment i.e. if MF = 1, more fragments are ahead of this fragment and if MF = 0, it is the last
fragment.
- **Don’t fragment (DF = 1 bit) –** if we don’t want the packet to be fragmented then DF is set i.e. DF = 1.

### Reassembly of Fragments –

It
 takes place only at the destination and not at routers since packets 
take an independent path(datagram packet switching), so all may not meet
 at a router and hence a need of fragmentation may arise again. The 
fragments may arrive out of order also.

!https://media.geeksforgeeks.org/wp-content/uploads/fr-2.png

### Algorithm –

1. Destination should identify that datagram is fragmented from MF, Fragment offset field.
2. Destination should identify all fragments belonging to same datagram from Identification field.
3. Identify the 1st fragment(offset = 0).
4. Identify subsequent fragments using header length, fragment offset.
5. Repeat until MF = 0.

### Efficiency –

```
Efficiency (e) = useful/total = (Data without header)/(Data with header)

Throughput = e * B { where B is bottleneck bandwidth }
```

**Example –**
 An IP router with a Maximum Transmission Unit (MTU) of 200 bytes has 
received an IP packet of size 520 bytes with an IP header of length 20 
bytes. The values of the relevant fields in the IP header.

**Explanation –**
 Since MTU is 200 bytes and 20 bytes is header size so, the maximum 
length of data = 180 bytes but it can’t be represented in fragment 
offset since it is not divisible by 8 so, the maximum length of data 
feasible = 176 bytes. Number of fragments = (520/200) = 3. Header length = 5 (since scaling factor is 4 therefore, 20/4 = 5) Efficiency, e = (Data without header)/(Data with header) = 500/560 = 89.2 %

!https://media.geeksforgeeks.org/wp-content/uploads/fr-4-1.png

*** Internet Protocol version 6 (IPv6)
IP 
v6 was developed by Internet Engineering Task Force (IETF) to deal with 
the problem of IP v4 exhaustion. IP v6 is a 128-bits address having an 
address space of 2^128, which is way bigger than IPv4. In IPv6 we use 
Colon-Hexa representation. There are 8 groups and each group represents 2
 Bytes.

!https://media.geeksforgeeks.org/wp-content/uploads/ipv6-1-2-1024x284.png

In IPv6 representation, we have three addressing methods :

- Unicast
- Multicast
- Anycast

**1. Unicast Address –**Unicast
 Address identifies a single network interface. A packet sent to a 
unicast address is delivered to the interface identified by that 
address.

**2. Multicast Address –**Multicast 
Address is used by multiple hosts, called as Group, acquires a multicast
 destination address. These hosts need not be geographically together. 
If any packet is sent to this multicast address, it will be distributed 
to all interfaces corresponding to that multicast address.

**3. Anycast Address –**Anycast
 Address is assigned to a group of interfaces. Any packet sent to an 
anycast address will be delivered to only one member interface (mostly 
nearest host possible).

**Note:** Broadcast is not defined in IPv6.

**Types of IPv6 address:** We have 128 bits in IPv6 address but by looking at the first few bits we can identify what type of address it is.

[Untitled Database](https://www.notion.so/d55ce66c220540ddb47bfaea864eda32?pvs=21)

**Note:** In IPv6, all 0’s and all 1’s can be assigned to any host, there is not any restriction like IPv4.

**Provider-based Unicast address :** These are used for global communication. 

!https://media.geeksforgeeks.org/wp-content/uploads/IP_v6_2.png

The First 3 bits identify it as of this type. **Registry Id (5-bits):** Registry Id identifies the region to which it belongs. Out of 32 (i.e. 2^5), only 4 registry IDs are being used. 

!https://media.geeksforgeeks.org/wp-content/uploads/IP_v6_4.png

**Provider Id:**
 Depending on the number of service providers that operate under a 
region, certain bits will be allocated to the Provider Id field. This 
field need not be fixed. Let’s say if Provider Id = 10 bits then 
Subscriber Id will be 56 – 10 = 46 bits. **Subscriber Id:** After Provider Id is fixed, the remaining part can be used by ISP as a normal IP address. **Intra Subscriber:** This part can be modified as per the need of the organization that is using the service.

**Geography based Unicast address :** 

!https://media.geeksforgeeks.org/wp-content/uploads/IP_v6_5.png

**Global routing prefix:**
 Global routing prefix contains all the details of Latitude and 
Longitude. As of now, it is not being used. In Geography-based Unicast 
address routing will be based on location. **Interface Id:** In IPv6, instead of using Host Id, we use the term Interface Id.

**Some special addresses:** **Unspecified –** 

!https://media.geeksforgeeks.org/wp-content/uploads/IP_v6_6.png

**Loopback –** 

!https://media.geeksforgeeks.org/wp-content/uploads/IP_v6_7.png

**IPv4 Compatible –** 

!https://media.geeksforgeeks.org/wp-content/uploads/IP_v6_8.png

**IPv4 mapped –** 

!https://media.geeksforgeeks.org/wp-content/uploads/IP_v6_9.png

**Local Unicast Addresses :** There are two types of Local Unicast addresses defined- *Link-local* and *Site-Local*.

**Link-local address:** 

!https://media.geeksforgeeks.org/wp-content/uploads/IP_v6_10.png

A
 link-local address is used for addressing a single link. It can also be
 used to communicate with nodes on the same link. The link-local address
 always begins with 1111111010 (i.e. FE80). The router will not forward 
any packet with Link-local address.

**Site local address:** 

!https://media.geeksforgeeks.org/wp-content/uploads/IP_v6_11.png

Site
 local addresses are equivalent to a private IP address in IPv4. Likely,
 some address space is reserved, which can only be routed within an 
organization. The first 10-bits are set to 1111111011, which is why Site
 local addresses always begin with FEC0. The following 32 bits are 
Subnet IDs, which can be used to create a subnet within the 
organization. The node address is used to uniquely identify the link; 
therefore, we use a 48-bits MAC address here.

**References :**

- https://tools.ietf.org/html/rfc3513
- https://en.wikipedia.org/wiki/IPv6_address
*** Internet Protocol version 6 (IPv6) Header
Prerequisite: [Introduction to Internet Protocol version 6](https://www.geeksforgeeks.org/internet-protocol-v6-ipv6/)

IP
 version 6 is the new version of Internet Protocol, which is way better 
than IP version 4 in terms of complexity and efficiency. Let’s look at 
the header of IP version 6 and understand how it is different from the 
IPv4 header.

**IP version 6 Header Format :** 

!https://media.geeksforgeeks.org/wp-content/uploads/ipv6-header.png

**Version (4-bits):** Indicates version of Internet Protocol which contains bit sequence 0110.

**Traffic Class (8-bits):** The Traffic Class field indicates class or priority of IPv6 packet which is similar to *Service Field*
 in IPv4 packet. It helps routers to handle the traffic based on the 
priority of the packet. If congestion occurs on the router then packets 
with the least priority will be discarded. As of now, only 4-bits 
are being used (and the remaining bits are under research), in which 0 
to 7 are assigned to Congestion controlled traffic and 8 to 15 are 
assigned to Uncontrolled traffic.

Priority assignment of Congestion controlled traffic : 

!https://media.geeksforgeeks.org/wp-content/uploads/congestion-table.png

Uncontrolled data traffic is mainly used for Audio/Video data. So we give higher priority to Uncontrolled data traffic. The
 source node is allowed to set the priorities but on the way, routers 
can change it. Therefore, the destination should not expect the same 
priority which was set by the source node.

**Flow Label (20-bits):** Flow
 Label field is used by a source to label the packets belonging to the 
same flow in order to request special handling by intermediate IPv6 
routers, such as non-default quality of service or real-time service. In
 order to distinguish the flow, an intermediate router can use the 
source address, a destination address, and flow label of the packets. 
Between a source and destination, multiple flows may exist because many 
processes might be running at the same time. Routers or Host that does 
not support the functionality of flow label field and for default router
 handling, flow label field is set to 0. While setting up the flow 
label, the source is also supposed to specify the lifetime of the flow.

**Payload Length (16-bits):**
 It is a 16-bit (unsigned integer) field, indicates the total size of 
the payload which tells routers about the amount of information a 
particular packet contains in its payload. The payload Length field 
includes extension headers(if any) and an upper-layer packet. In case 
the length of the payload is greater than 65,535 bytes (payload up to 
65,535 bytes can be indicated with 16-bits), then the payload length 
field will be set to 0 and the jumbo payload option is used in the 
Hop-by-Hop options extension header.

**Next Header (8-bits):**
 Next Header indicates the type of extension header(if present) 
immediately following the IPv6 header. Whereas In some cases it 
indicates the protocols contained within upper-layer packets, such as 
TCP, UDP.

**Hop Limit (8-bits):** Hop Limit field is
 the same as TTL in IPv4 packets. It indicates the maximum number of 
intermediate nodes IPv6 packet is allowed to travel. Its value gets 
decremented by one, by each node that forwards the packet and the packet
 is discarded if the value decrements to 0. This is used to discard the 
packets that are stuck in an infinite loop because of some routing 
error.

**Source Address (128-bits):** Source Address is the 128-bit IPv6 address of the original source of the packet.

**Destination Address (128-bits):**
 The destination Address field indicates the IPv6 address of the final 
destination(in most cases). All the intermediate nodes can use this 
information in order to correctly route the packet.

**Extension Headers:** In order to rectify the limitations of the *IPv4 Option Field*,
 Extension Headers are introduced in IP version 6. The extension header 
mechanism is a very important part of the IPv6 architecture. The next 
Header field of IPv6 fixed header points to the first Extension Header 
and this first extension header points to the second extension header 
and so on.

!https://media.geeksforgeeks.org/wp-content/uploads/ext-header.png

IPv6 packet may contain zero, one or more extension headers but these should be present in their recommended order:

!https://media.geeksforgeeks.org/wp-content/uploads/next-header-2.png

**Rule:** Hop-by-Hop options header(if present) should always be placed after the IPv6 base header. 

**Conventions :**

1. Any extension header can appear at most once except Destination Header
because Destination Header is present two times in the above list
itself.
2. If Destination Header is present before Routing Header
then it will be examined by all intermediate nodes specified in the
routing header.
3. If Destination Header is present just above the Upper layer then it will be examined only by the Destination node.

Given order in which all extension header should be chained in IPv6 packet and working of each extension header **:**

!https://media.geeksforgeeks.org/wp-content/uploads/ext-header-1.png

**References**: https://www.ietf.org/rfc/rfc2460.txt https://www.ietf.org/rfc/rfc3697.txt https://www.cisco.com/en/US/technologies/tk648/tk872/technologies_white_paper0900aecd8054d37d.html
*** IP Addressing | Classless Addressing
We have introduced [IP addressing and classful addressing](https://www.geeksforgeeks.org/introduction-of-classful-ip-addressing/) in the previous post.

**Network Address and Mask**

Network
 address – It identifies a network on internet.  Using this, we can find
 range of addresses in the network and total possible number of hosts in
 the network.

Mask – It is a 32-bit 
binary number that gives the network address in the address block when 
AND operation is bitwise applied on the mask and any IP address of the 
block.

The default mask in different classes are :

Class A – 255.0.0.0

Class B – 255.255.0.0

Class C – 255.255.255.0

Example : Given IP address 132.6.17.85 and default class B mask, find the beginning address (network address).

Solution
 : The default mask is 255.255.0.0, which means that the only the first 2
 bytes are preserved and the other 2 bytes are set to 0. Therefore, the 
network address is 132.6.0.0.

**Subnetting:**  Dividing
 a large block of addresses into several contiguous sub-blocks and 
assigning these sub-blocks to different smaller networks is called 
subnetting. It is a practice that is widely used when classless 
addressing is done.

**Classless Addressing**

To
 reduce the wastage of IP addresses in a block, we use sub-netting. What
 we do is that we use host id bits as net id bits of a classful IP 
address. We give the IP address and define the number of bits for mask 
along with it (usually followed by a ‘/’ symbol), like, 192.168.1.1/28. 
Here, subnet mask is found by putting the given number of bits out of 32
 as 1, like, in the given address, we need to put 28 out of 32 bits as 1
 and the rest as 0, and so, the subnet mask would be 255.255.255.240.

**Some values calculated in subnetting :**

1. Number of subnets : Given bits for mask – No. of bits in default mask

2. Subnet address : AND result of subnet mask and the given IP address

3. Broadcast address : By putting the host bits as 1 and retaining the network bits as in the IP address

4. Number of hosts per subnet : 2(32 – Given bits for mask) – 2

5. First Host ID : Subnet address + 1 (adding one to the binary representation of the subnet address)

6. Last Host ID : Subnet address + Number of Hosts

**Example :**
 Given IP Address – 172.16.0.0/25, find the number of subnets and the 
number of hosts per subnet. Also, for the first subnet block, find the 
subnet address, first host ID, last host ID and broadcast address.

**Solution** : This is a class B address. So, no. of subnets = 2(25-16) = 29 = 512.

No. of hosts per subnet = 2(32-25) – 2 = 27 – 2 = 128 – 2 = 126

For
 the first subnet block, we have subnet address = 0.0, first host id = 
0.1, last host id = 0.126 and broadcast address = 0.127
*** Supernetting in Network Layer
**Supernetting** is the opposite of [Subnetting](https://www.geeksforgeeks.org/ip-addressing-classless-addressing/).
 In subnetting, a single big network is divided into multiple smaller 
subnetworks. In Supernetting, multiple networks are combined into a 
bigger network termed as a Supernetwork or Supernet.

Supernetting
 is mainly used in Route Summarization, where routes to multiple 
networks with similar network prefixes are combined into a single 
routing entry, with the routing entry pointing to a Super network, 
encompassing all the networks. This in turn significantly reduces the 
size of routing tables and also the size of routing updates exchanged by
 routing protocols.

More specifically,

- When multiple networks are combined to form a bigger network, it is termed super-netting
- Super netting is used in route aggregation to reduce the size of routing tables and routing table updates

There are some points which should be kept in mind while supernetting: 

1. All the Networks should be contiguous. 
2. The block size of every network should be equal and must be in form of 2. 
    
    n
    
3. First Network id should be exactly divisible by whole size of supernet. 

**Example –** Suppose 4 small networks of class C: 

```
200.1.0.0,
200.1.1.0,
200.1.2.0,
200.1.3.0
```

Build a bigger network that has a single Network Id.

**Explanation –** Before Supernetting routing table will look like as:

[Untitled Database](https://www.notion.so/f33efaf6423a46cd84177a5f6ef32c03?pvs=21)

First, let’s check whether three conditions are satisfied or not:

1. **Contiguous:** You can easily see that all networks are contiguous all having size 256 hosts. Range of first Network from 200.1.0.0 to 200.1.0.255. If you add 1 in last IP address of first network that is 200.1.0.255 + 0.0.0.1, you will get
the next network id which is 200.1.1.0. Similarly, check that all
network are contiguous.
2. **Equal size of all network:** As all networks are of class C, so all of them have a size of 256 which is in turn equal to 2.
    
    8
    
3. **First IP address exactly divisible by total size:** When a binary number is divided by 2 then last n bits are the remainder. Hence in order to prove that first
IP address is exactly divisible by while size of Supernet Network. You
can check that if last n v=bits are 0 or not.
    
    n
    
    In the given example first IP is 200.1.0.0 and whole size of supernet is 4*28 = 210. If last 10 bits of first IP address are zero then IP will be divisible.
    

!https://media.geeksforgeeks.org/wp-content/uploads/11001000-1.jpg

1. Last 10 bits of first IP address are zero (highlighted by green color). So 3rd condition is also satisfied.
    1. Control and reduce network traffic 
    2. Helpful to solve the problem of lacking IP addresses 
    3. Minimizes the routing table
        - It cannot cover a different area of the network when combined
        - All the networks should be in the same class and all IP should be contiguous
        
*** Longest Prefix Matching in Routers
**What is Forwarding?** Forwarding
 is moving incoming packets to the appropriate interface. Routers use a 
forwarding table to decide which incoming packet should be forwarded to 
which next hop.

**What is an** **IP prefix?** IP
 prefix is a prefix of IP address. All computers on one network have the
 same IP prefix. For example, in 192.24.0.0/18, 18 is the length of the 
prefix and prefix is the first 18 bits of the address.

**How does forwarding work?** Routers
 basically look at the destination address’s IP prefix, searches the 
forwarding table for a match, and forward the packet to the 
corresponding next hop in the forwarding table.

**What happens if the prefixes overlap?** Since
 prefixes might overlap (this is possible as classless addressing is 
used everywhere), an incoming IP’s prefix may match multiple IP entries 
in a table. For example, consider the below forwarding table

[Untitled Database](https://www.notion.so/113c92c4cc0548729e999718bde9e888?pvs=21)

In the above table, addresses from 192.24.12.0 to 192.24.15.255 overlap, i.e., match with both entries of the table. To handle the above situation, routers use the **Longest Prefix Matching**
 rule. The rule is to find the entry in a table which has the longest 
prefix matching with the incoming packet’s destination IP and forward 
the packet to the corresponding next hope. In the above example, all
 packets in overlapping range (192.24.12.0 to 192.24.15.255) are 
forwarded to next hop B as B has a longer prefix (22 bits). 

!https://media.geeksforgeeks.org/wp-content/uploads/Computer-Networks-Longest-Prefix-Matching-in-Routers.png

**Example 1:**
 Routers forward a packet using forwarding table entries. The network 
address of the incoming packet may match multiple entries. How do 
routers resolve this? (A) Forward it to the router whose entry matches with the longest prefix of the incoming packet (B) Forward the packet to all routers whose network addresses match. (C) Discard the packet. (D) Forward it the router whose entry matches with the longest suffix of an incoming packet 

**Answer:**
 (A) The network addresses of different entries may overlap in the 
forwarding table. Routers forward the incoming packet to the router 
which hashes the longest prefix matching with the incoming packet.

**Example 2:**
 Classless Inter-domain Routing (CIDR) receives a packet with address 
131.23.151.76. The router’s routing table has the following entries: 
(GATE CS 2015) 

```
Prefix           Output Interface Identifier
131.16.0.0/12              3
131.28.0.0/14              5
131.19.0.0/16              2
131.22.0.0/15              1
```

The identifier of the output interface on which this packet will be forwarded is ______.

**Answer:** “1”.
 We need to first find out matching table entries for an incoming 
packets with address “131.23.151.76”. The address matches with two 
entries “131.16.0.0/12” and “131.22.0.0/15” (We found this by matching 
the first 12 and 15 bits respectively). So should the packet go to 
interface 3 or 1? We use Longest Prefix Matching to decide among the 
two. The most specific of the matching table entries is used as the 
interface. Since “131.22.0.0/15” is most specific, the packet goes to 
interface 1.

**Exercise** Consider the following routing table of a router. 

[Untitled Database](https://www.notion.so/9346560053cd45d3a7f7ef04b1514bfa?pvs=21)

Consider the following three IP addresses.

1. 192.24.6.0
2. 192.24.14.32
*** Program to determine class, Network and Host ID of an IPv4 address
Given a valid IPv4 address in the form of string and it follows [Class Full](https://www.geeksforgeeks.org/ip-addressing-introduction-and-classful-addressing/)
 addressing. The task is to determine the class of the given IPv4 
address as well as separate the Network and Host ID parts from it.

**Examples:**

```
Input :1.4.5.5
Output :
Given IP address belongs to Class A
Network ID is 1
Host ID is 4.5.5

Input :130.45.151.154
Output :
Given IP address belongs to Class B
Network ID is 130.45
Host ID is 151.154
```

**Approach**

1. **For determining the class:** The idea is to check the first octet of the IP addresses. As we know, for class **A** first octet will range from **1 – 126**, for class **B** first octet will range from **128 – 191**, for class **C** first octet will range from **192- 223**, for class **D** first octet will range from **224 – 239**, for class **E** first octet will range from **240 – 255**. 
2. **For determining the Network and Host ID:** We know that [Subnet Mask](https://www.iplocation.net/subnet-mask) for Class **A** is **8**, for Class **B** is **16** and for Class **C** is **24** whereas Class **D** and **E** are not divided into Network and Host ID.For 2nd Example, the first octet is 130. So, it belongs to Class **B**. Class B has a subnet mask of 16. So, the first 16 bit or first two
octets are the Network ID part and the rest is the Host ID part. Hence, the Network ID is **130.45** and the Host ID is **151.154**

[Recommended: Please try your approach on ***{IDE}*** first, before moving on to the solution.](https://ide.geeksforgeeks.org/)

`// C program to determine class, Network`

`// and Host ID of an IPv4 address`

`#include<stdio.h>`

`#include<string.h>`

`// Function to find out the Class`

`char` `findClass(char` `str[])`

`{`

`// storing first octet in arr[] variable`

`char` `arr[4];`

`int` `i = 0;`

`while` `(str[i] != '.')`

`{`

`arr[i] = str[i];`

`i++;`

`}`

`i--;`

`// converting str[] variable into number for`

`// comparison`

`int` `ip = 0, j = 1;`

`while` `(i >= 0)`

`{`

`ip = ip + (str[i] - '0') * j;`

`j = j * 10;`

`i--;`

`}`

`// Class A`

`if` `(ip >=1 && ip <= 126)`

`return` `'A';`

`// Class B`

`else` `if` `(ip >= 128 && ip <= 191)`

`return` `'B';`

`// Class C`

`else` `if` `(ip >= 192 && ip <= 223)`

`return` `'C';`

`// Class D`

`else` `if` `(ip >= 224 && ip <= 239)`

`return` `'D';`

`// Class E`

`else`

`return` `'E';`

`}`

`// Function to separate Network ID as well as`

`// Host ID and print them`

`void` `separate(char` `str[], char` `ipClass)`

`{`

`// Initializing network and host array to NULL`

`char` `network[12], host[12];`

`for` `(int` `k = 0; k < 12; k++)`

`network[k] = host[k] = '\0';`

`// for class A, only first octet is Network ID`

`// and rest are Host ID`

`if` `(ipClass == 'A')`

`{`

`int` `i = 0, j = 0;`

`while` `(str[j] != '.')`

`network[i++] = str[j++];`

`i = 0;`

`j++;`

`while` `(str[j] != '\0')`

`host[i++] = str[j++];`

`printf("Network ID is %s\n", network);`

`printf("Host ID is %s\n", host);`

`}`

`// for class B, first two octet are Network ID`

`// and rest are Host ID`

`else` `if` `(ipClass == 'B')`

`{`

`int` `i = 0, j = 0, dotCount = 0;`

`// storing in network[] up to 2nd dot`

`// dotCount keeps track of number of`

`// dots or octets passed`

`while` `(dotCount < 2)`

`{`

`network[i++] = str[j++];`

`if` `(str[j] == '.')`

`dotCount++;`

`}`

`i = 0;`

`j++;`

`while` `(str[j] != '\0')`

`host[i++] = str[j++];`

`printf("Network ID is %s\n", network);`

`printf("Host ID is %s\n", host);`

`}`

`// for class C, first three octet are Network ID`

`// and rest are Host ID`

`else` `if` `(ipClass == 'C')`

`{`

`int` `i = 0, j = 0, dotCount = 0;`

`// storing in network[] up to 3rd dot`

`// dotCount keeps track of number of`

`// dots or octets passed`

`while` `(dotCount < 3)`

`{`

`network[i++] = str[j++];`

`if` `(str[j] == '.')`

`dotCount++;`

`}`

`i = 0;`

`j++;`

`while` `(str[j] != '\0')`

`host[i++] = str[j++];`

`printf("Network ID is %s\n", network);`

`printf("Host ID is %s\n", host);`

`}`

`// Class D and E are not divided in Network`

`// and Host ID`

`else`

`printf("In this Class, IP address is not"`

`" divided into Network and Host ID\n");`

`}`

`// Driver function is to test above function`

`int` `main()`

`{`

`char` `str[] = "192.226.12.11";`

`char` `ipClass = findClass(str);`

`printf("Given IP address belongs to Class %c\n",`

`ipClass);`

`separate(str, ipClass);`

`return` `0;`

`}`

**Output:**

```
Given IP address belongs to Class C
Network ID is 192.226.12
Host ID is 11
```
*** C Program to find IP Address, Subnet Mask & Default Gateway
**Terminology**

**[IP Address](https://www.geeksforgeeks.org/ip-addressing-classless-addressing/) :** An
 IP address, short for Internet Protocol address, is an identifying 
number for a piece of network hardware. Having an IP address allows a 
device to communicate with other devices over an IP-based network like 
the internet.

**Subnet mask:** A subnet mask is a 
32-bit number used to differentiate the network component of an IP 
address by dividing the IP address into a network address and host 
address. Subnet masks are used to design subnetworks, or subnets, that 
connect local networks and determine what subnet an IP address belongs 
to.

**Default Gateway:** A default gateway serves as 
an access point or IP router that a networked computer uses to send 
information to a computer in another network or the Internet. The 
default simply means that this gateway is used by default, unless an 
application specifies another gateway. A default gateway allows 
computers on a network to communicate with computers on another network.
 Without it, the network is isolated from the outside.

**Using system command**

To
 get the IP Address, Subnet Mask and Default Gateway, we execute 
ipconfig command in the cmd.Here, we will make use of system() from <
 stdlib.h > to perform a system operation with the help of a C 
program:

`#include <stdio.h>`

`#include <stdlib.h>`

`int` `main()`

`{`

`system("c:\\windows\\system32\\ipconfig");`

`return` `0;`

`}`

**Using execl command**

This
 displays the IPv4 address, Subnet Mask and the Default Gateway.The same
 operation can also be performed with the execl() function.To execute 
the later, we code:

`#include <stdio.h>`

`#include <stdlib.h>`

`#include <unistd.h>`

`int` `main()`

`{`

`execl("c:\\windows\\system32\\ipconfig", "ipconfig", 0);`

`return` `0;`

`}`

**Output:**

!https://media.geeksforgeeks.org/wp-content/uploads/Captihure-1024x852.jpg
*** IPv4 Classless Subnet equation
Prerequisite – [Classless Addressing](https://www.geeksforgeeks.org/ip-addressing-classless-addressing/), [Supernetting](https://www.geeksforgeeks.org/computer-network-supernetting/)**Problem –** How to calculate IP address subnet information (Network, Broadcast, First IP, Last IP)?It’s too simple equation to calculate IPv4 Subnet Network ID.

- Used and Tested with Class C Subnets.

First Of All, Keep this Subnet Hosts Map in mind (Number of Hosts per Prefix):

```
Network Prefix:  Number of IPs
24            :      256 IPs
25            :      128 IPs
26            :      64 IPs
27            :      32 IPs
28            :      16 IPs
29            :      8 IPs
30            :      4 IPs
```

**Using Equation:**

```
Network ID: floor(Host Address/Subnet Number of Hosts) * Subnet Number of Hosts
Broadcast ID: (Host ID + (Subnet Number of Hosts-1))
First Host: Network ID + 1
Last Host: Broadcast ID - 1

```

**Ex1: 192.168.1.65/28:**

```
65/16 = 4.0625
Network ID: 4*16 = 64           (192.168.1.64)
Broadcast ID: 64+(16-1) = 79    (192.168.1.79)
First Host ID: 64 + 1 = 65      (192.168.1.65)
Last Host ID: 79 - 1 = 78       (192.168.1.78)

```

**Ex2: 192.168.20.166/25:**

```
166/128 = 1.296875
Network ID: 1*128 = 128         (192.168.20.128)
Broadcast ID: 128+(128-1) = 255 (192.168.20.255)
First Host ID: 128 + 1 = 129    (192.168.20.129)
Last Host ID: 255 - 1 = 254     (192.168.20.254)

```

**Ex3: 192.168.30.14/29:**

```
14/8 = 1.75
Network ID: 1*8 = 8             (192.168.30.8)
Broadcast ID: 8+(8-1) = 15      (192.168.30.15)
First Host ID: 8 + 1 = 9        (192.168.30.9)
Last Host ID: 15 - 1 = 14       (192.168.30.14)

```

**Ex4: 192.168.20.86/30:**

```
86/4 = 21.5
Network ID: 21*4 = 84           (192.168.20.84)
Broadcast ID: 84+(4-1) = 87     (192.168.20.87)
First Host ID: 84 + 1 = 85      (192.168.20.85)
Last Host ID: 87 - 1 = 86       (192.168.20.86)

```

!https://media.geeksforgeeks.org/wp-content/post-ads-banner/2022-05-25-15-57-36-InterviewSeriesPrepareInArticleAd.webp
*** Introduction of Variable Length Subnet Mask (VLSM)
VLSM
 stands for Variable Length Subnet Mask where the subnet design uses 
more than one mask in the same network which means more than one mask is
 used for different subnets of a single class A, B, C or a network. It 
is used to increase the usability of subnets as they can be of variable 
size. It is also defined as the process of subnetting of a subnet.

**Procedure of implementing VLSM –**In
 VLSM, subnets use block size based on requirement so subnetting is 
required multiple times. Suppose there is an administrator that has four
 departments to manage. These are sales and purchase department with 120
 computers, development department with 50 computers, accounts 
department with 26 computers and management department with 5 computers.

If the administrator has IP 192.168.1.0/24, department wise IPs can be allocated by following these steps:

1. For each segment select the block size that is greater than or equal to the actual requirement which is the sum of host addresses, broadcast
addresses and network addresses. Make a list of subnets possible:**table –** possible subnets list
    
    !https://media.geeksforgeeks.org/wp-content/uploads/vpic5-2.png
    
2. Arrange all the segments in descending order based on the block size that is from highest to lowest requirement.
    
    ```
    Sales and Purchase: 120
    Development: 50
    Accounts: 26
    Management: 5
    ```
    
3. The highest IP available has to be
allocated to highest requirement so the sales and purchase department
gets 192.168.1.0/25 which has 126 valid addresses that can easily be
available for 120 hosts. The subnet mask used is 255.255.255.128
4. The next segment requires an IP to handle 50 hosts. The IP subnet with
network number 192.168.1.128/26 is the next highest which can be
assigned to 62 hosts thus fulfilling the requirement of development
department. The subnet mask used is 255.255.255.192
5. Similarly
the next IP subnet 192.168.1.192/27 can fulfill the requirements of the
accounts department as it has 30 valid hosts IP which can be assigned to 26 computers. The mask used is 255.255.255.224
6. The last segment requires 5 valid hosts IP which can be fulfilled by the subnet
192.168.1.224/29 which has the mask as 255.255.255.248 is chosen as per
the requirement. The IP with the mask 255.255.255.240 could be chosen
but it has 14 valid host IPs and the requirement is less in comparison
so the one that is comparable with the requirement is chosen. Thus there is less IP wastage in VLSM as compared to FLSM.

**Advantages of VLSM over FLSM –**

1. In Fixed length subnet mask subnetting (FLSM), all subnets are of equal
size and have equal number of hosts but in VLSM the size is variable and it can have variable number of hosts thus making the IP addressing more efficient by allowing a routed system of different mask length to suit
requirements.
2. In FLSM there is a wastage of IP addresses but in VLSM there is a minimum wastage of IP addresses.
3. FLSM is preferred for private IP addresses while for public IP addresses VLSM is the best option.
*** Network Address Translation (NAT)
To 
access the Internet, one public IP address is needed, but we can use a 
private IP address in our private network. The idea of NAT is to allow 
multiple devices to access the Internet through a single public address.
 To achieve this, the translation of a private IP address to a public IP
 address is required. **Network Address Translation (NAT)**
 is a process in which one or more local IP address is translated into 
one or more Global IP address and vice versa in order to provide 
Internet access to the local hosts. Also, it does the translation of 
port numbers i.e. masks the port number of the host with another port 
number, in the packet that will be routed to the destination. It then 
makes the corresponding entries of IP address and port number in the NAT
 table. NAT generally operates on a router or firewall.

**Network Address Translation (NAT) working –** Generally,
 the border router is configured for NAT i.e the router which has one 
interface in the local (inside) network and one interface in the global 
(outside) network. When a packet traverse outside the local (inside) 
network, then NAT converts that local (private) IP address to a global 
(public) IP address. When a packet enters the local network, the global 
(public) IP address is converted to a local (private) IP address.

If
 NAT runs out of addresses, i.e., no address is left in the pool 
configured then the packets will be dropped and an Internet Control 
Message Protocol (ICMP) host unreachable packet to the destination is 
sent.

**Why mask port numbers ?**   Suppose, in a
 network, two hosts A and B are connected. Now, both of them request for
 the same destination, on the same port number, say 1000, on the host 
side, at the same time. If NAT does only translation of IP addresses, 
then when their packets will arrive at the NAT, both of their IP 
addresses would be masked by the public IP address of the network and 
sent to the destination. Destination will send replies to the public IP 
address of the router. Thus, on receiving a reply, it will be unclear to
 NAT as to which reply belongs to which host (because source port 
numbers for both A and B are the same). Hence, to avoid such a problem, 
NAT masks the source port number as well and makes an entry in the NAT 
table.

**NAT inside and outside addresses –** Inside
 refers to the addresses which must be translated. Outside refers to the
 addresses which are not in control of an organization. These are the 
network Addresses in which the translation of the addresses will be 
done.

!https://media.geeksforgeeks.org/wp-content/uploads/stati1c.png

- **Inside local address –** An IP address that is assigned to a host on the Inside (local) network. The address is probably not an IP address assigned by the service
provider i.e., these are private IP addresses. This is the inside host
seen from the inside network.
- **Inside global address –** IP address that represents one or more inside local IP addresses to the outside world. This is the inside host as seen from the outside
network.
- **Outside local address –** This is the actual IP address of the destination host in the local network after translation.
- **Outside global address –** This is the outside host as seen from the outside network. It is the IP address of the outside destination host before translation.

**Network Address Translation (NAT) Types –** There are 3 ways to configure NAT: 

1. **Static NAT –** In this, a single unregistered (Private) IP address is mapped with a
legally registered (Public) IP address i.e one-to-one mapping between
local and global addresses. This is generally used for Web hosting.
These are not used in organizations as there are many devices that will
need Internet access and to provide Internet access, a public IP address is needed.
    
    Suppose, if there are 3000 devices that need access to 
    the Internet, the organization has to buy 3000 public addresses that 
    will be very costly. 
    
2. **Dynamic NAT –** In this type of NAT, an unregistered IP address is translated into a
registered (Public) IP address from a pool of public IP addresses. If
the IP address of the pool is not free, then the packet will be dropped
as only a fixed number of private IP addresses can be translated to
public addresses.
    
    Suppose, if there is a pool of 2 public IP 
    addresses then only 2 private IP addresses can be translated at a given 
    time. If 3rd private IP address wants to access the Internet then the 
    packet will be dropped therefore many private IP addresses are mapped to
     a pool of public IP addresses. NAT is used when the number of users who
     want to access the Internet is fixed. This is also very costly as the 
    organization has to buy many global IP addresses to make a pool. 
    
3. **Port Address Translation (PAT) –** This is also known as NAT overload. In this, many local (private) IP
addresses can be translated to a single registered IP address. Port
numbers are used to distinguish the traffic i.e., which traffic belongs
to which IP address. This is most frequently used as it is
cost-effective as thousands of users can be connected to the Internet by using only one real global (public) IP address. 

**Advantages of NAT –** 

- NAT conserves legally registered IP addresses.
- It provides privacy as the device’s IP address, sending and receiving the traffic, will be hidden.
- Eliminates address renumbering when a network evolves.

**Disadvantage of NAT –** 

- Translation results in switching path delays.
- Certain applications will not function while NAT is enabled.
- Complicates tunneling protocols such as IPsec.
- Also, the router being a network layer device, should not tamper with port
numbers(transport layer) but it has to do so because of NAT.
*** Types of Network Address Translation (NAT)
Prerequisite – [Network address translation (NAT)](https://www.geeksforgeeks.org/computer-network-network-address-translation-nat/) Network
 Address Translation (NAT) is a process in which one or more local IP 
address is translated into one or more Global IP address and vice versa 
in order to provide Internet access to the local hosts. NAT generally 
operates on a router or firewall.

**Network address translation (NAT) working –** Generally,
 the border router is configured for NAT i.e the router which has one 
interface in the local (inside) network and one interface in the global 
(outside) network. When a packet traverse outside the local (inside) 
network, then NAT converts that local (private) IP address to a global 
(public) IP address. When a packet enters the local network, the global 
(public) IP address is converted to a local (private) IP address.

If
 NAT runs out of addresses, i.e., no address is left in the pool 
configured then the packets will be dropped and an Internet Control 
Message Protocol (ICMP) host unreachable packet to the destination is 
sent.

**NAT types –** There are 3 types of NAT:

**1. Static NAT –** In
 this, a single private IP address is mapped with a single Public IP 
address, i.e., a private IP address is translated to a public IP 
address. It is used in Web hosting.

**Configuration –**

!https://media.geeksforgeeks.org/wp-content/uploads/staticRFWE.png

Here
 is a small topology in which there is PC having IP address 
192.168.1.1/24, Router R1 having IP address 192.168.1.2/24 on interface 
fa0/0, 12.1.1.1/24 on fa0/1, and server having IP address 73.1.1.2/24.

Now,
 inside local and inside global are shown in the figure. Configuring the
 static NAT through command IP nat inside source static 
INSIDE_LOCAL_IP_ADDRESS INSIDE_GLOBAL_IP_ADDRESS. 

```
R1(config)# ip nat inside source static 192.168.1.1 12.1.1.1
```

Now, we have configured the router’s inside interface as IP NAT inside and outside interface as IP NAT outside. 

```
R1(config)# int fa0/0
R1(config-if)# ip nat inside
R1(config)# int fa0/1
R1(config-if)# ip nat outside
```

**2. Dynamic NAT –** In
 this type of NAT, multiple private IP addresses are mapped to a pool of
 public IP addresses. It is used when we know the number of fixed users 
who want to access the Internet at a given point in time.

**Configuration –**

!https://media.geeksforgeeks.org/wp-content/uploads/staticRFWE.png

There
 is a PC having IP address 192.168.1.1/24, Router R1 having IP address 
192.168.1.2/24 on interface fa0/0, 12.1.1.1/24 on fa0/1, and a server 
having IP address 73.1.1.2/24. Now, first configuring the access-list: 

```
R1(config)# access-list 1 permit 192.168.1.0 0.0.0.255
```

Configuring the nat pool from which a public IP will be selected. 

```
R1(config)# ip nat pool pool1 12.1.1.1 12.1.1.3 netmask 255.255.255.0
```

Now, enabling Dynamic NAT: 

```
R1(config)# ip nat inside source list 1 pool pool1
```

At last, we have to configure router interfaces as inside or outside. 

```
R1(config)# int fa0/0
R1(config-if)# ip nat inside
R1(config)# int fa0/1
R1(config-if)# ip nat outside
```

**3. Port Address Translation (PAT) –** This
 is also known as NAT overload. In this, many local (private) IP 
addresses can be translated to a single public IP address. Port numbers 
are used to distinguish the traffic, i.e., which traffic belongs to 
which IP address. This is most frequently used as it is cost-effective 
as thousands of users can be connected to the Internet by using only one
 real global (public) IP address.

**Configuration –**

!https://media.geeksforgeeks.org/wp-content/uploads/staticRFWE.png

Taking
 the same topology, There is PC1 having IP address 192.168.1.1/24, 
Router R1 has IP address 192.168.1.2/24 on interface fa0/0, 12.1.1.1/24 
on fa0/1, and the server has IP address 73.1.1.2/24. Now, first configuring the access-list: 

```
R1(config)# access-list 1 permit 192.168.1.0 0.0.0.255
```

Configuring the nat pool from which a public IP will be selected. 

```
R1(config)# ip nat pool pool1 12.1.1.1 12.1.1.1 netmask 255.255.255.0
```

Here,
 note that the nat pool is shrunk to one IP address only and the IP 
address used is the outside interface IP address of the router. If you 
have additional IP then you can use that also. Now, enabling Dynamic NAT overload (PAT): 

```
R1(config)# ip nat inside source list 1 pool pool1 overload
```

Or we can also use 

```
R1(config)# ip nat inside source list 1 interface fastEthernet 0/1 overload
```

At last, we have to configure router interfaces as inside or outside. 

```
R1(config)# int fa0/0
R1(config-if)# ip nat inside
R1(config)# int fa0/1
R1(config-if)# ip nat outside
```

**How NAT protect you:-**

- It hides the IP address of any devices on your network from the outside world giving them all a single address.
- It requires every incoming packet of information to have been asked for by a device. if a malicious data packet isn’t on the list of expected
communications it gets rejected.
- Some firewalls can use
whitelisting to block unauthorized outgoing traffic so if you do
contract a piece of malware your firewall may prevent it from
communicating with your device.

!https://media.geeksforgeeks.org/wp-content/post-ads-banner/2022-05-25-15-57-36-InterviewSeriesPrepareInArticleAd.webp
*** Classification of Routing Algorithms
Prerequisite – [Fixed and Flooding Routing algorithms](https://www.geeksforgeeks.org/computer-network-fixed-flooding-routing-algorithms/) **Routing** is
 the process of establishing the routes that data packets must follow to
 reach the destination. In this process, a routing table is created 
which contains information regarding routes that data packets follow. 
Various routing algorithms are used for the purpose of deciding which 
route an incoming data packet needs to be transmitted on to reach the 
destination efficiently.

**Classification of Routing Algorithms:** The routing algorithms can be classified as follows:

**1. Adaptive Algorithms –** These
 are the algorithms that change their routing decisions whenever network
 topology or traffic load changes. The changes in routing decisions are 
reflected in the topology as well as the traffic of the network. Also 
known as dynamic routing, these make use of dynamic information such as 
current topology, load, delay, etc. to select routes. Optimization 
parameters are distance, number of hops, and estimated transit time.

Further, these are classified as follows:

- **(a) Isolated –** In this method each, node makes its routing decisions using the
information it has without seeking information from other nodes. The
sending nodes don’t have information about the status of a particular
link. The disadvantage is that packets may be sent through a congested
network which may result in delay. Examples: Hot potato routing,
backward learning.
- **(b) Centralized –** In
this method, a centralized node has entire information about the network and makes all the routing decisions. The advantage of this is only one
node is required to keep the information of the entire network and the
disadvantage is that if the central node goes down the entire network is done. The link state algorithm is referred to as a centralized
algorithm since it is aware of the cost of each link in the network.
- **(c) Distributed –** In this method, the node receives information from its neighbors and
then takes the decision about routing the packets. A disadvantage is
that the packet may be delayed if there is a change in between intervals in which it receives information and sends packets. It is also known as a decentralized algorithm as it computes the least-cost path between
source and destination

**2. Non-Adaptive Algorithms –** These
 are the algorithms that do not change their routing decisions once they
 have been selected. This is also known as static routing as a route to 
be taken is computed in advance and downloaded to routers when a router 
is booted.

Further, these are classified as follows:

- **(a) Flooding –** This adapts the technique in which every incoming packet is sent on
every outgoing line except from which it arrived. One problem with this
is that packets may go in a loop and as a result of which a node may
receive duplicate packets. These problems can be overcome with the help
of sequence numbers, hop count, and spanning trees.
- **(b) Random walk –** In this method, packets are sent host by host or node by node to one of its neighbors randomly. This is a highly robust method that is usually
implemented by sending packets onto the link which is least queued.

**Routing v/s Flooding:**

!https://media.geeksforgeeks.org/wp-content/uploads/po.png
*** Types of Routing
Routing
 is a process that is performed by layer 3 (or network layer) devices in
 order to deliver the packet by choosing an optimal path from one 
network to another.

There are 3 types of routing: 

**1. Static routing –** Static routing is a process in which we have to manually add routes to the routing table.

**Advantages –**

- No routing overhead for router CPU which means a cheaper router can be used to do routing.
- It adds security because an only administrator can allow routing to particular networks only.
- No bandwidth usage between routers.

**Disadvantage –**

- For a large network, it is a hectic task for administrators to manually add each route for the network in the routing table on each router.
- The administrator should have good knowledge of the topology. If a new
administrator comes, then he has to manually add each route so he should have very good knowledge of the routes of the topology.

**Configuration –**

!https://media.geeksforgeeks.org/wp-content/uploads/ccoco-1.png

R1 having IP address 172.16.10.6/30 on s0/0/1, 192.168.10.1/24 on fa0/0. R2 having IP address 172.16.10.2/30 on s0/0/0, 192.168.20.1/24 on fa0/0. R3 having IP address 172.16.10.5/30 on s0/1, 172.16.10.1/30 on s0/0, 10.10.10.1/24 on fa0/0.

Now configuring static routes for router R3:

```
R3(config)#ip route 192.168.10.0 255.255.255.0 172.16.10.2
R3(config)#ip route 192.168.20.0 255.255.255.0 172.16.10.6
```

Here,
 provided the route for 192.168.10.0 network where 192.168.10.0 is its 
network I’d and 172.16.10.2 and 172.16.10.6 are the next-hop address. 

Now, configuring for R2:

```
R2(config)#ip route 192.168.20.0 255.255.255.0 172.16.10.1
R2(config)#ip route 10.10.10.0 255.255.255.0 172.16.10.1
R2(config)#ip route 172.16.10.0 255.255.255.0 172.16.10.1
```

Similarly for R1:

```
R1(config)#ip route 192.168.10.0 255.255.255.0 172.16.10.5
R1(config)#ip route 10.10.10.0 255.255.255.0 172.16.10.5
R1(config)#ip route 172.16.10.0 255.255.255.0 172.16.10.5
```

**2. Default Routing –** This
 is the method where the router is configured to send all packets 
towards a single router (next hop). It doesn’t matter to which network 
the packet belongs, it is forwarded out to the router which is 
configured for default routing. It is generally used with stub routers. A
 stub router is a router that has only one route to reach all other 
networks. 

**Configuration –** Using the same topology which we have used for the static routing before.

!https://media.geeksforgeeks.org/wp-content/uploads/ccoco-1.png

In this topology, R1 and R2 are stub routers so we can configure default routing for both these routers. 

Configuring default routing for R1:

```
R1(config)#ip route 0.0.0.0 0.0.0.0  172.16.10.5
```

Now configuring default routing for R2:

```
R2(config)#ip route 0.0.0.0 0.0.0.0  172.16.10.1
```

**3. Dynamic Routing –** Dynamic
 routing makes automatic adjustments of the routes according to the 
current state of the route in the routing table. Dynamic routing uses 
protocols to discover network destinations and the routes to reach them.
 [RIP](https://www.geeksforgeeks.org/computer-network-routing-vs-routed-protocols/) and [OSPF](https://www.geeksforgeeks.org/computer-network-open-shortest-path-first-ospf-protocol-fundamentals/)
 are the best examples of dynamic routing protocols. Automatic 
adjustments will be made to reach the network destination if one route 
goes down.

A dynamic protocol has the following features:

1. The routers should have the same dynamic protocol running in order to exchange routes.
2. When a router finds a change in the topology then the router advertises it to all other routers.

**Advantages –**

- Easy to configure.
- More effective at selecting the best route to a destination remote network and also for discovering remote network.

**Disadvantage –**

- Consumes more bandwidth for communicating with other neighbors.
- Less secure than static routing.
*** Classes of Routing Protocols
Prerequisite – [Distance vector routing protocol](https://www.geeksforgeeks.org/computer-network-routing-protocols-set-1-distance-vector-routing/), [Link state routing protocol](https://practice.geeksforgeeks.org/problems/link-state-routing) Routing
 is a process in which the layer 3 devices (either router or layer 3 
switches) find the optimal path to deliver a packet from one network to 
another. Dynamic routing protocols use metric, cost, and hop count to 
identify the best path from the path available for the destination 
network. There are mainly 3 different classes of routing protocols:

**1. Distance Vector Routing Protocol :**These
 protocols select the best path on the basis of hop counts to reach a 
destination network in a particular direction. Dynamic protocol like RIP
 is an example of a distance vector routing protocol. Hop count is each 
router that occurs in between the source and the destination network. 
The path with the least hop count will be chosen as the best path.

**Features –**

- Updates of the network are exchanged periodically.
- Updates (routing information) is not broadcasted but shared to neighbouring nodes only.
- Full routing tables are not sent in updates but only distance vector is shared.
- Routers always trust routing information received from neighbor routers. This is also known as routing on rumors.

**Disadvantages –**

- As the routing information is exchanged periodically, unnecessary traffic is generated which consumes available bandwidth.
- As full routing tables are exchanged, therefore it has security issues. If an **un-authorized** person enters the network, then the whole topology will be very easy to understand.
- Also, the broadcasting of the network periodically creates unnecessary traffic.

**2. Link State Routing Protocol :**These
 protocols know more about Internetwork than any other distance vector 
routing protocol. These are also known as SPF (Shortest Path First) 
protocol. OSPF is an example of link-state routing protocol.

**Features –**

- Hello, messages, also known as keep-alive messages are used for neighbor discovery and recovery.
- Concept of triggered updates is used i.e updates are triggered only when there is a topology change.
- Only that many updates are exchanged which is requested by the neighbor router.

Link state routing protocol maintains three tables namely:

1. **Neighbor table-** the table which contains information about the neighbors of the router only, i.e, to which adjacency has been formed.
2. **Topology table-** This table contains information about the whole topology i.e contains
both best and backup routes to a particular advertised networks.
3. **Routing table-** This table contains all the best routes to the advertised network. 

**Advantages –**

- As it maintains separate tables for both the best route and the backup
routes ( whole topology) therefore it has more knowledge of the
internetwork than any other distance vector routing protocol.
- Concept of triggered updates is used therefore no more unnecessary bandwidth
consumption is seen like in distance vector routing protocol.
- Partial updates are triggered when there is a topology change, not a full
update like distance vector routing protocol where the whole routing
table is exchanged.

**3. Advanced Distance vector routing protocol :**It is also known as hybrid routing protocol which uses the concept of both distance vector and link-state routing protocol. [Enhanced Interior Gateway Routing Protocol (EIGRP)](https://www.geeksforgeeks.org/computer-network-eigrp-fundamentals/)
 is an example of this class of routing protocol. EIGRP acts as a 
link-state routing protocol as it uses the concept of Hello protocol for
 neighbor discovery and forming an adjacency. Also, partial updates are 
triggered when a change occurs. EIGRP acts as a distance-vector routing 
protocol as it learned routes from directly connected neighbors.
*** Difference between Distance vector routing and Link State routing
Prerequisite – [Classification of Routing Algorithms](https://www.geeksforgeeks.org/computer-network-classification-routing-algorithms/)

**[Distance Vector Routing](https://www.geeksforgeeks.org/computer-network-routing-protocols-set-1-distance-vector-routing/) –**

- It is a dynamic routing algorithm in which each router computes a distance between itself and each possible destination i.e. its immediate
neighbors.
- The router shares its knowledge about the whole
network to its neighbors and accordingly updates the table based on its
neighbors.
- The sharing of information with the neighbors takes place at regular intervals.
- It makes use of **Bellman-Ford Algorithm** for making routing tables.
- **Problems –** Count to infinity problem which can be solved by splitting horizon. **–** Good news spread fast and bad news spread slowly. **–** Persistent looping problem i.e. loop will be there forever.

**[Link State Routing](https://practice.geeksforgeeks.org/problems/what-is-link-state-routing-protocol) –**

- It is a dynamic routing algorithm in which each router shares knowledge of its neighbors with every other router in the network.
- A router sends its information about its neighbors only to all the routers through flooding.
- Information sharing takes place only whenever there is a change.
- It makes use of **Dijkstra’s Algorithm** for making routing tables.
- **Problems –** Heavy traffic due to flooding of packets. **–** Flooding can result in infinite looping which can be solved by using the **Time to live (TTL)** field.
    
    *Comparison between Distance Vector Routing and Link State Routing:*
    

!https://media.geeksforgeeks.org/wp-content/uploads/po-1.png
*** Fixed and Flooding Routing algorithms
In 
most situations, packets require multiple hops to make a journey towards
 the destination. Routing is one of the most complex and crucial aspects
 of packet-switched network design.

**Desirable Properties of Routing Algorithms**:-

- Correctness and Simplicity
- Robustness: Ability of the network to deliver packets via some route even in the face of failures.
- Stability: The algorithm should converge to equilibrium fast in the face of changing conditions in the network.
- Fairness and Optimality
- Efficiency: Minimum overhead.

**Design Parameters of Routing Algorithms :**

- Performance Criteria: Number of hops, Cost(Send packet with high bandwidth path as
the cost is less), Delay(Size of Queue), Throughput time(Number of
packets delivered/time).
- Decision Time: When to decide to route a packet? Per-Packet(Datagram) or Per-session(Virtual-Circuit).
- Decision Place: Who will decide about routing? Each Node(distributed), Central Node (centralized),Originated Node (source) .
- Network Information Source: None, Local, Adjacent node, Nodes along the route, All nodes.
- Network Information Update Time: Continuous, Periodic, Major Load Change, Topology Change.

**Routing Strategies :**

1. Fixed Routing
2. Flooding
3. Dynamic Routing
4. Random Routing
5. Flow-based Routing

**Fixed Routing –**

- A route is selected for each source and destination pair of nodes in the network.
- The route is fixed; changes only if the topology of the network changes.

Fixed Routing: Example (1)

!https://media.geeksforgeeks.org/wp-content/uploads/networking.png

**Figure –** A simple packet switching network with six nodes (routers)

!https://media.geeksforgeeks.org/wp-content/uploads/network.png

**Figure –** Central routing table based on least-cost path algorithm

- A Central routing matrix is created based on the least-cost path which is stored in the network control center
- The matrix shows for each source-destination of the route, the identity of the next node on the route.
- Drawback: If the network control center fails, then everything will collapse. Hence it is not reliable.

Fixed Routing: Example (2)

!https://media.geeksforgeeks.org/wp-content/uploads/netwk.png

**Figure –** Routing table stored in different nodes of the network

- Routing Table is created for each node. This is called a distributed routing algorithm
- Routing table can be created using the least-min path or min-hop reach method. Two famous path algorithms
    1. Dijkstra Algorithm
    2. Bellman Ford Algorithm

**Advantages –**

- Simple
- Works well in reliable network with stable load in a reliable network
- Same for virtual circuit and datagram

**Disadvantages –** 

- Lack of flexibility
- Doesn’t react to failure or network congestion

**Flooding –**

- Requires no network information like topology, load condition, cost of diff. paths
- Every incoming packet to a node is sent out on every outgoing like except the one it arrived on.
- For Example in the above figure
    - An incoming packet to (1) is sent out to (2),(3)
    - from (2) is sent to (6),(4), and from (3) it is sent to (4),(5)
    - from (4) it is sent to (6),(5),(3), from (6) it is sent to (2),(4),(5), from (5) it is sent to (4),(3)

**Characteristics –**

- All possible routes between Source and Destination are tried. A packet will always get through if the path exists
- As all routes are tried, there will be at least one route which is the shortest
- All nodes directly or indirectly connected are visited

**Limitations –** 

- Flooding generates a vast number of duplicate packets
- Suitable damping mechanism must be used

**Hop-Count –** 

- A hop counter may be contained in the packet header which is decremented at each hop. with the packet being discarded when the counter becomes zero
- The sender initializes the hop counter. If no estimate is known, it is set to the full diameter of the subnet.
- Keep track of the packets which are responsible for flooding using a sequence number. Avoid sending them out a second time.

Selective
 Flooding: Routers do not send every incoming packet out on every line, 
only on those lines that go in approximately in the direction of the 
destination.

**Advantages of Flooding :**

- Highly Robust, emergency or immediate messages can be sent (eg military applications)
- Set up the route in virtual circuit
- Flooding always chooses the shortest path
- Broadcast messages to all the nodes

**Reference –** [Data and Computer Communications](https://www.amazon.in/Computer-Communications-William-Stallings-Books/dp/0133506487)

Read next article – [Routing Protocols Set 1 (Distance Vector Routing)](https://www.geeksforgeeks.org/computer-network-routing-protocols-set-1-distance-vector-routing/)
*** Routing Protocols Set 1 (Distance Vector Routing)
The 
Network Layer of the OSI Model is responsible for providing logical 
addressing, which routers use to select best path for routing packets. 
There are two types of packets used at this layer :

1. **Data Packets –**The user data is transferred in the inter-network by these data packets. **Routed protocols** are those protocols which support such data traffic. Examples of routed protocols are IPv4, IPv6 and AppleTalk.
2. **Route Update Packets –**The information about the networks connected to all the routers is updated
to the neighbouring routers through route update packets. **Routing protocols** are the ones that are responsible for sending them. Examples of routing protocols are RIP(Routing Information Protocol), EIGRP(Enhanced
Interior Gateway Routing Protocol) and OSPF(Open Shortest Path First).

Now let’s take an real-life analogy to better understand the difference between routed and routing protocols.

Suppose
 you want to go to your home after your semester examinations. You book a
 cab or take a bus to your home. In the path of your journey, you 
encounter several sign boards which help you take proper or best path, 
or in case of a cab, Google Maps will help you in choosing the best 
route.

In this analogy, consider yourself as the DATA, the bus or 
cab as the ROUTED PROTOCOL and the sign boards or the GPS installed in 
your driver’s phone as the ROUTING PROTOCOL.Similarly, in a network 
routers use routing protocols to determine the best path for a packet to
 travel through the inter-network more efficiently. Routed protocols are
 assigned to an interface and determine the method of delivering the 
packet.

Now, lets move on to the different types of routing protocols.

!https://media.geeksforgeeks.org/wp-content/uploads/Routing-Protocols.png

**Abbreviations –IGP** – Interior Gateway Protocol**EGP** – Exterior Gateway Protocol**RIP** – Routing Information Protocol**IGRP** – Interior Gateway Routing Protocol**OSPF** – Open Shortest Path First**ISIS** – Intermediate System to Intermediate System**EIGRP** – Enhanced Interior Gateway Routing Protocol**BGP** – Border Gateway Protocol

**References –**[Todd Lammle e-book](http://www.innos.in/downloads/CISCO%20-%20640-802-ccna.pdf)[Wikipedia](https://en.wikipedia.org/wiki/Routing_protocol)
*** Unicast Routing – Link State Routing
Prerequisite – [Distance Vector Routing](https://www.geeksforgeeks.org/computer-network-routing-protocols-set-1-distance-vector-routing/), [Dijkstra algorithm](https://www.geeksforgeeks.org/greedy-algorithms-set-6-dijkstras-shortest-path-algorithm/), [Distance vector routing v/s Link state routing](https://www.geeksforgeeks.org/computer-network-distance-vector-routing-vs-link-state-routing/), [OSPF](https://www.geeksforgeeks.org/open-shortest-path-first-ospf-router-roles-configuration/), [RIP](https://www.geeksforgeeks.org/computer-network-routing-information-protocol-rip/) **Unicast –**
 Unicast means the transmission from a single sender to a single 
receiver. It is a point-to-point communication between sender and 
receiver. There are various unicast protocols such as TCP, HTTP, etc.

- TCP is the most commonly used unicast protocol. It is a connection-oriented protocol that relies on acknowledgement from the receiver side.
- HTTP stands for HyperText Transfer Protocol. It is an object-oriented protocol for communication.

There are three major protocols for unicast routing:

1. Distance Vector Routing
2. Link State Routing
3. Path-Vector Routing

**Link State Routing –** Link
 state routing is the second family of routing protocols. While 
distance-vector routers use a distributed algorithm to compute their 
routing tables, link-state routing uses link-state routers to exchange 
messages that allow each router to learn the entire network topology. 
Based on this learned topology, each router is then able to compute its 
routing table by using the shortest path computation.

**Features of link state routing protocols –**

- **Link state packet –** A small packet that contains routing information.
- **Link state database –** A collection of information gathered from the link-state packet.
- **Shortest path first algorithm (Dijkstra algorithm) –** A calculation performed on the database results in the shortest path
- **Routing table –** A list of known paths and interfaces.

**Calculation of shortest path –** To find the shortest path, each node needs to run the famous **Dijkstra algorithm**. This famous algorithm uses the following steps:

- **Step-1:** The node is taken and chosen as a root node of the tree, this creates
the tree with a single node, and now set the total cost of each node to
some value based on the information in Link State Database
- **Step-2:** Now the node selects one node, among all the nodes not in the tree-like structure, which is nearest to the root, and adds this to the tree. The shape of the tree gets changed.
- **Step-3:** After
this node is added to the tree, the cost of all the nodes not in the
tree needs to be updated because the paths may have been changed.
- **Step-4:** The node repeats Step 2. and Step 3. until all the nodes are added to the tree

Link State protocols in comparison to Distance Vector protocols have:

1. It requires a large amount of memory. 
2. Shortest path computations require many CPU circles. 
3. If a network uses little bandwidth; it quickly reacts to topology changes 
4. All items in the database must be sent to neighbors to form link-state packets. 
5. All neighbors must be trusted in the topology. 
6. Authentication mechanisms can be used to avoid undesired adjacency and problems. 
7. No split horizon techniques are possible in the link-state routing.
    - Open Shortest Path First (OSPF) is a unicast routing protocol developed by a working group of the Internet Engineering Task Force (IETF).
    - It is an intradomain routing protocol.
    - It is an open-source protocol.
    - It is similar to Routing Information Protocol (RIP)
    - OSPF is a classless routing protocol, which means that in its updates, it
    includes the subnet of each route it knows about, thus, enabling
    variable-length subnet masks. With variable-length subnet masks, an IP
    network can be broken into many subnets of various sizes. This provides
    network administrators with extra network configuration flexibility.
    These updates are multicasts at specific addresses (224.0.0.5 and
    224.0.0.6).
    - OSPF is implemented as a program in the network layer using the services provided by the Internet Protocol
    - IP datagram that carries the messages from OSPF sets the value of the protocol field to 89
    - OSPF is based on the SPF algorithm, which sometimes is referred to as the Dijkstra algorithm
    - OSPF has two versions – version 1 and version 2. Version 2 is used mostly

**OSPF Messages** – OSPF is a very complex protocol. It uses five different types of messages. These are as follows:

1. **Hello message (Type 1) –** It is used by the routers to introduce themselves to the other routers. 
2. **Database description message (Type 2) –** It is normally sent in response to the Hello message. 
3. **Link-state request message (Type 3) –** It is used by the routers that need information about specific Link-State packets. 
4. **Link-state update message (Type 4) –** It is the main OSPF message for building Link-State Database. 
5. **Link-state acknowledgement message (Type 5) –** It is used to create reliability in the OSPF protocol.
*** Distance Vector Routing (DVR) Protocol
A **distance-vector routing (DVR)**
 protocol requires that a router inform its neighbors of topology 
changes periodically. Historically known as the old ARPANET routing 
algorithm (or known as Bellman-Ford algorithm).

**Bellman Ford Basics –**
 Each router maintains a Distance Vector table containing the distance 
between itself and ALL possible destination nodes. Distances,based on a 
chosen metric, are computed using information from the neighbors’ 
distance vectors.

```
Information kept by DV router -
Each router has an IDAssociated with each link connected to a router,
there is a link cost (static or dynamic).Intermediate hops
Distance Vector Table Initialization -Distance to itself = 0Distance to ALL other routers = infinity number.
```

**Distance Vector Algorithm –**

1. A router transmits its distance vector to each of its neighbors in a routing packet.
2. Each router receives and saves the most recently received distance vector from each of its neighbors.
3. A router recalculates its distance vector when:
    - It receives a distance vector from a neighbor containing different information than before.
    - It discovers that a link to a neighbor has gone down.

The DV calculation is based on minimizing the cost to each destination

```
Dx(y) = Estimate of least cost from x to y
C(x,v) =  Node x knows cost to each neighbor v
Dx   =  [Dx(y): y ∈ N ] = Node x maintains distance vector
Node x also maintains its neighbors' distance vectors
– For each neighbor v, x maintains Dv = [Dv(y): y ∈ N ]

```

**Note –**

- From time-to-time, each node sends its own distance vector estimate to neighbors.
- When a node x receives new DV estimate from any neighbor v, it saves v’s
distance vector and it updates its own DV using B-F equation:
    
    ```
    Dx(y) = min { C(x,v) + Dv(y), Dx(y) } for each node y ∈ N
    
    ```
    

**Example –**

Consider 3-routers X, Y and Z as 
shown in figure. Each router have their routing table. Every routing 
table will contain distance to the destination nodes.

!https://media.geeksforgeeks.org/wp-content/uploads/DVP1.jpg

Consider
 router X , X will share it routing table to neighbors and neighbors 
will share it routing table to it to X and distance from node X to 
destination will be calculated using bellmen- ford equation.

```
 Dx(y) = min { C(x,v) + Dv(y)} for each node y ∈ N

```

As we can see that distance will be less going from X to Z when
 Y is intermediate node(hop) so it will be update in routing table X.

!https://media.geeksforgeeks.org/wp-content/uploads/dvp2.jpg

Similarly for Z also –

!https://media.geeksforgeeks.org/wp-content/uploads/dvp3.jpg

Finally the routing table for all –

!https://media.geeksforgeeks.org/wp-content/uploads/dvp4.jpg

**Advantages of Distance Vector routing –**

- It is simpler to configure and maintain than link state routing.

**Disadvantages of Distance Vector routing –**

- It is slower to converge than link state.
- It is at risk from the count-to-infinity problem.
- It creates more traffic than link state since a hop count change must be
propagated to all routers and processed on each router. Hop count
updates take place on a periodic basis, even if there are no changes in
the network topology, so bandwidth-wasting broadcasts still occur.
- For larger networks, distance vector routing results in larger routing
tables than link state since each router must know about all other
routers. This can also lead to congestion on WAN links.

**Note –** Distance Vector routing uses UDP(User datagram protocol) for transportation.

*** Route Poisoning and Count to infinity problem in Routing
The main issue with **D**istance Vector **R**outing (DVR) protocols is Routing Loops since [Bellman-Ford Algorithm](https://www.geeksforgeeks.org/dynamic-programming-set-23-bellman-ford-algorithm/)
 cannot prevent loops. This routing loop in the DVR network causes the 
Count to Infinity Problem. Routing loops usually occur when an interface
 goes down or two routers send updates at the same time.

**Counting to infinity problem:**

!https://media.geeksforgeeks.org/wp-content/uploads/counting-to-infinity.jpg

So
 in this example, the Bellman-Ford algorithm will converge for each 
router, they will have entries for each other. B will know that it can 
get to C at a cost of 1, and A will know that it can get to C via B at a
 cost of 2. 

!https://media.geeksforgeeks.org/wp-content/uploads/counting-to-infinity2.jpg

If
 the link between B and C is disconnected, then B will know that it can 
no longer get to C via that link and will remove it from its table. 
Before it can send any updates it’s possible that it will receive an 
update from A which will be advertising that it can get to C at a cost 
of 2. B can get to A at a cost of 1, so it will update a route to C via A
 at a cost of 3. A will then receive updates from B later and update its
 cost to 4. They will then go on feeding each other bad information 
toward infinity which is called as **Count to Infinity problem**.

### Solution for Count to Infinity problem:-

**Route Poisoning:** When a route fails, distance vector protocols spread the *bad news*
 about a route failure by poisoning the route. Route poisoning refers to
 the practice of advertising a route, but with a special metric value 
called Infinity. Routers consider routes advertised with an infinite 
metric to have failed. Each distance vector routing protocol uses the 
concept of an actual metric value that represents infinity. RIP defines 
infinity as 16. The main disadvantage of poison reverse is that it can 
significantly increase the size of routing announcements in certain 
fairly common network topologies.

!https://media.geeksforgeeks.org/wp-content/uploads/route-poison.jpg

**Split horizon:** If
 the link between B and C goes down, and B had received a route from A, B
 could end up using that route via A. A would send the packet right back
 to B, creating a loop. But according to the Split horizon Rule, Node A 
does not advertise its route for C (namely A to B to C) back to B. On 
the surface, this seems redundant since B will never route via node A 
because the route costs more than the direct route from B to C.

Consider the following network topology showing Split horizon-

!https://media.geeksforgeeks.org/wp-content/uploads/route-poison2.jpg

- In addition to these, we can also use split horizon with route poisoning
were above both techniques will be used combined to achieve efficiency
and less increase the size of routing announcements.
- Split
horizon with Poison reverse technique is used by Routing Information
Protocol (RIP) to reduce routing loops. Additionally, **Holddown timers** can be used to avoid the formation of loops. The hold-down timer
immediately starts when the router is informed that the attached link is down. Till this time, the router ignores all updates of the down route
unless it receives an update from the router of that downed link. During the timer, If the downlink is reachable again, the routing table can be updated.

**References:** https://en.wikipedia.org/wiki/Distance-vector_routing_protocol#Count-to-infinity_problem https://en.wikipedia.org/wiki/Route_poisoning https://en.wikipedia.org/wiki/Split_horizon_route_advertisement
*** Onion Routing
Onion
 routing is a technique for anonymous communication over a computer 
network. In an onion network, messages are encapsulated in layers of 
encryption, analogous to layers of an onion.

There
 is a large set of precautionary measures and best practices to make web
 browsing safer and more secure for users. Let’s say that you send an 
HTTPS request to a server and someone intercepts that request but that 
person can’t know what that message says because it’s encrypted. But you
 are still not satisfied with this level of security and want to take 
this to the next level i.e. you don’t even want anyone sniffing on your 
network to know which server you are contacting and if you are making 
any requests or not. This is where onion routing comes in.

The 
Onion Routing program consists of studies that investigate, design, 
construct and analyze anonymous communication networks. The focus is on 
realistic solutions for low-latency Internet-based connections that can 
withstand traffic analysis, eavesdropping, and other attacks from both 
outsiders (such as Internet routers) and insiders (such as hackers) 
(Onion Routing servers themselves). Onion Routing hides who is 
communicating with whom from the transport medium; the network just 
knows that communication is taking place. Furthermore, until the 
transmission leaves the OR network, the content of the conversation 
remains hidden from eavesdroppers.

Refer to [this](https://en.wikipedia.org/wiki/Onion_routing#/media/File:Onion_diagram.svg) image for details.

**How does onion routing work?**

If
 you are browsing the internet on a normal web browser like chrome, 
firefox, etc you request webpages by making simple GET requests to 
servers without any intermediary. It’s just a single connection between a
 client and a server and someone sniffing on your network can know which
 server your computer is contacting.

- Onion routing does this differently. In onion routing, the connection is maintained between
different nodes i.e. the connection hops from one server to another and
when it reaches the last server on this circuit it is the server that we wanted to contact and it will process our request and serve us the
desired webpage which is sent back to us using the same network of
nodes.
- Now you must think why is it called the onion router. It
is because the message we send and the responses we receive are
encrypted with different keys, with a unique key for encryption for
every different hop or server visit.
- The client has access to
all the keys but the servers only have access to the keys specific for
encryption/decryption to that server.
- Since this process **wraps your message under layers of encryption** which have to be peeled off at each different hop just like an onion that’s why it’s called an onion router.

**Understanding Onion routing concept an example**

Now
 suppose you are browsing the internet using Tor(the onion router) which
 is a special browser that lets you use the onion routers. You want to 
access YouTube but you live in China and since YouTube is banned in 
China you don’t want your government to know that you are visiting 
YouTube so you decide to use Tor. Your computer needs to contact a 
particular server to get the homepage of YouTube but it doesn’t directly
 contact that server. It does that through 3 nodes/servers/routers 
(these servers are maintained all over the world by volunteers) before 
that server so that no one can trace back your conversation with that 
server. To make this example simple I am using 3 nodes but a real Tor 
network can have hundreds of nodes in between.

!https://media.geeksforgeeks.org/wp-content/uploads/Onion-Routing-Page-1.png

Onion Routing Circuit(made using lucid chart)

1. The client with access to all the encryption keys i.e **key 1, key 2 & key 3** encrypts the message(get request) thrice wrapping it under 3 layers like an onion which have to be peeled one at a time.
2. This **triple encrypted message** is then sent to the first server i.e. **Node 1(Input Node).**
3. **Node 1** only has the address of **Node 2** and **Key 1**. So it **decrypts** the message using **Key 1** and realizes that it doesn’t make any sense since it still has 2 layers of encryption so it passes it on to **Node 2**
4. **Node 2** has **Key 2** and the addresses of the **input & exit nodes.** So it **decrypts** the message using **Key 2** realizes that it’s still **encrypted** and passes it onto the **exit node**
5. **Node 3 (exit node)** peels off the last layer of encryption and finds a **GET request** for youtube.com and passes it onto the **destination server**
6. The server processes the request and serves up the desired webpage as a **response.**
7. The response passes through the same nodes in the reverse direction where each node puts on a **layer of encryption** using their specific key
8. It finally reaches the client in the form of a **triple encrypted** response which can be decrypted since the client has access to all the keys

**How does it provide anonymity?**

Imagine if there is a sniffer listening in at the first connection(client – input node) **all it can know is the address of the input node and a thrice encrypted message** that doesn’t make sense. So all the attacker/sniffer knows that you are browsing tor. Similarly,
 if sniffing starts at the exit node all the sniffer sees is a server 
contacting another server but it can’t track the client or the source of
 the request generated. But now you may think that if someone is 
listening in at Node 2 they will know the address of the input and exit 
and can trace the client and the destination server. But it’s not that 
simple, each of these nodes has hundreds of concurrent connections going
 on, and to know which one leads to the right source and destination is 
not that easy. In our circuit, Node 2 is a middle node but it can be a 
part of another circuit on a different connection where it acts as the 
input node receiving requests or an exit node serving up webpages from 
various servers.

**Vulnerability in Onion Routing**

The
 only security flaw in onion routing is that if someone is listening in 
on a server at the same time and matches the request at the destination 
to a request made by a client on the other side of a network by 
analyzing the length and the frequency of the characters found in the 
intercepted request or response at the destination server and using that
 to match with the same request made by a client a fraction of a second 
(time-stamps on requests and responses can also be helpful in deducing 
that) and then tracking them down and knowing their online activity and 
shattering the idea of anonymity. This is pretty hard to do but not 
impossible. But removing this flaw from Tor is virtually impossible.

**References:** [Computerphile](https://www.youtube.com/user/Computerphile)
*** Configuration of Router on a stick
Prerequisite – [Access and trunk ports](https://www.geeksforgeeks.org/access-trunk-ports/)Switches
 divide broadcast domain through VLAN (Virtual LAN). VLAN is a 
partitioned broadcast domain from a single broadcast domain. Switch 
doesn’t forward packets across different VLANs by itself. If we want to 
make these virtual LANs communicate with each other, a concept of **Inter VLAN Routing** is used.

**Inter VLAN Routing :**

Inter
 VLAN routing is a process in which we make different virtual LANs 
communicate with each other irrespective of where the VLANs are present 
(on same switch or different switch). Inter VLAN Routing can be achieved
 through a layer-3 device i.e. Router or layer-3 Switch. When the Inter 
VLAN Routing is done through Router it is known as **Router on a stick**. **Router On a Stick :**

The Router’s interface is divided into sub-interfaces, which acts as a default gateway to their respective VLANs.

**Configuration :**

!https://media.geeksforgeeks.org/wp-content/uploads/hsrp1.png

Here
 is a topology in which there is a router and a switch and some end 
hosts. 2 different VLANs have been created on the switch. The router’s 
interface is divided into 2 sub-interfaces (as there are 2 different 
VLANs) which will acts as a default gateway to their respective VLANs. 
Then router will perform Inter VLAN Routing and the VLANs will 
communicate with each other.

> First we will assign IP 
address to the host PC1 as 192.168.1.10/24, Server 192.168.1.20/24, and 
the other host PC2 will have IP address 192.168.2.10/24 manually.
> 
> 
> Now,
>  we will make sub-interface of fa0/0 as fa0/0.1 and fa0/0.2 and assign 
> IP addresses as 192.168.1.1/24 and 192.168.2.1/24 respectively on the 
> router’s ports.
> 

```
r1# int fa0/0.1
r1# encapsulation dot1q 2
r1# ip address 192.168.1.1  255.255.255.0
r1# int fa0/0.2
r1# encapsulation dot1q 3
r1# ip address 192.168.2.1 255.255.255.0
```

**NOTE :** Here encapsulation type **dot1q** is
 used for frame tagging between the 2 different VLAN. When the switch 
forwards packet of one VLAN to another, it inserts a VLAN into the 
Ethernet header.

Now, we will make 2 different VLANs on switch namely VLAN 2 and VLAN 3 giving names *HR_dept* and *sales_dept*.

```
Switch# vlan 2
Switch# name HR_dept
Switch# vlan 3
Switch# name sales_dept
```

```
Switch# int range fa0/1-2
Switch# switchport mode access
Switch# switchport access vlan 2
Switch# int fa0/3
Switch# switchport mode access
Switch# switchport access vlan 3
```

Here, we have assigned VLAN 2 to the specific switch ports fa0/1, fa0/2 and vlan 3 to fa0/3 respectively.

**NOTE :**

*int range fa0/1-2*

command is used as there are more than one host present in a single VLAN.

Now to check reachability of PC2 from PC1, we will try to PING PC2 from PC1.

!https://media.geeksforgeeks.org/wp-content/uploads/hsrp2.png

!https://media.geeksforgeeks.org/wp-content/uploads/hsrp3.png

!https://media.geeksforgeeks.org/wp-content/uploads/hsrp4.png

!https://media.geeksforgeeks.org/wp-content/uploads/hsrp5.png

!https://media.geeksforgeeks.org/wp-content/uploads/hsrp6.png

From
 the above figures, we see that the packet is delivered to the router by
 the switch, because now the broadcast domain have been divided by the 
different VLANs present on the switch therefore, the packet will be 
delivered to the default gateway (as PC2 is present on different 
network) and then to the destination.
*** Internet Control Message Protocol (ICMP)
Since
 IP does not have an inbuilt mechanism for sending error and control 
messages. It depends on Internet Control Message Protocol(ICMP) to 
provide an error control. It is used for reporting errors and management
 queries. It is a supporting protocol and is used by networks devices 
like routers for sending error messages and operations information., 
e.g. the requested service is not available or that a host or router 
could not be reached. 

**ICMPv4 Packet Format :**

!https://media.geeksforgeeks.org/wp-content/uploads/20211107223027/gfg.png

**Source quench message :**Source
 quench message is a request to decrease the traffic rate for messages 
sending to the host(destination). Or we can say when receiving host 
detects that the rate of sending packets (traffic rate) to it is too 
fast it sends the source quench message to the source to slow the pace 
down so that no packet can be lost.

!https://media.geeksforgeeks.org/wp-content/uploads/1-73.png

ICMP will take the source IP from the discarded packet and informs the source by sending a source quench message.

Then source will reduce the speed of transmission so that router will be free from congestion.

!https://media.geeksforgeeks.org/wp-content/uploads/2-46.png

When
 the congestion router is far away from the source the ICMP will send 
hop by hop source quench message so that every router will reduce the 
speed of transmission. 

**Parameter problem :**Whenever
 packets come to the router then the calculated header checksum should 
be equal to the received header checksum then the only the packet is 
accepted by the router.

!https://media.geeksforgeeks.org/wp-content/uploads/3-53.png

If there is a mismatch packet will be dropped by the router.

ICMP will take the source IP from the discarded packet and informs to the source by sending a parameter problem message. 

**Time exceeded message :**

!https://media.geeksforgeeks.org/wp-content/uploads/4-30.png

When
 some fragments are lost in a network then the holding fragment by the 
router will be dropped then ICMP will take the source IP from the 
discarded packet and informs the source, of discarded datagram due to 
time to live field reaches zero, by sending time exceeded message.

**Destination un-reachable :**Destination
 unreachable is generated by the host or its inbound gateway to inform 
the client that the destination is unreachable for some reason.

!https://media.geeksforgeeks.org/wp-content/uploads/5-21.png

There
 is no necessary condition that the only the router gives the ICMP error
 message some time the destination host sends an ICMP error message when
 any type of failure (link failure, hardware failure, port failure, etc)
 happens in the network.

**Redirection message :**Redirect
 requests data packets are sent on an alternate route. The message 
informs a host to update its routing information (to send packets on an 
alternate route).

**Ex.** If the host tries to send 
data through a router R1 and R1 sends data on a router R2 and there is a
 direct way from the host to R2. Then R1 will send a redirect message to
 inform the host that there is the best way to the destination directly 
through R2 available. The host then sends data packets for the 
destination directly to R2. The router R2 will send the original datagram to the intended destination. But
 if the datagram contains routing information then this message will not
 be sent even if a better route is available as redirects should only be
 sent by gateways and should not be sent by Internet hosts.

!https://media.geeksforgeeks.org/wp-content/uploads/6-18.png

Whenever
 a packet is forwarded in a wrong direction later it is re-directed in a
 current direction then ICMP will send a re-directed message.
 
*** Hot Standby Router Protocol (HSRP)
Hot 
Standby Router Protocol (HSRP) is a CISCO proprietary protocol, which 
provides redundancy for a local subnet. In HSRP, two or more routers 
gives an illusion of a virtual router.

HSRP
 allows you to configure two or more routers as standby routers and only
 a single router as an active router at a time. All the routers in a 
single HSRP group shares a single MAC address and IP address, which acts
 as a default gateway to the local network. The *Active router* is responsible for forwarding the traffic. If it fails, the *Standby router* takes up all the responsibilities of the active router and forwards the traffic.

### Some important terms related to HSRP :

1. **Virtual IP :** IP address from local subnet is assigned as default gateway to all local hosts in the network.
2. **Virtual MAC address** : MAC address is generated automatically by HSRP. The first 24 bits
will be default CISCO address (i.e. 0000.0c). The next 16 bits are ***HSRP ID*** (i.e. 07.ac). The next 8 bits will be the group number in hexadecimal.
e.g- if the group number is 10 then the last 8 bits will be 0a. Example of virtual MAC address –
    
    ```
    0000.0c07.ac0a
    ```
    
3. **Hello messages :** Periodic messages exchanged by active and standby routers. These messages are
exchanged after every 3 seconds telling the state of router.
4. **Hold down timer :** Its default value is 10 seconds i.e roughly 3 times the value of hello
message. This timer tells us about the router that how much time will
the standby router waits for hello message if it is not received on
time.
    
    > Note : If the active router fails then the standby router will become the active router.
    > 
5. **Priority :** By default, the priority value is 100. It is helpful when the active
router comes back after falling down, we can change the priority of
standby router (which has become the active router after the original
active router is down) to less than 100 therefore it again becomes
standby router.
    
    > Note : The router having higher priority will become the active router.
    > 
6. **Preempt :** It is a state in which the standby router automatically becomes the active router.

### WORKING :

Members
 having same group ID are the members of same group. One of the member 
of the group will be elected as the active router while others remain as
 standby routers. The virtual IP is configured as default gateway of all
 the hosts in the local subnet and the active router is responsible for 
forwarding the traffic of local hosts. If the active router goes down 
then the hello messages are not exchanged between the active and the 
standby routers therefore the standby router waits until the hold-down 
timer time. As soon as the hold down time is finished, the standby 
router will become the active router and take up all the 
responsibilities of active router. This is known as preempt.If in 
case the original active router comes back then we can decrease the 
priority of the standby router so that it will become the standby router
 again.

### Hot Standby Router Protocol (HSRP) has **2-versions** :

**version 1 :** The messages are multicast at 224.0.0.2 and uses the UDP port 1985. This version allows group number range from 0 to 255.**version 2 :** The messages are multicast at 224.0.0.102 and uses the UDP port 1985. This version allows group number range from 0 to 4095.

### CONFIGURATION :

!https://media.geeksforgeeks.org/wp-content/uploads/hsrp.png

Consider above given topology. There are 2 routers named

**R1**

and

**R2**

. IP address of R1 (f 0/0) is 10.1.1.1/24 and R2 (f 0/0) is 10.1.1.2/24.

**Assigning IP address to router R1.**

```
r1#(config) int fa0/0
r1#(config-if)ip add 10.1.1.1 255.255.255.0
```

**Assigning IP address to router R2.**

```
r2#(config) int fa0/0
r2#(config-if)ip address 10.1.1.2 255.255.255.0
```

Now, Let’s provide virtual IP address (10.1.1.100), group name *HSRP_TEST*,
 group number 1and priority 110. Also, preempt has been enabled i.e. if 
the active router goes down then the standby router automatically 
becomes the active router.

```
r1#(config-if) standby 1 ip 10.1.1.100
r1#(config-if) standby 1 name HSRP_TEST
r1#(config-if) standby 1 priority 110
r1#(config-if) standby 1 preempt
```

Now, we will provide virtual IP address (10.1.1.100), group name *HSRP_TEST* and priority 100. Also, group number 1 and preempt has been enabled.

```
r2#(config) int fa0/0
r2#(config-if) standby 1 ip 10.1.1.100
r2#(config-if) standby 1 name HSRP_TEST
r2#(config-if) standby 1 priority 100
r2#(config-if) standby 1 preempt
```

**Note :** As we have provided priority 110 to r1, therefore it will become the active router.
*** Open Shortest Path First (OSPF) Protocol fundamentals
Open shortest path first (OSPF) is a **link-state routing protocol**
 that is used to find the best path between the source and the 
destination router using its own shortest path first (SPF) algorithm. A 
link-state routing protocol is a protocol that uses the concept of 
triggered updates, i.e., if there is a change observed in the learned 
routing table then the updates are triggered only, not like the 
distance-vector routing protocol where the routing table is exchanged at
 a period of time.

Open
 shortest path first (OSPF) is developed by Internet Engineering Task 
Force (IETF) as one of the Interior Gateway Protocol (IGP), i.e., the 
protocol which aims at moving the packet within a large autonomous 
system or routing domain. It is a **network layer protocol**
 that works on protocol number 89 and uses AD value 110. OSPF uses 
multicast address 224.0.0.5 for normal communication and 224.0.0.6 for 
update to designated router(DR)/Backup Designated Router (BDR).

**Criteria –** To form neighbourship in OSPF, there is a criterion for both the routers:

1. It should be present in the same area.
2. The router I’d be unique.
3. The subnet mask should be the same.
4. Hello, and the dead timer should be the same.
5. The stub flag must match.
6. Authentication must match. 

OSPF supports NULL, plain text, MD5 authentication.

**Note –**
 Both the routers (neighbors) should have some type of authentication 
enabled. e.g- if one neighbor has MD5 authentication enabled then others
 should also have MD5 authentication enabled.

**OSPF messages –** OSPF uses certain messages for the communication between the routers operating OSPF.

- **Hello message –** These are keep-alive messages used for neighbor discovery /recovery. These
are exchanged every 10 seconds. This includes the following information: Router I’d, Hello/dead interval, Area I’d, Router priority, DR and BDR
IP address, authentication data.
- **Database Description (DBD) –** It is the OSPF route of the router. This contains the topology of an AS or an area (routing domain).
- **Link state request (LSR) –** When a router receives DBD, it compares it with its own DBD. If the DBD
received has some more updates than its own DBD then LSR is being sent
to its neighbor.
- **Link state update (LSU) –** When a router receives LSR, it responds with an LSU message containing the details requested.
- **Link state acknowledgement –** This provides reliability to the link-state exchange process. It is sent as the acknowledgement of LSU.
- **Link state advertisement (LSA) –** It is an OSPF data packet that contains link-state routing information,
shared only with the routers to which adjacency has been formed.

**Note –** Link State Advertisement and Link State Acknowledgement both are different messages.

**Timers –**

- **Hello timer –** The interval in which the OSPF router sends a hello message on an interface. It is 10 seconds by default.
- **Dead timer –** The interval in which the neighbor will be declared dead if it is not able
to send the hello packet. It is 40 seconds by default. It is usually 4
times the hello interval but can be configured manually according to
need.

**OSPF supports/provides/advantages –**

- Both IPv4 and IPv6 routed protocols
- Load balancing with equal-cost routes for the same destination
- VLSM and route summarization
- Unlimited hop counts
- Trigger updates for fast convergence
- A loop-free topology using SPF algorithm
- Run-on most routers
- Classless protocol

There
 are some disadvantages of OSPF like, it requires an extra CPU process 
to run the SPF algorithm, requiring more RAM to store adjacency 
topology, and being more complex to set up and hard to troubleshoot.
*** Open Shortest Path First (OSPF) protocol States
Prerequisite – [OSPF fundamentals](https://www.geeksforgeeks.org/computer-network-open-shortest-path-first-ospf-protocol-fundamentals/) Open
 Shortest Path First (OSPF) is a link-state routing protocol that is 
used to find the best path between the source and the destination router
 using its own Shortest Path First). OSPF is developed by Internet 
Engineering Task Force (IETF) as one of the Interior Gateway Protocol 
(IGP), i.e, the protocol which aims at moving the packet within a large 
autonomous system or routing domain. It is a network layer protocol 
which works on protocol number 89 and uses AD value 110. OSPF uses 
multicast address 224.0.0.5 for normal communication and 224.0.0.6 for 
update to designated router(DR)/Backup Designated Router (BDR).

**OSPF terms –**

1. **Router I’d –** It is the highest active IP address present on the router. First, the
highest loopback address is considered. If no loopback is configured
then the highest active IP address on the interface of the router is
considered. 
2. **Router priority –** It is an 8-bit value assigned to a router operating OSPF, used to elect DR and BDR in a broadcast network. 
3. **Designated Router (DR) –** It is elected to minimize the number of adjacencies formed. DR
distributes the LSAs to all the other routers. DR is elected in a
broadcast network to which all the other routers share their DBD. In a
broadcast network, the router requests for an update to DR, and DR will
respond to that request with an update. 
4. **Backup Designated Router (BDR) –** BDR is a backup to DR in a broadcast network. When DR goes down, BDR becomes DR and performs its functions. 

**DR and BDR election –** DR and BDR election takes place in the broadcast network or multi-access network. Here are the criteria for the election:

1. Router having the highest router priority will be declared as DR. 
2. If there is a tie in router priority then the highest router I’d be
considered. First, the highest loopback address is considered. If no
loopback is configured then the highest active IP address on the
interface of the router is considered. 

**OSPF states –** The device operating OSPF goes through certain states. These states are:

1. **Down –** In this state, no hello packets have been received on the interface. **Note –** The Downstate doesn’t mean that the interface is physically down. Here, it means that the OSPF adjacency process has not started yet. 
2. **INIT –** In this state, the hello packets have been received from the other router. 
3. **2WAY –** In the 2WAY state, both the routers have received the hello packets
from other routers. Bidirectional connectivity has been established. **Note –** In between the 2WAY state and Exstart state, the DR and BDR election takes place. 
4. **Exstart –** In this state, NULL DBD are exchanged. In this state, the master and
slave elections take place. The router having the higher router I’d
become the master while the other becomes the slave. This election
decides Which router will send its DBD first (routers who have formed
neighbourship will take part in this election). 
5. **Exchange –** In this state, the actual DBDs are exchanged. 
6. **Loading –** In this state, LSR, LSU, and LSA (Link State Acknowledgement) are exchanged. **Important –** When a router receives DBD from other router, it compares its own DBD
with the other router DBD. If the received DBD is more updated than its
own DBD then the router will send LSR to the other router stating what
links are needed. The other router replies with the LSU containing the
updates that are needed. In return to this, the router replies with the
Link State Acknowledgement. 
7. **Full –** In this state, synchronization of all the information takes place. OSPF routing can begin only after the Full state.
*** Open shortest path first (OSPF) router roles and configuration
Prerequisite – [Open shortest path first (OSPF)](https://www.geeksforgeeks.org/computer-network-open-shortest-path-first-ospf-protocol-states/)Open
 shortest path first (OSPF) is a link-state routing protocol which is 
used to find the best path between the source and the destination router
 using its own SPF algorithm.

**Open shortest path first (OSPF) router roles –**An
 area is a group of contiguous networks and routers. Routers belonging 
to same area shares a common topology table and area I’d. The area I’d 
is associated with router’s interface as a router can belong to more 
than one area. There are some roles of router in OSPF:

!https://media.geeksforgeeks.org/wp-content/uploads/rrf.png

1. **Backbone router –** The area 0 is known as backbone area and the routers in area 0 are
known as backbone routers. If the routers exists partially in the area
0then also it is a backbone router.
2. **Internal router –** An internal router is a router which have all of its interfaces in a single area.
3. **Area Boundary Router (ABR) –** The router which connects backbone area with another area is called
Area Boundary Router. It belongs to more than one area. The ABRs,
therefore, maintain multiple link-state databases that describe both the backbone topology and the topology of the other areas.
4. **Area Summary Border Router (ASBR) –** When an OSPF router is connected to a different protocol like EIGRP or
Border Gateway Protocol, or any other routing protocol then it is known
as AS. The router which connects two different AS (in which one of the
interfaces is operating OSPF) is known as Area Summary Border Router.
These routers perform redistribution. ASBRs run both OSPF and another
routing protocol, such as RIP or BGP. ASBRs advertise the exchanged
external routing information throughout their AS.

**Note –**
 A router can be backbone router and Area Boundary Router at the same 
time i.e a router can perform more than one role at a time.

**Configuration –**

!https://media.geeksforgeeks.org/wp-content/uploads/Configuration-1-1.png

There
 is a small topology in which there are 3 routers namely R1, R2, R3 are 
connected. R1 is connected to networks 10.255.255.80/30 (interface 
fa0/1), 192.168.10.48/29 (interface fa0/0) and 10.255.255.8/30 
(interface gi0/0)**Note –** In the figure, IP addresses
 are written with their respected interfaces but as have to advertise 
networks therefore, you have to write network I’d. R2 is connected to 
networks 192.168.10.64/29 (interface fa0/0), 10.255.255.80/30 (interface
 fa0/1). R3 is connected to networks 10.255.255.8/30 (int fa0/1), 
192.168.10.16/29 (int fa0/0).

Now, configuring OSPF for R1.

```
R1(config)#router ospf 1
R1(config-router)#network 192.168.10.48 0.0.0.7 area 1
R1(config-router)#network 10.255.255.80 0.0.0.3 area 1
R1(config-router)#network 10.255.255.8 0.0.0.3 area 1
```

Here, 1 is
 the OSPF instance or process I’d. It can be same or different (doesn’t 
matter). You have use wildcard mask here and area used is 1.Now, configuring R2

```
R2(config)#router ospf 1
R2(config-router)#network 192.168.10.64 0.0.0.7 area 1
R2(config-router)#network 10.255.255.80 0.0.0.3 area 1
```

Similarly, for R3

```
R3(config)#router ospf 1
R3(config-router)#network 192.168.10.16 0.0.0.7 area 1
R3(config-router)#network 10.255.255.8 0.0.0.3 area 1
```

You can check the configuration by typing command

```
R3#show ip protocols
```
*** Root Bridge Election in Spanning Tree Protocol
Redundant
 links are used to provide a backup path when one link goes down but a 
Redundant link can sometimes cause switching loops. The main purpose of 
Spanning Tree Protocol (STP) is to ensure that you do not create loops 
when you have redundant paths in your network.

**Spanning Tree Protocol (STP) –** As
 IEEE STP is used to make a loop-free network by monitoring the network 
to track all the links and shut down the redundant ones. These are some 
important terms related to Spanning Tree Protocol:

- **Bridge Priority Data Unit (BPDU) –** It contains the Bridge ID, Sender’s Bridge ID, Cost to the Root Bridge, Timer values on Root Bridge. All switches exchange BPDU in order to
elect root bridge. The switch with the lowest Bridge ID become the root
bridge.
- **Bridge ID –** It is an 8-byte field that
is a combination of bridge priority (2 bytes) and Base Mac address (6
bytes) of a device. If there is a tie on bridge priority then the Base
Mac address is considered.
- **Bridge Priority –** It is a priority, which is assigned to every switch, 32768 by default.
- **Root Bridge –** The root bridge is the bridge with the lowest Bridge ID. All the decisions
like which ports are the root ports (the port with the best path to the
root bridge) are made from the perspective of the root bridge.
- **Path cost –** A switch may encounter one or more switches in the path to the root
bridge. All the paths are analyzed and the path with the lowest cost
will be selected.

[Untitled Database](https://www.notion.so/8102ad86af014a3e8e5abfb699f83ba4?pvs=21)

**Designated port –** The port which sends the best BPDU i.e ports on the root bridge will be in a forwarding state. **Root port –** The port which receives the best BPDU on a non-root bridge. Criteria for selecting root port: 

1. Lowest path cost to reach the root bridge
2. Lowest sender bridge ID
3. Lowest sender port ID

(Port priority + Port number) – Port priority is by default 128 and port number is the switch interface number.

**Election procedure –** All
 the switches in the network declare themselves root bridges and start 
exchanging their own BPDU. The BPDU with the lowest bridge ID is 
considered as superior. Now the switch receiving the superior BPDU makes
 changes in its own BPDU and carries forward to its neighbours. It 
changes the value of root Bridge ID with its superior BPDU bridge ID. 
This process goes on until all the switches are satisfied with which 
bridge has the lowest bridge ID and hence that switch will be declared 
as the root bridge.

Now according to the criteria, the root ports will be selected and then the port left will be in blocking mode.

**Example –**

!https://media.geeksforgeeks.org/wp-content/uploads/image1-6.png

Here
 is a small topology with three switches switch A (mac 
address-0000.0ACA7.A603), switch B(0030.F222.2794), and switch 
C(000A.41D5.7937) with all having default priority (32768).

**Root Bridge election –** As
 all the switches have default priority therefore there is a tie on the 
basis of priority. Now, the switch with the lowest Mac address will 
become a root bridge. Here, switch A will become the root bridge as it 
has the lowest Mac address. Therefore, the ports of switch A will be in 
forwarding state i.e designated port.

!https://media.geeksforgeeks.org/wp-content/uploads/image2-1.png

**Root Ports Election –** The
 root ports are selected on non-root bridges, i.e. switch B and switch 
C. Now, for instance, if switch C choose the path through switch B then 
the cost will be (4+4=8) but if it chooses the directly connected path 
to switch A then the cost will be 4, therefore, both switch B and switch
 C will choose the ports connected to switch A as their root ports.

Now,
 the only thing left is to find which port will be in forwarding mode 
and blocking mode respectively. Now as the link between switch B and 
switch C has the same cost as the root bridge, therefore, the switch 
with the lowest bridge I’d be in forwarding mode therefore switch C port
 will be in forwarding mode and switch B port will be in block mode.
 
*** Types of Spanning Tree Protocol (STP)
Prerequisite – [Spanning Tree Protocol](https://www.geeksforgeeks.org/computer-network-root-bridge-election-spanning-tree-protocol/) Spanning
 Tree Protocol (STP) is used to make a loop free network by monitoring 
the network to track all the links and shut down the least redundant 
ones. Root bridge is a switch in a single VLAN or whole topology 
(according to the type of STP standard used) which is responsible for 
distributing BPDUs and block the least redundant port.

**Election procedure (root bridge) –** All
 the switches in the network declare themselves as root bridge and start
 exchanging their own BPDUs. The BPDU with the lowest bridge I’d will be
 considered as superior. Now the switch receiving the superior BPDU make
 changes in its own BPDU and carry forward to its neighbour switches. It
 changes the value of root Bridge I’d with its superior BPDU bridge I’d.
 This process goes on until all the switches are satisfied with which 
bridge have the lowest bridge I’d and hence that switch will be declared
 as root bridge.

**Types of Spanning Tree Protocol (STP) –**

**1. 802.1D –**
 This is also known as CST (Common Spanning Tree). It is a spanning tree
 standard developed by IEEE which elects only one root bridge per whole 
topology. All the traffic flows over the same path (the best path to the
 root bridge) but this doesn’t hold good always as there can be 
scenarios in which the optimised path to reach a VLAN is different than 
the path obtained on electing the root bridge. It is very slow as it 
takes 32 seconds to converge.

**Advantages:**

- Less CPU and memory required.

**Disadvantages:**

- Lesser optimisation as the path calculated as the best cost to root bridge might not be the best path to reach a network.
- No load balancing.

**2. Per VLAN Spanning Tree + (PVST+) –**
 It is a spanning tree standard developed by Cisco for its devices which
 finds the root bridge per VLAN. It is a Cisco default version of STP. 
It finds separate 802.1d spanning tree instance for each VLAN. It also 
provides backward comparability with 802.1d or CST. This is more 
optimized to the IEEE because it provides optimal path selection as 
separate instance of STP per VLAN is find. This is as slow as CST.

**Advantages:**

- PVST+ provides more optimization on the performance of a network than CST as it selects root bridges per VLAN.
- Bandwidth consumption is lesser than CST.
- Optimum load balancing is achieved.

**Disadvantages:**

- This is slow as CST i.e. convergence time is slow. By default, Cisco switches take 50 seconds for converging.
- More resources (CPU and memory) is required.

**3. 802.1w – Rapid Spanning Tree Protocol (RSTP) –**
 It is a spanning standard developed by IEEE which provides faster 
convergence than CST but holds the same idea of finding a single root 
bridge in the topology. The bridge resources needed in RSTP is higher 
than CST but less than PVST+ .

**Advantages:**

- Prevents network loops.
- Prevents redundancy.
- Faster Convergence.
- Backward compatible with STP.

**4. Rapid Per VLAN Spanning Tree + (RPVST+) –**This
 Spanning Tree standard is developed by Cisco which provides faster 
convergence than PVST+ and finds separate instance of 802.1w per VLAN. 
It requires much more CPU and memory than other STP standards. 

**5. 802.1s (Multiple Spanning Tree) :-**This
 standard is developed by IEEE in which grouping of VLANs is done and 
for each single group, RSTP is run. This is basically a Spanning Tree 
Protocol running over another Spanning Tree Protocol.

**Advantages:**

- High redundancy
- load balancing can be achieved.
- lower CPU and memory usage is required

**Disadvantages:**

- More configuration is required and not easy to implement.
*** EIGRP fundamentals
Dynamic
 routing Protocol performs the same function as static routing Protocol 
does. In dynamic routing Protocol, if the destination is unreachable 
then another entry, in the routing table, to the same destination can be
 used. One of the routing protocols is EIGRP. **EIGRP:** [Enhanced Interior Gateway Routing Protocol (EIGRP)](https://www.geeksforgeeks.org/computer-network-features-enhanced-interior-gateway-routing-protocol-eigrp/)
 is a dynamic routing protocol that is used to find the best path 
between any two-layer 3 devices to deliver the packet. EIGRP works on 
network layer Protocol of OSI model and uses protocol number 88. It uses
 metrics to find out the best path between two layer 3 devices (router 
or layer 3 switches) operating EIGRP. Administrative Distance for EIGRP 
are:- 

[Untitled Database](https://www.notion.so/4c4166fcc4794d64bb16b6905e110449?pvs=21)

It uses some messages to communicate with the neighbour devices that operate EIGRP. These are:- 

1. **Hello message-**These messages are kept alive messages which are exchanged between two
devices operating EIGRP. These messages are used for neighbour
discovery/recovery, if there is any device operating EIGRP or if any
device(operating EIGRP) coming up again. These messages are used for neighbor discovery if multicast at 224.0.0.10. It contains values like AS number, k values, etc. These messages are used as acknowledgement when unicast. A hello with no data is used as the acknowledgement.
2. **NULL update-**It is used to calculate SRTT(Smooth Round Trip Timer) and RTO(Retransmission Time Out). *SRTT:* The time is taken by a packet to reach the neighboring router and the acknowledgement of the packet to reach the local router.
    
    *RTO:* If
     a multicast fails then unicast is being sent to that router. RTO is the
     time for which the local router waits for an acknowledgement of the 
    packet.
    
3. **Full Update –** After exchanging
hello messages or after the neighbourship is formed, these messages are
exchanged. This message contains all the best routes.
4. **Partial update-**These messages are exchanged when there is a topology change and new links
are added. It contains only the new routes, not all the routes. These
messages are multicast.
5. **Query message-**These messages are multicast when the device is declared dead and it has no routes to it in its topology table.
6. **Reply message –** These messages are the acknowledgment of the query message sent to the
originator of the query message stating the route to the network which
has been asked in the query message.
7. **Acknowledgement message** It is used to acknowledge EIGRP updates, queries, and replies. Acks are hello packets that contain no data.
    
    **Note:-**Hello and acknowledgment packets do not require any acknowledgment. Reply, query, update messages are reliable messages i.e require acknowledgement.
    

**Composite matrix-**The
 EIGRP composite metric calculation can use up to 5 variables, but only 2
 are used by default (K1 and K3). The composite metric values are :

***K1 (bandwidth) K2 (load) K3 (delay) K4 (reliability) K5 (MTU)***

The
 lowest bandwidth, load, delay, reliability, MTU along the path between 
the source and the destination is considered in the composite matrix in 
order to calculate the cost. **Note:-** Generally, only
 k1 and k3 values are used for metric calculation by EIGRP. The values 
are 10100 for k1, k2, k3, k4, k5 respectively. **criteria** To form EIGRP neighbourship, these criteria should be fulfilled:- 

1. k values should match.
2. Autonomous system number should match. (AS is a group of networks running under a single administrative control) .
3. authentication should match (if applied). EIGRP supports MD5 authentication only.
4. subnet mask should be the same.

**Timers:-** **Hello timer-** The interval in which EIGRP sends a hello message on an interface. It is 5 seconds by default. **Dead timer-**
 The interval in which the neighbor will be declared dead if it is not 
able to send the hello packet. It is 15 seconds by default.
*** Features of Enhanced Interior Gateway Routing Protocol (EIGRP)
Enhanced
 Interior Gateway Routing Protocol (EIGRP) is a Cisco-proprietary Hybrid
 routing protocol that contains features of distance-vector and 
link-state routing protocols. It is a network layer protocol that works 
on protocol number 88.

Some of its features are:

1. **Rapid convergence –** EIGRP uses a DUAL algorithm to support rapid convergence. If a route to a network goes down then another route(feasible successor) can be used. If there is no route present to that network in the topology table also then a query message is multicast to find out the alternative route to
that network. 
2. **Reduced bandwidth usage –**
EIGRP doesn’t send periodic updates like other distance vector routing
protocol does. Distance Vector Routing protocol like RIP sends full
routing table over a period of time, therefore, consumes the available
bandwidth needlessly but EIGRP uses partial updates if there is any
change in the topology occurs i.e updates are triggered only if any
event occurs therefore consuming the bandwidth when needed. Also, EIGRP
updates are propagated to the routers only who require it. 
3. **Support all LAN and WAN data link protocols and topologies –** EIGRP supports multi-access networks like FDDI, token ring, etc, and
all WAN topologies like leased line, point-to-point links. EIGRP doesn’t require any additional configuration across layer 2 protocols like
frame relay. 
4. **Supports auto-summary –** In
EIGRP, auto-summarization is enabled by default. Auto summarization is a feature that allows Routing Protocols to summarize their routes to
their classful networks automatically i.e routers will receive
summarised routes automatically. EIGRP. e.g-1.1.1.1 /24 will be
automatically summarised to the classful 1.1.1.1/8 
5. **Supports unequal cost load balancing –** Unequal cost load balancing is possible in EIGRP by changing the value
of variance. By default, variance is 1, therefore, supports equal-cost
load balancing but if we want to use unequal cost load balancing then we can change the value of variance according to the amount of traffic we
want to divide across different paths. Feasible distance is multiplied
in such a way that it becomes greater than the value of the feasible
distance of successor. 
6. **Communication via Reliable Transfer Protocol (RTP) –** EIGRP depends upon proprietary protocol RTP to manage the communication between EIGRP speaking routers. EIGRP uses 224.0.0.10 as its a
multicast address. For each multicast it sends, the router prepares and
maintains a list of routers (speaking EIGRP). If no acknowledgement of
multicast is received then the same data is transmitted through 16
unicast messages. If no acknowledgement is received even after 16
unicast attempts then it is declared dead. This process is known as
reliable multicast. 
7. **Best path selection using DUAL –** EIGRP uses Diffusing Update Algorithm (DUAL) to find out the best path
available to a network. EIGRP speaking routers maintain a topology table in which all the routes to the network are maintained. If the best path (successor) goes down, then the second best path (feasible successor)
is used from the topology table. If there is no path available in the
topology table then it sends a query message to resolve the query.
    
    It maintains 3 different tables mainly: **(a) Neighbor table:**
     It contains information about the routers with which neighbourship has 
    been formed. It contains the SRTT, RTP. It also contains the queue count
     value for the hello messages that are not being acknowledged. **(b) Topology table:** It contains all the routes available to a network (both feasible successor and successor). **(c) Routing table:**
     It contains all the routes which are being used to make current routing
     decisions. The routes in this table are considered as successor (best 
    path) routes. 
    
8. **Traffic control –**
Suppose if one of the interfaces of the router is connected to ISP then
we don’t want that interface to be part of the EIGRP process. For this
scenario, EIGRP provides a feature in which we can flag the interface as passive i.e not to take part in the EIGRP process. 
9. Support Variable Length Subnet Mask (VLSM).
10. Support for both IPv4 and IPv6.

!https://media.geeksforgeeks.org/wp-content/post-ads-banner/2022-05-25-15-57-36-InterviewSeriesPrepareInArticleAd.webp
*** Routing Information Protocol (RIP)
**Routing Information Protocol**
 (RIP) is a dynamic routing protocol that uses hop count as a routing 
metric to find the best path between the source and the destination 
network. It is a distance-vector routing protocol that has an AD value 
of 120 and works on the Network layer of the OSI model. RIP uses port 
number 520.

### **Hop Count**

Hop
 count is the number of routers occurring in between the source and 
destination network. The path with the lowest hop count is considered as
 the best route to reach a network and therefore placed in the routing 
table. RIP prevents routing loops by limiting the number of hops allowed
 in a path from source and destination. The maximum hop count allowed 
for RIP is 15 and a hop count of 16 is considered as network 
unreachable.

### **Features of RIP**

1. Updates of the network are exchanged periodically. 2. Updates (routing information) are always broadcast. 3. Full routing tables are sent in updates. 4. Routers always trust routing information received from neighbor routers. This is also known as *Routing on* rumors.

### **RIP versions :**

There are three versions of routing information protocol – **RIP Version1**, **RIP Version2**, and **RIPng**.

[Untitled Database](https://www.notion.so/4ca624899589442c9f6ca10d5b533ee1?pvs=21)

**RIP v1** is known as *Classful* Routing Protocol because it doesn’t send information of subnet mask in its routing update. **RIP v2** is known as *Classless* Routing Protocol because it sends information of subnet mask in its routing update. 

> >> Use debug command to get the details :
> 
> 
> ```
> # debug ip rip
> ```
> 
> >> Use this command to show all routes configured in router, say for router R1 :
> 
> ```
> R1# show ip route
> ```
> 
> >> Use this command to show all protocols configured in router, say for router R1 :
> 
> ```
> R1# show ip protocols
> ```
> 

### **Configuration :**

!https://media.geeksforgeeks.org/wp-content/uploads/rip_topology.png

Consider
 the above-given topology which has 3-routers R1, R2, R3. R1 has IP 
address 172.16.10.6/30 on s0/0/1, 192.168.20.1/24 on fa0/0. R2 has IP 
address 172.16.10.2/30 on s0/0/0, 192.168.10.1/24 on fa0/0. R3 has IP 
address 172.16.10.5/30 on s0/1, 172.16.10.1/30 on s0/0, 10.10.10.1/24 on
 fa0/0.

**Configure RIP for R1 :**

```
R1(config)# router rip
R1(config-router)# network 192.168.20.0
R1(config-router)# network 172.16.10.4
R1(config-router)# version 2
R1(config-router)# no auto-summary
```

**Note:** no
 auto-summary command disables the auto-summarisation. If we don’t 
select any auto-summary, then the subnet mask will be considered as 
classful in Version 1.

**Configuring RIP for R2:**

```
R2(config)# router rip
R2(config-router)# network 192.168.10.0
R2(config-router)# network 172.16.10.0
R2(config-router)# version 2
R2(config-router)# no auto-summary
```

**Similarly, Configure RIP for R3 :**

```
R3(config)# router rip
R3(config-router)# network 10.10.10.0
R3(config-router)# network 172.16.10.4
R3(config-router)# network 172.16.10.0
R3(config-router)# version 2
R3(config-router)# no auto-summary
```

### **RIP timers:**

- **Update timer:** The default timing for routing information being exchanged by the routers
operating RIP is 30 seconds. Using an Update timer, the routers exchange their routing table periodically.
- **Invalid timer:** If no update comes until 180 seconds, then the destination router
considers it invalid. In this scenario, the destination router mark hop
counts as 16 for that router.
- **Hold down timer:** This is the time for which the router waits for a neighbor router to
respond. If the router isn’t able to respond within a given time then it is declared dead. It is 180 seconds by default.
- **Flush time:** It is the time after which the entry of the route will be flushed if it
doesn’t respond within the flush time. It is 60 seconds by default. This timer starts after the route has been declared invalid and after 60
seconds i.e time will be 180 + 60 = 240 seconds.

Note that all these times are adjustable. Use this command to change the timers :

```
R1(config-router)# timers basic
R1(config-router)# timers basic 20   80    80    90
```
*** Routing Information Protocol (RIP) V1 & V2
**[Routing Information Protocol (RIP)](https://www.geeksforgeeks.org/computer-network-routing-information-protocol-rip/)**
 protocol are the intradomain (interior) routing protocol which is based
 on distance vector routing and it is used inside an autonomous 
system.Routers and network links are called node. The first column of 
routing table is destination address. The cost of metric in this 
protocol is hop count which is number of networks which need to be 
passed to reach destination. Here infinity is defined by a fixed number 
which is 16 it means that using a Rip, network cannot have more than 15 
hops.

### RIP Version-1:

It
 is an open standard protocol means it works on the various vendor’s 
routers. It works on most of the routers, it is classful routing 
protocol. Updates are broadcasted. Its administrative distance value is 
120, it means it is not reliable, The lesser the administrative distance
 value the reliability is much more. Its metric is hop count and max hop
 count is 15. There will be a total of 16 routers in the network. When 
there will be the same number of hop to reach the destination, Rip 
starts to perform load balancing. Load balancing means if there are 
three ways to reach the destination and each way has same number of 
routers then packets will be sent to each path to reach the destination.
 This reduces traffic and also the load is balanced. It is used in small
 companies, in this protocol routing tables are updated in each 30 sec. 
Whenever link breaks rip trace out another path to reach the 
destination. It is one of the slowest protocol.

**Advantages of RIP ver1 –**

1. Easy to configure, static router are complex.
2. Less overhead
3. No complexity.

**Disadvantage of RIP ver1 –**

1. Bandwidth utilization is very high as broadcast for every 30 seconds.
2. It works only on hop count.
3. It is not scalable as hop count is only 15. If there will be requirement of more routers in the network it would be a problem .
4. Convergence is very slow, wastes a lot of time in finding alternate path.

### RIP Version-2:

Due
 to some deficiencies in the original RIP specification, RIP version 2 
was developed in 1993. It supports classless Inter-Domain Routing (CIDR)
 and has the ability to carry subnet information, its metric is also hop
 count, and max hop count 15 is same as rip version 1. It supports 
authentication and does subnetting and multicasting. Auto summary can be
 done on every router. In RIPv2 Subnet masks are included in the routing
 update. RIPv2 multicasts the entire routing table to all adjacent 
routers at the address 224.0.0.9, as opposed to RIPv1 which uses 
broadcast (255.255.255.255).

**Advantages of RIP ver2 –**

1. It’s a standardized protocol.
2. It’s VLSM compliant.
3. Provides fast convergence.
4. It sends triggered updates when the network changes.
5. Works with snapshot routing – making it ideal for dial networks.

**Disadvantage of RIP ver2 –** There lies some disadvantages as well:

1. Max hopcount of 15, due to the ‘count-to-infinity’ vulnerability.
2. No concept of neighbours.
3. Exchanges entire table with all neighbours every 30 seconds (except in the case of a triggered update).

### RIP ver1 versus RIP ver2:

[Untitled Database](https://www.notion.so/a933eabfb14c49b2b54a35754522f786?pvs=21)
*** Link State Advertisement (LSA)
[Open shortest path first (OSPF)](https://www.geeksforgeeks.org/computer-network-open-shortest-path-first-ospf-protocol-states/) is a [link-state routing protocol](https://www.geeksforgeeks.org/computer-network-classes-routing-protocols/)
 which is used to find the best path between the source and the 
destination router using its own shortest path first (SPF) algorithm. 
OSPF routers exchange LSAs to update and maintain topological OSPF 
database by the devices operating OSPF but to first understand the types
 of LSAs, we first have to understand about the router roles in OSPF.

**Router Roles –**

!https://media.geeksforgeeks.org/wp-content/uploads/rrf.png

1. **Backbone router –** The area 0 is known as backbone area and the routers in area 0 are known as backbone routers. 
2. **Internal router –** An internal router is a router which have all of its interfaces in a single area. 
3. **Area Boundary Router (ABR) –** The router which connects backbone area with another area is called
Area Boundary Router. The ABRs therefore maintain multiple link-state
databases that describe both the backbone topology and the topology of
the other areas. 
4. **Autonomous System Border Router (ASBR) –** When an OSPF router is connected to a different protocol like EIGRP, or Border Gateway Protocol, or any other routing protocol then it is known as AS. The router which connects two different AS (in which one of the
interface is operating OSPF in area 0) is known as Autonomous System
Border Router. These routers perform redistribution. ASBRs run both OSPF and another routing protocol, such as RIP or BGP. 

**LSA Types –** There are different types of LSAs exchanged depending upon the areas in which devices operating OSPF reside.

1. **Type-1 (Router Link Advertisement) –** This is a Type-1 LSA exchanged by the routers which belongs to a same
area. The router contains status of link, Router I’d, IP information and current interface state. If a router is connected to multiple areas
then separate Type 1 LSA is exchanged.

!https://media.geeksforgeeks.org/wp-content/uploads/Type11-1.png

1. As shown in the figure, Type 1 LSA are exchanged by the routers within the same area but if other interface of router is in another area then
different Type 1 LSA will be exchanged.
2. **Type-2 (Network Link Advertisement) –** This is a Type-2 LSA which is send by DR (Designed Router) only to all
the other routers present in the same area (broadcast or multi-access
network) . These contain the DR and BDR IP information and also the
state of other routers that are part of same network. Remember DR is
responsible for distributing routing information to all other routers
present in same broadcast area.

!https://media.geeksforgeeks.org/wp-content/uploads/Type22.png

1. As shown in the figure, in a broadcast network, only DR distributes the routing information to other routers in the same area.
2. **Type-3 (Summary LSA) –** This is a Type-3 LSA which are generated by ABRs to areas other than in which it resides. The topological database which ABR receives from
other areas are injected into the backbone area. This includes the IP
information and Router I’d of ABR that is advertising these LSA.

!https://media.geeksforgeeks.org/wp-content/uploads/type3.png

1. As shown in the figure, R3 (ABR) floods the routing information of area 1 to other areas by generating Type 3 LSA.
2. **Type-4 (Summary ASBR LSA) –** ABR send these Type 4 LSA towards the area other than the area in which they are generated. These LSAs are generated by ABR to tell others the
route to ASBR.

!https://media.geeksforgeeks.org/wp-content/uploads/Type4-1.png

1. As we can see in the figure, R4 is an ASBR therefore to advertise it’s own routes to R3, R4 will generate a Type 1 LSA which in turn generate a
Type 4 LSA and flood the LSA to all other external areas to tell the
route of ASBR to other area routers .
2. **Type-5 AS external link advertisement –** These LSAs are generated by ASBR to advertise routes of other Autonomous System than OSPF.

!https://media.geeksforgeeks.org/wp-content/uploads/Type1-1.png

1. As shown in the above figure R4 will be an ASBR (as connecting area of
OSPF and RIP) and route 1.1.1.0/24 is to be advertised in OSPF areas.
This is the responsibility of ASBR to advertise other routing protocol
routes into OSPF areas therefore R4 will now create a Type 5 LSA to
advertise these route to all other OSPF areas.
*** Administrative Distance (AD) and Autonomous System (AS)
**Administrative Distance (AD)**
 is used to rate the trustworthiness of routing information received 
from the neighbor router. The route with the least AD will be selected 
as the best route to reach the destination remote network and that route
 will be placed in the routing table. It defines how reliable a routing 
protocol is. It is an integer value ranging from 0 to 255 where 0 shows 
that the route is most trusted and 255 means that no traffic will be 
passed through that route or that route is never installed in the 
routing table.

[Untitled Database](https://www.notion.so/32701241242c441bb7ad58b4f9bb3648?pvs=21)

- **Example –** The smaller the value of AD, the more reliable the routing protocol is. For example, if a router receives an advertised route to a remote
destination network from OSPF and EIGRP, then the advertised route of
EIGRP will be considered as the best route and will be placed in the
routing table as EIGRP has lower AD.
- **The best path selection process by dynamic protocol –** If a router receives the same advertised routes from more than one source
for a remote network, then the first AD value is checked. The advertised route having the least AD value will get preference. If the AD value of the advertised routes is the same, then the metrics of advertised
routes are checked. The advertised route with the least metric will be
placed in the routing table. If both AD and metric are the same then
load balancing is done i.e the traffic will traverse through different
routes. The load balancing can be equal or unequal. In equal load
balancing, the same amount of traffic will traverse through both routes
one at a time while the different amounts of traffic will traverse in
unequal load balancing.

**Autonomous System (AS)**
 is a group of routers and networks working under a single 
administrative domain. It is a 16-bit value that defines the routing 
domain of the routers. These numbers range from 1 to 65535. 

- **Public Autonomous System Number –** These are 16-bit values that range from 1 to 64511. The service provider will provide a public AS if the customer is connected to more than one ISPs
such as multihoming. A global autonomous number, which will be unique,
is provided when the customer wants to propagate its BGP routes through 2 ISPs.
- **Private Autonomous system Number –** Private Autonomous System Number are 16-bit values that range from 64512 to
65535. The service provider will provide a private autonomous system
number to the customer when the customer wants multi-connection to a
single ISP (single home or dual home network) but not to more than one
ISPs. These are provided in order to conserve the autonomous system
numbers.
- **Assigning of AS numbers –** The Autonomous numbers are first assigned by IANA (Internet Assign Number
Authority) to the respective regional registries. Further, the regional
registry distributes these autonomous numbers (from the block of
autonomous numbers provided by IANA) to entities within their designated area.
*** Circuit Switching in Computer Network
In 
circuit switching network resources (bandwidth) are divided into pieces 
and bit delay is constant during a connection. The dedicated 
path/circuit established between sender and receiver provides a 
guaranteed data rate. Data can be transmitted without any delays once 
the circuit is established.

Telephone system network is one of the example of Circuit switching. **TDM (Time Division Multiplexing) and FDM (Frequency Division Multiplexing)** are two methods of multiplexing multiple signals into a single carrier.

- **Frequency Division Multiplexing :** *Divides into multiple bands* Frequency Division Multiplexing or FDM is used when multiple data signals are
combined for simultaneous transmission via a shared communication
medium.It is a technique by which the total bandwidth is divided into a
series of non-overlapping frequency sub-bands,where each sub-band carry
different signal. Practical use in radio spectrum & optical fibre to share multiple independent signals.
- **Time Division Multiplexing :** *Divides into frames* Time-division multiplexing (TDM) is a method of transmitting and receiving
independent signals over a common signal path by means of synchronized
switches at each end of the transmission line. TDM is used for
long-distance communication links and bears heavy data traffic loads
from end user. Time division multiplexing (TDM) is also known as a digital circuit switched.

**Advantages of Circuit Switching:** It has the following advantages : 

1. The main advantage of circuit switching is that a committed transmission
channel is established between the computers which give a guaranteed
data rate.
2. In-circuit switching, there is no delay in data flow because of the dedicated transmission path.

**Disadvantages of Circuit Switching:** It has the following disadvantages : 

1. It takes a long time to establish a connection.
2. More bandwidth is required in setting up dedicated channels.
3. It cannot be used to transmit any other data even if the channel is free as the connection is dedicated to circuit switching.

Formulas in Circuit Switching : 

```
Transmission rate = Link Rate or Bit rate /
                    no. of slots = R/h bps
Transmission time = size of file /
                    transmission rate
                 = x / (R/h) = (x*h)/R second
Total time to send packet to destination =
               Transmission time + circuit setup time
```

**Question on Circuit switching** – These questions will help you understand circuit switching  **Example 1 :** How
 long it takes to send a file of ‘x bits’ from host A to host B over a 
circuit switched network that uses TDM with ‘h slots’ and have a bit 
rate of ‘R Mbps’, circuit establish time is k seconds.Find total time?

**Explanation :** Transmission rate = Link Rate or Bit rate / no. of slots = R/h bps Transmission time = size of file/ transmission rate = x / (R/h) = (x*h)/R

Total time = transmission time + circuit setup time = (x*h)/R secs + k secs  **Example 2 :** If a link transmits F frames/sec and each slot has B bits then find the transmission rate?

**Explanation :** Since it is not mention how many slots in each frame we take one frame has one slot. The transmission rate is the amount of data sent in 1 second. Transmission rate = F * B bits/sec 

To know the difference between Circuit Switching and Packet Switching refer – [Difference b/w Circuit switch & packet switch](https://www.geeksforgeeks.org/computer-network-circuit-switching-vs-packet-switching/) 

References : https://en.wikipedia.org/wiki/Circuit_switching https://en.wikipedia.org/wiki/Frequency-division_multiplexing
*** Packet Switching and Delays in Computer Network
**Packet switching**
 is a method of transferring the data to a network in form of packets. 
In order to transfer the file fast and efficiently manner over the 
network and minimize the transmission latency, the data is broken into 
small pieces of variable length, called **Packet**. At the 
destination, all these small parts (packets) have to be reassembled, 
belonging to the same file. A packet composes of payload and various 
control information. No pre-setup or reservation of resources is 
needed.

Packet Switching uses **Store and Forward**
 technique while switching the packets; while forwarding the packet each
 hop first stores that packet then forward. This technique is very 
beneficial because packets may get discarded at any hop due to some 
reason. More than one path is possible between a pair of sources and 
destinations. Each packet contains Source and destination address using 
which they independently travel through the network. In other words, 
packets belonging to the same file may or may not travel through the 
same path. If there is congestion at some path, packets are allowed to 
choose different paths possible over an existing network.

Packet-Switched networks were designed to overcome the *weaknesses* of Circuit-Switched networks since circuit-switched networks were not very effective for small messages.

**Advantage of Packet Switching over Circuit Switching :** 

- More efficient in terms of bandwidth, since the concept of reserving circuit is not there.
- Minimal transmission latency.
- More reliable as a destination can detect the missing packet.
- More fault tolerant because packets may follow a different path in case any link is down, Unlike Circuit Switching.
- Cost-effective and comparatively cheaper to implement.

**The disadvantage of Packet Switching over Circuit Switching :** 

- Packet Switching doesn’t give packets in order, whereas Circuit Switching
provides ordered delivery of packets because all the packets follow the
same path.
- Since the packets are unordered, we need to provide sequence numbers for each packet.
- Complexity is more at each node because of the facility to follow multiple paths.
- Transmission delay is more because of rerouting.
- Packet Switching is beneficial only for small messages, but for bursty data (large messages) Circuit Switching is better.

**Modes of Packet Switching :** 

**1. Connection-oriented Packet Switching (Virtual Circuit) :** Before
 starting the transmission, it establishes a logical path or virtual 
connection using signaling protocol, between sender and receiver and all
 packets belongs to this flow will follow this predefined route. Virtual
 Circuit ID is provided by switches/routers to uniquely identify this 
virtual connection. Data is divided into small units and all these small
 units are appended with help of sequence numbers. Overall, three phases
 take place here- The setup, data transfer and tear down phase. 

!https://media.geeksforgeeks.org/wp-content/uploads/Connection.jpg

!https://media.geeksforgeeks.org/wp-content/uploads/Connection-oriented-Packet.jpg

All
 address information is only transferred during the setup phase. Once 
the route to a destination is discovered, entry is added to the 
switching table of each intermediate node. During data transfer, packet 
header (local header) may contain information such as length, timestamp,
 sequence number, etc. Connection-oriented switching is very useful 
in switched WAN. Some popular protocols which use the Virtual Circuit 
Switching approach are X.25, Frame-Relay, ATM, and MPLS(Multi-Protocol 
Label Switching).

**2. Connectionless Packet Switching (Datagram) :**Unlike
 Connection-oriented packet switching, In Connectionless Packet 
Switching each packet contains all necessary addressing information such
 as source address, destination address and port numbers, etc. In 
Datagram Packet Switching, each packet is treated independently. Packets
 belonging to one flow may take different routes because routing 
decisions are made dynamically, so the packets arrived at the 
destination might be out of order. It has no connection setup and 
teardown phase, like Virtual Circuits. Packet delivery is not 
guaranteed in connectionless packet switching, so reliable delivery must
 be provided by end systems using additional protocols. 

!https://media.geeksforgeeks.org/wp-content/uploads/Connection-less.jpg

```
A---R1---R2---B

A is the sender (start)
R1, R2 are two routers that store and forward data
B is receiver(destination)
```

To send a packet from A to B there are delays since this is a Store and Forward network.

### Delays in Packet switching :

1. Transmission Delay
2. Propagation Delay
3. Queuing Delay
4. Processing Delay
*** Differences between Virtual Circuits and Datagram Networks
Computer
 networks that provide connection-oriented services are called Virtual 
Circuits while those providing connection-less services are called 
Datagram networks. For prior knowledge, the Internet which we use is 
actually based on a Datagram network (connection-less) at the network 
level as all packets from a source to a destination do not follow the 
same path. Let us see what are the highlighting differences between these two hot debated topics here:

**Virtual Circuits:**

1. It is connection-oriented, meaning that there is a reservation of
resources like buffers, CPU, bandwidth, etc. for the time in which the
newly setup VC is going to be used by a data transfer session.
2. The first sent packet reserves resources at each server along the path.
Subsequent packets will follow the same path as the first sent packet
for the connection time.
3. Since all the packets are going to
follow the same path, a global header is required. Only the first packet of the connection requires a global header, the remaining packets
generally don’t require global headers.
4. Since all packets follow a specific path, packets are received in order at the destination.
5. Virtual Circuit Switching ensures that all packets successfully reach the
Destination. No packet will be discarded due to the unavailability of
resources.
6. From the above points, it can be concluded that Virtual Circuits are a highly reliable method of data transfer.
7. The issue with virtual circuits is that each time a new connection is set
up, resources and extra information have to be reserved at every router
along the path, which becomes problematic if many clients are trying to
reserve a router’s resources simultaneously.
8. It is used by the ATM (Asynchronous Transfer Mode) Network, specifically for Telephone calls.

**Datagram Networks :**

1. It is a connection-less service. There is no need for reservation of
resources as there is no dedicated path for a connection session.
2. All packets are free to use any available path. As a result, intermediate
routers calculate routes on the go due to dynamically changing routing
tables on routers.
3. Since every packet is free to choose any
path, all packets must be associated with a header with proper
information about the source and the upper layer data.
4. The
connection-less property makes data packets reach the destination in any order, which means that they can potentially be received out of order
at the receiver’s end.
5. Datagram networks are not as reliable as Virtual Circuits.
6. The major drawback of Datagram Packet switching is that a packet can only
be forwarded if resources such as the buffer, CPU, and bandwidth are
available. Otherwise, the packet will be discarded.
7. But it is
always easy and cost-efficient to implement datagram networks as there
is no extra headache of reserving resources and making a dedicated each
time an application has to communicate.
8. It is generally used by the IP network, which is used for Data services like the Internet.
*** Difference between Circuit Switching and Packet Switching
# In-circuit switching has there are 3 phases: i) Connection Establishment. ii) Data Transfer. iii) Connection Released.

[In-circuit switching, each data unit knows the entire path address which is provided by the source.](https://www.notion.so/In-circuit-switching-each-data-unit-knows-the-entire-path-address-which-is-provided-by-the-source-c3c0aa062b1c480a88285156c6367d42?pvs=21)

[In-Circuit switching, data is processed at the source system only](https://www.notion.so/In-Circuit-switching-data-is-processed-at-the-source-system-only-26f94183e7264811b6be57dd80f05fd5?pvs=21)

[The delay between data units in circuit switching is uniform.](https://www.notion.so/The-delay-between-data-units-in-circuit-switching-is-uniform-43f6437643574dcead1118dc0784c112?pvs=21)

[Resource reservation is the feature of circuit switching because the path is fixed for data transmission.](https://www.notion.so/Resource-reservation-is-the-feature-of-circuit-switching-because-the-path-is-fixed-for-data-transmis-b265e2e52b2c4940ad0eb08ee6b2371a?pvs=21)

[Circuit switching is more reliable.](https://www.notion.so/Circuit-switching-is-more-reliable-a24fa027ea79486a9f6c0815372f00a9?pvs=21)

[Wastage of resources is more in Circuit Switching](https://www.notion.so/Wastage-of-resources-is-more-in-Circuit-Switching-982b0ce2b0d944e2835b7812f13190bf?pvs=21)

[It is not a store and forward technique.](https://www.notion.so/It-is-not-a-store-and-forward-technique-4ea3860a7d0a446486a64eeac622cf8b?pvs=21)

[Transmission of the data is done by the source.](https://www.notion.so/Transmission-of-the-data-is-done-by-the-source-09a3de4ce272494f8a7e415e1d53db16?pvs=21)

[Congestion
 can occur during the connection establishment phase because there might
 be a case where a request is being made for a channel but the channel 
is already occupied.](https://www.notion.so/Congestion-can-occur-during-the-connection-establishment-phase-because-there-might-be-a-case-where-d39c0e7939f64ea2b1a19e3b6f1b5695?pvs=21)

[Circuit switching is not convenient for handling bilateral traffic.](https://www.notion.so/Circuit-switching-is-not-convenient-for-handling-bilateral-traffic-179a033d52494f1d9474e7fbe2fa50bf?pvs=21)

[In-Circuit switching, the charge depends on time and distance, not on traffic in the network.](https://www.notion.so/In-Circuit-switching-the-charge-depends-on-time-and-distance-not-on-traffic-in-the-network-0d420300e97d435dbf8de9b2abdd86bd?pvs=21)

[Recording of packets is never possible in circuit switching.](https://www.notion.so/Recording-of-packets-is-never-possible-in-circuit-switching-0f899bd7e136422fa3f84f2194c17800?pvs=21)

[In-Circuit Switching there is a physical path between the source and the destination](https://www.notion.so/In-Circuit-Switching-there-is-a-physical-path-between-the-source-and-the-destination-f022422cb42442579dea264eb2f27b17?pvs=21)

[Circuit Switching does not support store and forward transmission](https://www.notion.so/Circuit-Switching-does-not-support-store-and-forward-transmission-24cc5a00c0be4ba5a8c08abe9c87daab?pvs=21)

[Call setup is required in circuit switching.](https://www.notion.so/Call-setup-is-required-in-circuit-switching-4cddcc0f31574df1a2ea0168f1adc7b2?pvs=21)

[In-circuit switching each packet follows the same route.](https://www.notion.so/In-circuit-switching-each-packet-follows-the-same-route-b14f710c23f9411794a07301ebf75426?pvs=21)

[The circuit switching network is implemented at the physical layer.](https://www.notion.so/The-circuit-switching-network-is-implemented-at-the-physical-layer-1f75e0862cd94c8f9d671c07331ecf75?pvs=21)

[Circuit switching requires simple protocols for delivery.](https://www.notion.so/Circuit-switching-requires-simple-protocols-for-delivery-7bd4077f96eb4889b006f0184653e2ac?pvs=21)
*** Traceroute in Network Layer
Consider
 a situation when you are not able to access a website and can access 
other websites. You would want to know if this is a problem with your 
network, some intermediate network, or with the webserver. How do you 
figure it out?

You can use Traceroute.

**What is a** **traceroute?** Traceroute
 is a widely used command-line utility available in almost all operating
 systems. It shows you the complete route to a destination address. It 
also shows the time is taken (or delays) between intermediate routers. 
Isn’t it great? Below is an example of the Windows operating system.

!https://media.geeksforgeeks.org/wp-content/uploads/computer-network-traceroute-2.png

**What does the** **above output mean?** A
 first column is a serial number for intermediate routers. In the above 
output, three packets are sent to every hop to get a good estimate of 
delays for every router. The three columns show the time taken by three 
different packets. The last column is the IP/Name of intermediate 
routers. The output shows three delays for the first hop, followed by delays for the second hop, and so on.

**What is a** **command in Linux and other Operating Systems?** In Windows, as shown above, the command name is “tracert”, but in Linux, Unix, and Apple MAC OS, a command is “traceroute”.

**How does traceroute work?** As shown in the below diagram, there are intermediate routers between source and destination. 

!https://media.geeksforgeeks.org/wp-content/uploads/computer-network-traceroute.png

It sends many packets toward the destination.

The
 first set of packets (3 packets in the above example) are sent in a way
 that they are dropped by the first intermediate hop and a control 
message is received from the first intermediate node to get the time 
estimation for the first hop.

The second set of packets (3 
packets in the above example) are sent in a way that they are dropped by
 the second intermediate hop and a control message is received from the 
second intermediate node to get the time estimation for the first hop.

**How does traceroute make sure that a packet is dropped at i’th hop?** It
 uses the TTL field for this purpose. TTL is set as 1 for the first 
packet(s), then 2, and so on until the destination is reached.

**How is the** **total time estimated?** When
 a packet is dropped, the router sends an ICMP Time Exceeded message 
back to the source. That is how the source figures out the total time.

Traceroute is a widely used command-line utility in networks
*** How Address Resolution Protocol (ARP) works?
Most of the computer programs/applications use **logical address (IP address)** to send/receive messages, however, the actual communication happens over the **physical address (MAC address)**
 i.e from layer 2 of the OSI model. So our mission is to get the 
destination MAC address which helps in communicating with other devices.
 This is where ARP comes into the picture, its functionality is to 
translate IP address to physical addresses. 

!https://media.geeksforgeeks.org/wp-content/uploads/20190423135210/arpp.png

The acronym ARP stands for **Address Resolution Protocol** which is one of the most important protocols of the Network layer in the OSI model. **Note:** ARP finds the hardware address, also known as Media Access Control (MAC) address, of a host from its known IP address. 

!https://media.geeksforgeeks.org/wp-content/uploads/20190423132008/arp2.png

Let’s look at how ARP works.

Imagine
 a device that wants to communicate with the other over the internet. 
What ARP does? Does it broadcast a packet to all the devices of the 
source network. The devices of the network peel the header of the data link layer from the **protocol data unit (PDU)**
 called frame and transfer the packet to the network layer (layer 3 of 
OSI) where the network ID of the packet is validated with the 
destination IP’s network ID of the packet and if it’s equal then it 
responds to the source with the MAC address of the destination, else the
 packet reaches the gateway of the network and broadcasts packet to the 
devices it is connected with and validates their network ID

The 
above process continues till the second last network device in the path 
reaches the destination where it gets validated and ARP, in turn, 
responds with the destination MAC address. 

**ARP:** ARP stands for ****(**Address Resolution Protocol**). It is responsible to find the hardware address of a host from a known IP address. There are three basic **ARP** terms.The important terms associated with **ARP** are:

(i) Reverse ARP

(ii) Proxy ARP

(iii) Inverse ARP

1. **ARP Cache:** After resolving the MAC address, the ARP sends it to the source where
it is stored in a table for future reference. The subsequent
communications can use the MAC address from the table
2. **ARP Cache Timeout:** It indicates the time for which the MAC address in the ARP cache can reside
3. **ARP request:** This is nothing but broadcasting a packet over the network to validate
whether we came across the destination MAC address or not.
    1. The physical address of the sender.
    2. The IP address of the sender.
    3. The physical address of the receiver is FF:FF:FF:FF:FF:FF or 1’s.
    4. The IP address of the receiver
4. **ARP response/reply:** It is the MAC address response that the source receives from the destination which aids in further communication of the data. 
- **CASE-1:** The sender is a host and wants to send a packet to another host on the same network.
    - Use ARP to find another host’s physical address
- **CASE-2:** The sender is a host and wants to send a packet to another host on another network.
    - The sender looks at its routing table.
    - Find the IP address of the next-hop (router) for this destination.
    - Use ARP to find the router’s physical address
- **CASE-3:** the sender is a router and received a datagram destined for a host on another network.
    - The router checks its routing table.
    - Find the IP address of the next router.
    - Use ARP to find the next router’s physical address.
- **CASE-4:** The sender is a router that has received a datagram destined for a host in the same network.
    - Use ARP to find this host’s physical address.

**NOTE:** An ARP request is a broadcast, and an ARP response is a Unicast.

**Test Yourself :**

!https://media.geeksforgeeks.org/wp-content/uploads/internet-schema-1.png

Connect two PC, say A and B with a cross cable. Now you can see the working of ARP by typing these commands: 

```
1.A > arp -a
```

There will be no entry at the table because they never communicated with each other. 

!https://media.geeksforgeeks.org/wp-content/uploads/arp-03.jpg

```
2.A > ping 192.168.1.2

IP address of destination is 192.168.1.2
Reply comes from destination but one packet is lost because of ARP processing.
```

!https://media.geeksforgeeks.org/wp-content/uploads/ping2.jpg

Now, entries of the ARP table can be seen by typing the command. This is how ARP table looks like: 

!https://media.geeksforgeeks.org/wp-content/uploads/arp-2.png
*** ARP, Reverse ARP(RARP), Inverse ARP (InARP), Proxy ARP and Gratuitous ARP
**Prerequisite** [IP Addressing](https://www.geeksforgeeks.org/ip-addressing-classless-addressing/), [Introduction of MAC Addresses](https://www.geeksforgeeks.org/computer-network-introduction-mac-addresses/), [Basics of Address Resolution Protocol (ARP)](https://www.geeksforgeeks.org/computer-network-arp-works/)
 In this article, we will discuss about whole ARP-family, which are ARP,
 RARP, InARP, Proxy ARP and Gratuitous ARP. Let’s try to understand each
 one by one.

### 1. Address Resolution Protocol (ARP) –

Address
 Resolution Protocol is a communication protocol used for discovering 
physical address associated with given network address. Typically, ARP 
is a network layer to data link layer mapping process, which is used to 
discover MAC address for given Internet Protocol Address. In order to 
send the data to destination, having IP address is necessary but not 
sufficient; we also need the physical address of the destination 
machine. ARP is used to get the physical address (MAC address) of 
destination machine.

!https://media.geeksforgeeks.org/wp-content/uploads/arp.jpg

Before
 sending the IP packet, the MAC address of destination must be known. If
 not so, then sender broadcasts the ARP-discovery packet requesting the 
MAC address of intended destination. Since ARP-discovery is broadcast, 
every host inside that network will get this message but the packet will
 be discarded by everyone except that intended receiver host whose IP is
 associated. Now, this receiver will send a unicast packet with its MAC 
address (ARP-reply) to the sender of ARP-discovery packet. After the 
original sender receives the ARP-reply, it updates ARP-cache and start 
sending unicast message to the destination.

!https://media.geeksforgeeks.org/wp-content/uploads/arp-2.jpg

**Example –** [GATE CS 2005, Question 24 (ARP Based).](https://www.geeksforgeeks.org/gate-gate-cs-2005-question-24/)

### 2. Reverse Address Resolution Protocol (RARP) –

Reverse
 ARP is a networking protocol used by a client machine in a local area 
network to request its Internet Protocol address (IPv4) from the 
gateway-router’s ARP table. The network administrator creates a table in
 gateway-router, which is used to map the MAC address to corresponding 
IP address. When a new machine is setup or any machine which don’t have 
memory to store IP address, needs an IP address for its own use. So the 
machine sends a RARP broadcast packet which contains its own MAC address
 in both sender and receiver hardware address field.

!https://media.geeksforgeeks.org/wp-content/uploads/rarp.jpg

A
 special host configured inside the local area network, called as 
RARP-server is responsible to reply for these kind of broadcast packets.
 Now the RARP server attempt to find out the entry in IP to MAC address 
mapping table. If any entry matches in table, RARP server send the 
response packet to the requesting device along with IP address.

- LAN technologies like Ethernet, Ethernet II, Token Ring and Fiber
Distributed Data Interface (FDDI) support the Address Resolution
Protocol.
- RARP is not being used in today’s networks. Because we have much great featured protocols like BOOTP (Bootstrap Protocol) and
DHCP( Dynamic Host Configuration Protocol).

### 3. Inverse Address Resolution Protocol (InARP) –

Instead
 of using Layer-3 address (IP address) to find MAC address, Inverse ARP 
uses MAC address to find IP address. As the name suggests, InARP is just
 inverse of ARP. Reverse ARP has been replaced by BOOTP and later DHCP 
but Inverse ARP is solely used for device configuration. Inverse ARP is 
enabled by default in ATM(Asynchronous Transfer Mode) networks. InARP is
 used to find Layer-3 address from Layer-2 address (DLCI in frame 
relay). Inverse ARP dynamically maps local DLCIs to remote IP addresses 
when you configure Frame Relay. When using inverse ARP, we know the DLCI
 of remote router but don’t know its IP address. InARP sends a request 
to obtain that IP address and map it to the Layer-2 frame-relay DLCI.

!https://media.geeksforgeeks.org/wp-content/uploads/inarp.jpg

### 4. Proxy ARP –

Proxy
 ARP was implemented to enable devices which are separated into network 
segments connected by a router in the same IP network or sub-network to 
resolve IP address to MAC addresses. When devices are not in same data 
link layer network but are in the same IP network, they try to transmit 
data to each other as if they were on the local network. However, the 
router that separates the devices will not send a broadcast message 
because routers do not pass hardware-layer broadcasts. Therefore, the 
addresses cannot be resolved. Proxy ARP is enabled by default so the 
“proxy router” that resides between the local networks responds with its
 MAC address as if it were the router to which the broadcast is 
addressed. When the sending device receives the MAC address of the proxy
 router, it sends the datagram to the proxy router, which in turns sends
 the datagram to the designated device.

!https://media.geeksforgeeks.org/wp-content/uploads/proxy-arp.jpg

### 5. Gratuitous ARP –

Gratuitous
 Address Resolution Protocol is used in advance network scenarios. It is
 something performed by computer while booting up. When the computer 
booted up (Network Interface Card is powered) for the first time, it 
automatically broadcast its MAC address to the entire network. After 
Gratuitous ARP MAC address of the computer is known to every switch and 
allow DHCP servers to know where to send the IP address if requested. 
Gratuitous ARP could mean both Gratuitous ARP request and Gratuitous ARP
 reply, but not needed in all cases. Gratuitous ARP request is a packet 
where source and destination IP are both set to IP of the machine 
issuing the packet and the destination MAC is the broadcast address 
ff:ff:ff:ff:ff:ff ; no reply packet will occur. Gratuitous ARP is 
ARP-Reply that was not prompted by an ARP-Request. Gratuitous Address 
Resolution Protocol is useful to detect IP conflict. Gratuitous ARP is 
also used to update ARP mapping table and Switch port MAC address table.

!https://media.geeksforgeeks.org/wp-content/uploads/gratituous-arp-1.jpg

### What is ARP poisoning (ARP spoofing) –

ARP
 spoofing is a type of network attack in which the attacker sends the 
falsified ARP request over the LAN (say to the default gateway), which 
results connecting attacker’s MAC address to the legitimate server on 
that victim network. Now, the attacker will start receiving the data 
which was intended for that IP address. With the help of ARP Poisoning 
(or ARP Spoofing) attacker is able to intercept data frames, modify 
traffic or even stop data in-transit.

!https://media.geeksforgeeks.org/wp-content/uploads/arp-poison.jpg

ARP
 poisoning can act as the opening for other major attacks, such as Man 
in the middle, denial of service, or session hijacking attacks. We will 
discuss about ARP Spoofing later in depth. **References –** [Address Resolution Protocol – Cisco](https://www.cisco.com/c/en/us/td/docs/ios-xml/ios/ipaddr_arp/configuration/15-mt/arp-15-mt-book/arp-config-arp.html) [tools.ietf.org/html/rfc826](https://tools.ietf.org/html/rfc826) [tools.ietf.org/html/rfc903](https://tools.ietf.org/html/rfc903) [ARP – Wikipedia](https://en.wikipedia.org/wiki/Address_Resolution_Protocol)
*** Packet flow in the same Network
Prerequisite – [How ARP works?](https://www.geeksforgeeks.org/computer-network-arp-works/) To
 transfer a packet from source to destination, both the MAC address and 
IP address of the destination should be known. If the destination MAC 
address is not present then ARP will resolve this issue first then the 
packet will be delivered to a destination host.

There are simple rules for a packet flow in a network:

1. If the destination host is present in the same network as the source host
then the packet will be delivered directly to the destination host using MAC address.
2. Within a network, the packet will be delivered on the basis of MAC address.
3. MAC address never crosses its broadcast domain.

Now, first, we have to take an idea about ARP.

**Address Resolution Protocol –** Address
 Resolution Protocol is a layer 2(Data link layer) protocol that is used
 to find the MAC address of the known IP address.

There are some important terms associated with ARP:

**ARP cache** is
 a table maintained by ARP that contains an IP address with its 
associated MAC address and type. If MAC address is learned dynamically 
then the type will be dynamic and if MAC address is added manually then 
the type will be static.

!https://media.geeksforgeeks.org/wp-content/uploads/images-2.jpeg

**ARP request** is a broadcast message generated by the source to find the destination MAC address if the ARP is not resolved initially.

**ARP reply** is a unicast message from destination to source device containing the destination MAC address.

**Explanation –**

!https://media.geeksforgeeks.org/wp-content/uploads/networking12.png

The steps included in the ARP process are as follows:-

When a source wants to send a packet to the destination device then,

1.
 The source ARP cache is checked if the ARP is resolved or not. If the 
ARP is not resolved, it puts the packet on hold and generates an ARP 
request.

!https://media.geeksforgeeks.org/wp-content/uploads/dd-1.png

2. If the ARP is already resolved then the packet will be delivered to the destination host.

3. The ARP request is broadcast all over the network to find out the device has a destination IP address. **Note –**
 If the destination is present in the same network then ARP will find 
out destination MAC address but if it is present in a different network 
then ARP will find out default gateway MAC address.

!https://media.geeksforgeeks.org/wp-content/uploads/dd1.png

4. When the device having the destination IP address receives the ARP request, it updates its own ARP cache.

5. The destination host machine generates an ARP reply containing its own MAC address.

6. Now, the device having the source IP address receives the ARP reply and updates its ARP cache.

!https://media.geeksforgeeks.org/wp-content/uploads/dd2.png

7.
 Since, both source and destination IP address and MAC address are 
available now, therefore, the packet is delivered to the destination 
host.

Now, we have taken an idea about the ARP protocol. Let’s see about the **packet flow**.

Now
 we will understand how the packet is delivered to the destination when 
the destination is present in the same network(network of the source).

!https://media.geeksforgeeks.org/wp-content/uploads/packetnetwork0.png

Here
 is the topology in which host A has IP address 192.168.1.1, host B has 
IP address 192.168.1.2, and the router has IP address 192.168.1.3 on 
interface fa0/0.

Now how to source device will know that the destination is present in the same or different network. Let us understand:-

**AND operation**
 is performed between the source IP address, source subnet mask and 
destination IP address, source subnet mask. If the resultant of both are
 the same then the destination is present in the same network otherwise 
in a different network.

Let us try to ping host B from host A.

!https://media.geeksforgeeks.org/wp-content/uploads/packetnetwork1.png

As
 you can see 2 packets are generated, one of ICMP and the other of 
ARP(green). ARP frame is generated because host A has not yet 
communicated to host B i.e. the ARP has not been resolved i.e ARP will 
be resolved first so that host A has an entry for host B MAC address.

!https://media.geeksforgeeks.org/wp-content/uploads/packetnetwork2.png

As
 already explained the ARP request will be broadcast first for the 
target IP address within the network because routers do not forward 
broadcast packets. The broadcast request is received by the switch as 
shown in the above figure.

!https://media.geeksforgeeks.org/wp-content/uploads/packet4.png

The switch broadcasts the ARP request as the entry in the ethernet header is FFFF.FFFF.FFFF (broadcast MAC address).

!https://media.geeksforgeeks.org/wp-content/uploads/packetnetwork3.png

The
 request is received by Host B as shown in the above figure. Host B 
generates an ARP reply immediately specifying its own MAC address.

!https://media.geeksforgeeks.org/wp-content/uploads/packetnetwork2.png

!https://media.geeksforgeeks.org/wp-content/uploads/packetnetwork4.png

Now
 the host B unicast the ARP reply to host A which is received by the 
switch which in turn forward it to host A as shown in the above 2 
figures.

**Note –** The switch is able to 
unicast the reply because the switch has put an entry for host A in its 
MAC table when hosting A broadcasts the ARP request.in the same way, a 
switch has also put an entry for the host B when the switch receives

the ARP reply.

!https://media.geeksforgeeks.org/wp-content/uploads/packetnetwork5.png

!https://media.geeksforgeeks.org/wp-content/uploads/packetnetwork6.png

Now the ARP has been resolved and the ICMP will be unicast to the host B from host A(as shown above).

!https://media.geeksforgeeks.org/wp-content/uploads/packetnetwork5.png

!https://media.geeksforgeeks.org/wp-content/uploads/packetnetwork7.png

Now
 the ICMP acknowledgement packet will be unicast from host B to host A 
i.e. host B is successfully pinged from host A as shown in the above 
figures.
*** Packet flow in different Network
Prerequisite – [How ARP works](https://www.geeksforgeeks.org/computer-network-arp-works/), [Packet flow in the same network](https://www.geeksforgeeks.org/computer-network-packet-flow-network/)

To
 deliver the packet to the destination host, the source IP, destination 
IP, source MAC address and destination MAC address should be known. Some
 basic rules for the packet flow:

1. If the destination host is present in the same network, then the packet is delivered directly to the destination host.
2. If the destination host is present in a different network then the packet
is delivered to the default gateway first which in turn delivers the
packet to the destination host.
3. If ARP is not resolved then ARP will be resolved first.
4. MAC address never crosses its broadcast domain.

**Explanation –**

!https://media.geeksforgeeks.org/wp-content/uploads/Packet_flow_1.jpg

Here
 is a topology, in which there is host A (IP address – 10.0.0.10 and MAC
 address – 000D.BD22.7C22), host C (IP address – 10.0.0.9), host B (IP 
address – 20.0.0.10), host C (IP address-20.0.0.9 and MAC address – 
00E0.A3E2.03DC) and the router (IP address – 10.0.0.20 and MAC address –
 000B.BE8E.5201 on fa0/0,IP address – 20.0.0.20 and MAC address – 
000B.BE8E.5202 on fa0/1 ).

Now we will try to ping from host A (IP address – 10.0.0.10) to host B (IP address – 20.0.0.10). First, **AND operation**
 is performed by source host between source IP address, source subnet 
mask, and destination IP address, source subnet mask to know if the 
destination is present in same or different network.

If the 
result is the same then the destination is in the same network otherwise
 in a different network. Here, the destination is present in different 
networks, therefore, the result will be different and the packet will be
 delivered to a default gateway.

!https://media.geeksforgeeks.org/wp-content/uploads/Packet_flow_2.jpg

We see that 2 messages are generated ICMP(purple) and ARP(green). ARP has been generated because ARP has not been resolved.

!https://media.geeksforgeeks.org/wp-content/uploads/Packet_flow_3.jpg

Now as the ARP should be resolved first, therefore the ARP request will be broadcast which is received by switch:

!https://media.geeksforgeeks.org/wp-content/uploads/Packet_flow_4.jpg

The switch in turn broadcast the ARP request to the host and the router. The PC discards the request and the router accepts it.

!https://media.geeksforgeeks.org/wp-content/uploads/Packet_flow_5.jpg

!https://media.geeksforgeeks.org/wp-content/uploads/Packet_flow_6.jpg

Now the ARP reply is unicast to host A by the router as shown in the above figure.

!https://media.geeksforgeeks.org/wp-content/uploads/Packet_flow_7.jpg

!https://media.geeksforgeeks.org/wp-content/uploads/Packet_flow_8.jpg

Now
 the ICMP packet will be unicast to the default gateway (IP address – 
10.0.0.20 and MAC address – 000B.BE8E.5201) as shown in the above 
figures.

**Note –** The ICMP packet will be unicast to the default gateway as the ARP has been resolved now.

!https://media.geeksforgeeks.org/wp-content/uploads/Packet_flow_9-1.jpg

!https://media.geeksforgeeks.org/wp-content/uploads/Packet_flow_10-1.jpg

Now
 the ARP has to be resolved again because the router has to deliver the 
packet to host B and the ARP table has no entry for host B. Therefore, 
the ARP request is broadcast in the network 20.0.0.0/24. The packet is 
received by the Switch which in turn broadcast the request to host B and
 D. Host D will reject the request and host B will accept it and 
generate an ARP reply for the MAC address 000B.BE8E.5202 (router fa0/1 
MAC address) because the ARP reply has to be given to that MAC address 
from which the ARP request has been received.

!https://media.geeksforgeeks.org/wp-content/uploads/packetd12.png

As
 you can see in the figure, the ARP reply packet is unicast to the 
router’s interface fa0/1 MAC address(000B.BE8E.5202) and the source MAC 
is 00E0.A3E2.03DC.

**Note –** Here, the target MAC 
address is the MAC address of host B (000B.BE8E.5202). Target MAC 
address is the MAC address of a device that the host wants to know 
through its ARP request to resolve ARP.

!https://media.geeksforgeeks.org/wp-content/uploads/packetd15.png

!https://media.geeksforgeeks.org/wp-content/uploads/packetd16.png

!https://media.geeksforgeeks.org/wp-content/uploads/packetd17.png

Now the ICMP echo-request packet will be unicast to the host B as shown in the above 3 figures.

!https://media.geeksforgeeks.org/wp-content/uploads/packetd16.png

!https://media.geeksforgeeks.org/wp-content/uploads/packetd15.png

!https://media.geeksforgeeks.org/wp-content/uploads/packetd18.png

!https://media.geeksforgeeks.org/wp-content/uploads/packetd19.png

Host
 B will generate an ICMP echo reply in response to the ICMP echo request
 for host A which will be delivered to the 20.0.0.20 (router’s interface
 IP address) first and then unicast to host A.

**How does** **the MAC address never crosses its broadcast domain?**

!https://media.geeksforgeeks.org/wp-content/uploads/ppp.png

This
 is the IP and Ethernet header when host A forwards the ICMP echo 
request to its default gateway. Therefore source IP is 10.0.0.10 and 
destination IP is 10.0.0.20, source MAC address is 000D.BD22.7C22 (host A
 MAC address) and destination MAC address is 000B.BE8E.5201 (router’s 
fa0/0 interface MAC address).

!https://media.geeksforgeeks.org/wp-content/uploads/pp-3.png

But
 now when the ICMP echo request message is forwarded from the router’s 
fa0/1 interface to host B then the source MAC address is changed to 
000B.BE8E.5202 (router’s fa0/1 interface MAC address) and destination 
MAC address is 00E0.A3E2.03DC (host B MAC address).

Here router’s
 fa0/0 interface MAC address is not used as the source MAC address, 
instead the fa0/1 MAC address is used as a MAC address. Therefore, fa0/0
 is not used in other broadcast domains (20.0.0.0/24 network) therefore 
MAC address never crosses its broadcast domain. IN this way, PING is 
performed in 2 different networks.
*** Difference between layer-2 and layer-3 switches
Prerequisite – [Network Devices](https://www.geeksforgeeks.org/network-devices-hub-repeater-bridge-switch-router-gateways/) A **switch**
 is a device which sends a data packet in a local network. What is 
advantage over hub? A hub floods the network with the packet and only 
destination system receives that packet while others just drop due to 
which the traffic increases a lot. To solve this problem switch came 
into the picture. A switch first learns, by flooding network just like 
hub to fill MAC- address table, on which port a particular device is 
connected. After learning it sends packets to that particular host 
only.

!https://media.geeksforgeeks.org/wp-content/uploads/HUB.png

!https://media.geeksforgeeks.org/wp-content/uploads/SWITCH.png

!https://media.geeksforgeeks.org/wp-content/uploads/Untitled-drawing-4-1.png

Layer
 2 switch work on layer 2 of OSI model i.e. data link layer and sends a 
“Frames” to destination port using MAC address table which stores the 
mac address of a device associated with that port. Layer 3 switch work 
on layer 3 of OSI model i.e. network layer where it route packet by 
using IP address, it is used widely on VLANs.

[Untitled Database](https://www.notion.so/dce148b8f3f2446ea4b5b1f4af260c18?pvs=21)
*** Difference between Ping and Traceroute
In
 computer networks, data is sent in small blocks known as packets. Each 
packet is transmitted individually and may also follow a different route
 to reach the destination. Once all these packets of the original 
message reach the destination, they are re-assembled to form the 
original message. But, sometimes, it may happen that the webserver is 
down, network congestion or some other technical glitch is there, that 
may prevent the message from reaching the destination. To diagnose such 
congestions and network failures, we use two common programs namely Ping
 and Traceroute.

**Ping:**
 It is a utility that helps one to check if a particular IP address is 
accessible or not. Ping works by sending a packet to the specified 
address and waits for a reply. It also measures round trip time and 
reports errors.

Ping is also used in 
checking if the computers on a local network are active. For this, the 
user has to go to the command prompt and type: ping 127.0.0.1, and if 
the address is active, the ping would return a message like this :

```
Pinging 127.0.0.1 with 32 bytes of data
Reply from 127.0.0.1: bytes=32 time<10ms TTL=32
Reply from 127.0.0.1: bytes=32 time<10ms TTL=32
Reply from 127.0.0.1: bytes=32 time<10ms TTL=32
Reply from 127.0.0.1: bytes=32 time<10ms TTL=32
```

The
 IP address 127.0.0.1 is the address of the local host and would receive
 a ping reply even if the sender is not connected to the internet.

**Traceroute:**
 It is a utility that traces a packet from your computer to the host, 
and will also show the number of steps (hops) required to reach there, 
along with the time by each step. Traceroute works by sending the 
packets of data with a low survival time (Time to Live – TTL) which 
specifies how many steps (hops) can the packet survive before it is 
returned. When a packet can’t reach the final destination and expires at
 an intermediate step, that node returns the packet and identifies 
itself. So, by increasing the TTL gradually, Traceroute is able to 
identify the intermediate hosts. If any of the hops come back with  
“Request timed out”, it denotes network congestion and a reason for slow
 loading Web pages and dropped connections.

The main difference between Ping and [Traceroute](https://www.geeksforgeeks.org/traceroute-in-network-layer/)
 is that Ping is a quick and easy utility to tell if the specified 
server is reachable and how long will it take to send and receive data 
from the server whereas Traceroute finds the exact route taken to reach 
the server and time taken by each step (hop).

### Difference between Ping and Traceroute:

[Untitled Database](https://www.notion.so/ced1275ea83343d99de623f138c59023?pvs=21)
*** Servers in Computer Network
In computing, a **server** is a computer **program or a device** that provides functionality for called clients which are other programs or devices. This architecture is called the **client–server model**.
 A single overall computation is distributed across multiple processes 
or devices. Servers can provide various functionalities called services.
 These services include **sharing data or resources** among
 multiple clients, or performing computation for a client. Multiple 
clients can be served by a single server, and a single client can use 
multiple servers. A client process may run on the same device. It can 
also connect over a network to a server to run on a different device. 
Example of servers may include database servers, mail servers, print 
servers, file servers, web servers, application servers, and game 
servers.

Most frequently client–server systems are implemented by the **request–response model**.,
 i.e., a client sends a request to the server. In this model server 
performs some action and sends a response back to the client, typically 
with a result or acknowledgement. Designating a computer as server-class
 hardware means that it is specialized for running servers on it. This 
implies that it is more powerful and reliable than standard personal 
computers. But large computing clusters may be composed of many 
relatively simple, replaceable server components.

**Types of Servers and their applications:**

1. **Application server –** These servers hosts web apps (computer programs that run inside a web
browser) allowing users in the network to run and use them preventing
the installation a copy on their own computers. These servers need not
be part of the World Wide Web. Their clients are computers with a web
browser.
2. **Catalog server –** These
servers maintains an index or table of contents of information that can
be found across a large distributed network. Distributed network may
include computers, users, files shared on file servers, and web apps.
Examples of catalog servers are Directory servers and name servers.
Their clients are any computer program that needs to find something on
the network. Example can be a Domain member attempting to log in, an
email client looking for an email address, or a user looking for a file
3. **Communications server –** These servers maintains an environment needed for one communication endpoint
to find other endpoints and then communicates with them. These servers
may or may not include a directory of communication endpoints and a
presence detection service, depending on the openness and security
parameters of the network. Their clients are communication endpoints.
4. **Computing server –** These servers share vast amounts of computing resources which include CPU and random-access memory over a network. Any computer program that needs
more CPU power and RAM than a personal computer can probably afford can
use these types of servers. The client must be a networked computer to
implement the client–server model which is necessity.
5. **Database server –** These servers maintains and shares any form of database over a network. A
database is a organized collections of data with predefined properties
that may be displayed in a table. Clients of these servers are
spreadsheets, accounting software, asset management software or
virtually any computer program that consumes well-organized data,
especially in large volumes.
6. **Fax server –** These servers share one or more fax machines over a network which eliminates
the hassle of physical access. Any fax sender or recipient are the
clients of these servers.
7. **File server –** Shares files and folders, storage space to hold files and folders, or both,
over a network Networked computers are the intended clients, even though local programs can be clients
8. **Game server –** These servers enables several computers or gaming devices to play multiplayer games. Personal computers or gaming consoles are their clients.
9. **Mail server –** These servers makes email communication possible in the same way as a post
office makes snail mail communication possible. Clients of these servers are senders and recipients of email
10. **Print server –** These servers share one or more printers over a network which eliminates the
hassle of physical access. Their clients are computers in need of
printing something.
11. **Proxy server –** This server acts as an intermediary between a client and a server accepting
incoming traffic from the client and sending it to the server. Reasons
to use a proxy server includes content control and filtering, improving
traffic performance, preventing unauthorized network access or simply
routing the traffic over a large and complex network. There clients are
any networked computer.
12. **Web server –** These servers hosts web pages. A web server is responsible for making the
World Wide Web possible. Each website has one or more web servers. There clients are computers with a web browser.
*** What is Local Host?
When
 you call an IP address on your computer, you try to contact another 
computer on the internet but when you call the IP address 127.0.0.1 then
 you are communicating with the local host. **Localhost** 
is always your own computer. Your computer is talking to itself when you
 call the local host. Your computer does not always directly identify 
the local host. Within your personal network localhost has a separate IP
 address like 192.168.0.1. (for most cases) which is different from the 
one you use on the internet. This is usually dynamically assigned by the
 internet service provider (ISP). Localhost can be seen as a server that
 is used on your own computer.

This
 term is generally used in the context of networks. Localhost is not 
just the name for the virtual server but it is also its domain name. 
Just like .example, .test, or .invalid, ., .localhost is a top-level 
domain reserved for documentation and testing purposes. While accessing 
the domain, a loopback is triggered. If you access “http://localhost” in
 the browser, the request will not be forwarded to the internet through 
the router. It will instead remain in your own system. Localhost has the
 IP address 127.0.0.1. This refers back to your own server.

**127.0.0.1 – how does loopback work?** To
 communicate with each other within a network IP addresses are used. The
 participants in the network have their own unique addresses. Using 
TCP/IP data packets are able to reach the correct destination. The 
protocol pair Transmission Control Protocol (TCP) and Internet Protocol 
(IP) are some of the main features of the internet. TCP/IP is also used 
outside of the internet in local networks. The Internet Protocol is 
responsible for allowing the IP address and subnet mask to address 
subscribers in a network during the transmission.

The allocation 
of public IP addresses is regulated by an international organization 
which is the Internet Corporation for Assigned Names and Numbers 
(ICANN). **ICANN** is also responsible for the allocation 
of domain names called the Domain Name System (DNS). But certain address
 ranges are reserved for special purposes, like the range from 127.0.0.0
 to 127.255.255.255. There is no reliable information on why that range 
was chosen. IP addresses on the internet are divided into different 
classes. The first class Class A started with 0.0.0.0 (reserved address)
 and ended with 127.255.255.255. 127 is the last block of the Class A 
network. Its important position could have been the reason for its 
selection.

Within this address range, a Localnet can be set up. 
The special thing about this range is that IP addresses are not uniquely
 assigned in it, as is usually the case. Also, it was reserved by 
ICANN.

If you enter an IP address or corresponding domain name in
 your browser, the router forwards your request to the internet which 
connects you to the server. This means that if you enter 172.217.0.0, 
you will reach the Google homepage but the situation is different with 
127.0.0.1. The requests to this address will not be forwarded to the 
internet. TCP/IP recognizes from the first block (127) that you don’t 
want to access the internet, you are calling yourself instead. This then
 triggers the loopback.

The reason why a loopback device is 
created is so that the backlink to your own computer works. Through the 
operating system, this is a virtual interface that is created. The 
interface is called lo or lo0 and can also be displayed using the 
ifconfig command in Unix systems. A similar command for Windows is 
ipconfig.

**What is localhost used for?** Developers
 use the local host to test web applications and programs. Network 
administrators use the loopback to test network connections. Another use
 for the localhost is the host’s file, where you can use the loopback to
 block malicious websites.

**For Testing Purposes –** Web
 servers mainly use the local host for the programming applications that
 need to communicate over the internet. During development, it is 
important to find out whether the application actually works as 
developed once it has internet access. Localhosts’ other functions are 
only possible if the required files can be found on the internet. As we 
can see that there is a difference between opening an HTML document on 
your PC or loading it onto a server and accessing it. Releasing a 
product without testing it doesn’t make sense. So loopback is used by 
developers to test them. They can stimulate a connection while also 
avoiding network errors. The connection just stays completely inside 
their own system.

Another advantage of using localhost for 
testing purposes is the speed. Usually, more than 100 milliseconds are 
taken when you send a request over the internet. The maximum 
transmission time is just one millisecond for sending a ping to 
localhost. The correctness of the internet protocol can also be 
implemented using this technology.

If you want to set up your own
 test server on your PC to address it through the local host, the right 
software is needed. Softwares such as XAMPP specifically designed for 
use as localhost can be used.

**To block websites –** Localhost
 can also block the host’s files. This file is a predecessor of the 
Domain Name System (DNS). In this IP addresses can be assigned to the 
corresponding domains. The domain name is translated into an IP address 
when you enter a website address in the browser. It used to be the host 
file, but today usually the global DNS is used but the host file is 
still present in most operating systems. In Windows, the file is found 
under \system32\drivers\etc\hosts whereas, with macOS and other Unix 
systems, it is found under /etc/hosts.

There are probably these two entries left if there are no file changes done:

```
 127.0.0.1       localhost

 ::1             localhost
```

The name resolution for the 
localhost need not have to be done over the internet. Localhost can also
 use the host file to block certain websites. For this, the website to 
be blocked must be entered into the list and the IP address 127.0.0.1 
must be assigned to the domain. If you or a malicious script try to call
 up the locked domain, the browser will check the host’s file first and 
will find your entry there. The domain name 0.0.0.0 can also be used.

The
 browser will then try to access the corresponding website on the server
 with 127.0.0.1. However, it is unlikely that the browser will be able 
to locate it, as the requested file will not be there. However, if your 
own test server is set up, then the browser may find home.html, which is
 just your own file. An error message appears instead of the requested 
website if you have not set up your own test server. Ad inserts 
throughout the system can be switched off using this technology. To 
avoid every entry manually, you can find finished and regularly extended
 host files on the Internet.
 
** TRANSPORT LAYER
*** Transport Layer responsibilities
Transport Layer is the second layer in the [TCP/IP model](https://www.geeksforgeeks.org/tcp-ip-model/) and the fourth layer in the [OSI model](https://www.geeksforgeeks.org/layers-of-osi-model/). It is an **end-to-end** layer used to deliver messages to a host. It is termed an end-to-end layer because it provides a point-to-point connection **rather than**
 hop-to- hop, between the source host and destination host to deliver 
the services reliably. The unit of data encapsulation in the Transport 
Layer is a segment.

### Working of Transport Layer:

The transport layer takes services from the [Network layer](https://www.geeksforgeeks.org/network-layer-services-packetizing-routing-and-forwarding/) and provides services to the [Application layer](https://www.geeksforgeeks.org/application-layer-in-osi-model/)

**At the sender’s side:** The
 transport layer receives data (message) from the Application layer and 
then performs Segmentation, divides the actual message into segments, 
adds source and destination’s port numbers into the header of the 
segment, and transfers the message to the Network layer.

**At the receiver’s side:** The
 transport layer receives data from the Network layer, reassembles the 
segmented data, reads its header, identifies the port number, and 
forwards the message to the appropriate port in the Application layer.

### Responsibilities of a Transport Layer:

### **Process to process delivery:**

While Data Link Layer requires the [MAC address](https://www.geeksforgeeks.org/introduction-of-mac-address-in-computer-network/)
 (48 bits address contained inside the Network Interface Card of every 
host machine) of source-destination hosts to correctly deliver a frame 
and the Network layer requires the IP address for appropriate routing of
 packets, in a similar way Transport Layer requires a Port number to 
correctly deliver the segments of data to the correct process amongst 
the multiple processes running on a particular host. A **port number** is a 16-bit address used to identify any client-server program uniquely.

### **End-to-end Connection between hosts:**

The
 transport layer is also responsible for creating the end-to-end 
Connection between hosts for which it mainly uses TCP and UDP. TCP is a 
secure, connection-orientated protocol that uses a handshake protocol to
 establish a robust connection between two end hosts. TCP ensures 
reliable delivery of messages and is used in various applications. UDP, 
on the other hand, is a stateless and unreliable protocol that ensures 
best-effort delivery. It is suitable for applications that have little 
concern with flow or error control and requires sending the bulk of data
 like video conferencing. It is often used in multicasting protocols.

### **Multiplexing and Demultiplexing:**

Multiplexing
 allows simultaneous use of different applications over a network that 
is running on a host. The transport layer provides this mechanism which 
enables us to send packet streams from various applications 
simultaneously over a network. The transport layer accepts these packets
 from different processes differentiated by their port numbers and 
passes them to the network layer after adding proper headers. Similarly,
 Demultiplexing is required at the receiver side to obtain the data 
coming from various processes. Transport receives the segments of data 
from the network layer and delivers it to the appropriate process 
running on the receiver’s machine.

### **Congestion Control:**

Congestion
 is a situation in which too many sources over a network attempt to send
 data and the router buffers start overflowing due to which loss of 
packets occur. As a result retransmission of packets from the sources 
increases the congestion further. In this situation, the Transport layer
 provides Congestion Control in different ways. It uses **open loop** congestion control to prevent the congestion and **closed-loop**
 congestion control to remove the congestion in a network once it 
occurred. TCP provides AIMD- additive increase multiplicative decrease, 
leaky bucket technique for congestion control.

### **Data integrity and Error correction:**

The
 transport layer checks for errors in the messages coming from the 
application layer by using error detection codes, computing checksums, 
it checks whether the received data is not corrupted and uses the ACK 
and NACK services to inform the sender if the data has arrived or not 
and checks for the integrity of data.

### **Flow control:**

The
 transport layer provides a flow control mechanism between the adjacent 
layers of the TCP/IP model. TCP also prevents data loss due to a fast 
sender and slow receiver by imposing some flow control techniques. It 
uses the method of sliding window protocol which is accomplished by the 
receiver by sending a window back to the sender informing the size of 
data it can receive.

### Protocols of Transport Layer:

- [TCP](https://www.geeksforgeeks.org/tcp-and-udp-in-transport-layer/)(Transmission Control Protocol)
- [UDP](https://www.geeksforgeeks.org/user-datagram-protocol-udp/) (User Datagram Protocol)
- [SCTP](https://www.geeksforgeeks.org/sctp-full-form/) (Stream Control Transmission Protocol)
- DCCP (Datagram Congestion Control Protocol)
- ATP (AppleTalk Transaction Protocol)
- FCP (Fibre Channel Protocol)
- RDP (Reliable Data Protocol)
- RUDP (Reliable User Data Protocol)
- SST (Structured Steam Transport)
- SPX (Sequenced Packet Exchange)
*** Congestion Control in Computer Networks
What is **congestion**?

A state occurring in network layer when the message traffic is so heavy that it slows down network response time.

**Effects** of Congestion

- As delay increases, performance decreases.
- If delay increases, retransmission occurs, making situation worse.

**Congestion control algorithms**

- **Leaky Bucket Algorithm**

Let us consider an example to understand

Imagine
 a bucket with a small hole in the bottom.No matter at what rate water 
enters the bucket, the outflow is at constant rate.When the bucket is 
full with water additional water entering spills over the sides and is 
lost.

!https://media.geeksforgeeks.org/wp-content/uploads/leaky.jpg

Similarly, each network interface contains a leaky bucket and the following **steps** are involved in leaky bucket algorithm:

1.  When host wants to send packet, packet is thrown into the bucket.
2.  The bucket leaks at a constant rate, meaning the network interface transmits packets at a constant rate.
3.  Bursty traffic is converted to a uniform traffic by the leaky bucket.
4. In practice the bucket is a finite queue that outputs at a finite rate.

- **Token bucket Algorithm**

**Need** of token bucket Algorithm:-

The
 leaky bucket algorithm enforces output pattern at the average rate, no 
matter how bursty the traffic is. So in order to deal with the bursty 
traffic we need a flexible algorithm so that the data is not lost. One 
such algorithm is token bucket algorithm.

**Steps** of this algorithm can be described as follows:

1. In regular intervals tokens are thrown into the bucket. ƒ
2. The bucket has a maximum capacity. ƒ
3. If there is a ready packet, a token is removed from the bucket, and the packet is sent.
4. If there is no token in the bucket, the packet cannot be sent.

Let’s understand with an example,

In
 figure (A) we see a bucket holding three tokens, with five packets 
waiting to be transmitted. For a packet to be transmitted, it must 
capture and destroy one token. In figure (B) We see that three of the 
five packets have gotten through, but the other two are stuck waiting 
for more tokens to be generated.

**Ways in which token bucket is superior to leaky bucket:**The
 leaky bucket algorithm controls the rate at which the packets are 
introduced in the network, but it is very conservative in nature. Some 
flexibility is introduced in the token bucket algorithm. In the token 
bucket, algorithm tokens are generated at each tick (up to a certain 
limit). For an incoming packet to be transmitted, it must capture a 
token and the transmission takes place at the same rate. Hence some of 
the busty packets are transmitted at the same rate if tokens are 
available and thus introduces some amount of flexibility in the system.

**Formula:** M * s = C + ρ * swhere S – is time takenM – Maximum output rateρ – Token arrival rateC – Capacity of the token bucket in byte

Let’s understand with an example,

!https://media.geeksforgeeks.org/wp-content/uploads/leakybuk.jpg

Link to question on leaky bucket algorithm: https://www.geeksforgeeks.org/computer-networks-set-8/
*** Computer Network | Leaky bucket algorithm
In 
the network layer, before the network can make Quality of service 
guarantees, it must know what traffic is being guaranteed. One of the 
main causes of congestion is that traffic is often bursty.

To understand this concept first we have to know little about traffic shaping. **Traffic Shaping**
 is a mechanism to control the amount and the rate of traffic sent to 
the network. Approach of congestion management is called Traffic 
shaping. Traffic shaping helps to regulate the rate of data transmission
 and reduces congestion.

There are 2 types of traffic shaping algorithms:

1. Leaky Bucket
2. Token Bucket

Suppose
 we have a bucket in which we are pouring water, at random points in 
time, but we have to get water at a fixed rate, to achieve this we will 
make a hole at the bottom of the bucket. This will ensure that the water
 coming out is at some fixed rate, and also if the bucket gets full, 
then we will stop pouring water into it.

The
 input rate can vary, but the output rate remains constant. Similarly, 
in networking, a technique called leaky bucket can smooth out bursty 
traffic. Bursty chunks are stored in the bucket and sent out at an 
average rate.

!https://media.geeksforgeeks.org/wp-content/uploads/leakyTap-1.png

In
 the above figure, we assume that the network has committed a bandwidth 
of 3 Mbps for a host. The use of the leaky bucket shapes the input 
traffic to make it conform to this commitment. In the above figure, the 
host sends a burst of data at a rate of 12 Mbps for 2s, for a total of 
24 Mbits of data. The host is silent for 5 s and then sends data at a 
rate of 2 Mbps for 3 s, for a total of 6 Mbits of data. In all, the host
 has sent 30 Mbits of data in 10 s. The leaky bucket smooths out the 
traffic by sending out data at a rate of 3 Mbps during the same 10 s.

Without
 the leaky bucket, the beginning burst may have hurt the network by 
consuming more bandwidth than is set aside for this host. We can also 
see that the leaky bucket may prevent congestion.

A simple leaky 
bucket algorithm can be implemented using FIFO queue. A FIFO queue holds
 the packets. If the traffic consists of fixed-size packets (e.g., cells
 in ATM networks), the process removes a fixed number of packets from 
the queue at each tick of the clock. If the traffic consists of 
variable-length packets, the fixed output rate must be based on the 
number of bytes or bits.

The following is an algorithm for variable-length packets:

1. Initialize a counter to n at the tick of the clock.
2. Repeat until n is smaller than the packet size of the packet at the head of the queue.
    1. Pop a packet out of the head of the queue, say P.
    2. Send the packet P, into the network
    3. Decrement the counter by the size of packet P.
3. Reset the counter and go to step 1.

> Note: In the below examples, the head of the queue is the rightmost position and the tail of the queue is the leftmost position.
> 

**Example:** Let n=1000

Packet=

!https://media.geeksforgeeks.org/wp-content/uploads/leak-bucket-1.png

Since n > size of the packet at the head of the Queue, i.e. n > 200 Therefore, n = 1000-200 = 800 Packet size of 200 is sent into the network. 

!https://media.geeksforgeeks.org/wp-content/uploads/leak-bucket-2.png

Now, again n > size of the packet at the head of the Queue, i.e. n > 400 Therefore, n = 800-400 = 400 Packet size of 400 is sent into the network. 

!https://media.geeksforgeeks.org/wp-content/uploads/leak-bucket-3.png

Since, n < size of the packet at the head of the Queue, i.e.  n < 450Therefore, the procedure is stopped.

Initialise n = 1000 on another tick of the clock. This procedure is repeated until all the packets are sent into the network.

Below is the implementation of above explained approach: 

`// cpp program to implement leakybucket`

`#include <bits/stdc++.h>`

`using` `namespace` `std;`

`int` `main()`

`{`

`int` `no_of_queries, storage, output_pkt_size;`

`int` `input_pkt_size, bucket_size, size_left;`

`// initial packets in the bucket`

`storage = 0;`

`// total no. of times bucket content is checked`

`no_of_queries = 4;`

`// total no. of packets that can`

`// be accommodated in the bucket`

`bucket_size = 10;`

`// no. of packets that enters the bucket at a time`

`input_pkt_size = 4;`

`// no. of packets that exits the bucket at a time`

`output_pkt_size = 1;`

`for` `(int` `i = 0; i < no_of_queries; i++) // space left`

`{`

`size_left = bucket_size - storage;`

`if` `(input_pkt_size <= size_left) {`

`// update storage`

`storage += input_pkt_size;`

`}`

`else` `{`

`printf("Packet loss = %d\n", input_pkt_size);`

`}`

`printf("Buffer size= %d out of bucket size= %d\n",`

`storage, bucket_size);`

`storage -= output_pkt_size;`

`}`

`return` `0;`

`}`

`// This code is contributed by bunny09262002`

`// Improved by: rishitchaudhary`

**Output** 

```
Buffer size= 4 out of bucket size= 10
Buffer size= 7 out of bucket size= 10
Buffer size= 10 out of bucket size= 10
Packet loss = 4
Buffer size= 9 out of bucket size= 10
```

**Difference between Leaky and Token buckets –**

[Untitled Database](https://www.notion.so/264a8236e57d4fd78cd99b414b48e066?pvs=21)

**Some advantage of token Bucket over leaky bucket**

- If a bucket is full in tokens Bucket, tokens are discard not packets. While in leaky bucket, packets are discarded.
- Token Bucket can send large bursts at a faster rate while leaky bucket always sends packets at constant rate.

This article is contributed by **Abhishek Kumar** and **[Himanshu Gupta](https://auth.geeksforgeeks.org/user/Himanshu%20Gupta%2028/articles)**.
 If you like GeeksforGeeks and would like to contribute, you can also 
write an article using write.geeksforgeeks.org or mail your article to 
review-team@geeksforgeeks.org. See your article appearing on the 
GeeksforGeeks main page and help other Geeks.

Please write comments if you find anything incorrect, or if you want to share more information about the topic discussed above.
*** Services and Segment structure in TCP
The 
Transmission Control Protocol is the most common transport layer 
protocol. It works together with IP and provides a reliable transport 
service between processes using the network layer service provided by 
the IP protocol. The various **services** provided by the TCP to the application layer are as follows: 

1. **Process-to-Process Communication –** TCP provides a process to process communication, i.e, the transfer of data
that takes place between individual processes executing on end systems.
This is done using port numbers or port addresses. Port numbers are 16
bits long that help identify which process is sending or receiving data
on a host. 
2. **Stream oriented –** This
means that the data is sent and received as a stream of bytes(unlike UDP or IP that divides the bits into datagrams or packets). However, the
network layer, that provides service for the TCP, sends packets of
information not streams of bytes. Hence, TCP groups a number of bytes
together into a *segment* and adds a header to each of these
segments and then delivers these segments to the network layer. At the
network layer, each of these segments is encapsulated in an IP packet
for transmission. The TCP header has information that is required for
control purposes which will be discussed along with the segment
structure. 
3. **Full-duplex service –** This means that the communication can take place in both directions at the same time. 
4. **Connection-oriented service –** Unlike UDP, TCP provides a connection-oriented service. It defines 3 different phases:
    - Connection establishment
    - Data transfer
    - Connection termination
5. **Reliability –** TCP is reliable as it uses checksum for error detection, attempts to
recover lost or corrupted packets by re-transmission, acknowledgement
policy and timers. It uses features like byte number and sequence number and acknowledgement number so as to ensure reliability. Also, it uses
congestion control mechanisms. 
6. **Multiplexing –** TCP does multiplexing and de-multiplexing at the sender and receiver ends
respectively as a number of logical connections can be established
between port numbers over a physical connection. 

**Byte number, Sequence number and Acknowledgement number:** All
 the data bytes that are to be transmitted are numbered and the 
beginning of this numbering is arbitrary. Sequence numbers are given to 
the segments so as to reassemble the bytes at the receiver end even if 
they arrive in a different order. The sequence number of a segment is 
the byte number of the first byte that is being sent. The 
acknowledgement number is required since TCP provides full-duplex 
service. The acknowledgement number is the next byte number that the 
receiver expects to receive which also provides acknowledgement for 
receiving the previous bytes. Example:

!https://media.geeksforgeeks.org/wp-content/uploads/tcp1-2.png

In
 this example we see that A sends acknowledgement number1001, which 
means that it has received data bytes till byte number 1000 and expects 
to receive 1001 next, hence B next sends data bytes starting from 1001. 
Similarly, since B has received data bytes till byte number 13001 after 
the first data transfer from A to B, therefore B sends acknowledgement 
number 13002, the byte number that it expects to receive from A next.

**TCP Segment structure –** A TCP segment consists of data bytes to be sent and a header that is added to the data by TCP as shown:

!https://media.geeksforgeeks.org/wp-content/uploads/TCPSegmentHeader-1.png

The
 header of a TCP segment can range from 20-60 bytes. 40 bytes are for 
options. If there are no options, a header is 20 bytes else it can be of
 upmost 60 bytes. Header fields: 

- **Source Port Address –** A 16-bit field that holds the port address of the application that is sending the data segment.
- **Destination Port Address –** A 16-bit field that holds the port address of the application in the host that is receiving the data segment.
- **Sequence Number –** A 32-bit field that holds the sequence number, i.e, the byte number of
the first byte that is sent in that particular segment. It is used to
reassemble the message at the receiving end of the segments that are
received out of order.
- **Acknowledgement Number –** A 32-bit field that holds the acknowledgement number, i.e, the byte
number that the receiver expects to receive next. It is an
acknowledgement for the previous bytes being received successfully.
- **Header Length (HLEN) –** This is a 4-bit field that indicates the length of the TCP header by a
number of 4-byte words in the header, i.e if the header is 20 bytes(min
length of TCP header), then this field will hold 5 (because 5 x 4 = 20)
and the maximum length: 60 bytes, then it’ll hold the value 15(because
15 x 4 = 60). Hence, the value of this field is always between 5 and
15.
- **Control flags –** These are 6 1-bit control bits that control connection establishment, connection
termination, connection abortion, flow control, mode of transfer etc.
Their function is:
    - URG: Urgent pointer is valid
    - ACK: Acknowledgement number is valid( used in case of cumulative acknowledgement)
    - PSH: Request for push
    - RST: Reset the connection
    - SYN: Synchronize sequence numbers
    - FIN: Terminate the connection
- **Window size –** This field tells the window size of the sending TCP in bytes.
- **Checksum –** This field holds the checksum for error control. It is mandatory in TCP as opposed to UDP.
- **Urgent pointer –** This field (valid only if the URG control flag is set) is used to point to
data that is urgently required that needs to reach the receiving process at the earliest. The value of this field is added to the sequence
number to get the byte number of the last urgent byte.

**TCP Connection –** TCP is connection-oriented. A [TCP connection](https://www.geeksforgeeks.org/computer-network-tcp-connection-establishment/) is established by a [3-way handshake](https://www.geeksforgeeks.org/computer-network-tcp-3-way-handshake-process/).
*** TCP Congestion Control
**Prerequisites –** [Basic Congestion control knowledge](https://www.geeksforgeeks.org/computer-networks-congestion-control/)

TCP
 uses a congestion window and a congestion policy that avoid congestion.
 Previously, we assumed that only the receiver can dictate the sender’s 
window size. We ignored another entity here, the network. If the network
 cannot deliver the data as fast as it is created by the sender, it must
 tell the sender to slow down. In other words, in addition to the 
receiver, the network is a second entity that determines the size of the
 sender’s window.

**Congestion policy in TCP –**

1. Slow Start Phase: starts slowly increment is exponential to threshold
2. Congestion Avoidance Phase: After reaching the threshold increment is by 1
3. Congestion Detection Phase: Sender goes back to Slow start phase or Congestion avoidance phase.

**Slow Start Phase : exponential increment –** In this phase after every RTT the congestion window size increments exponentially.

```
Initially cwnd = 1
After 1 RTT, cwnd = 2^(1) = 2
2 RTT, cwnd = 2^(2) = 4
3 RTT, cwnd = 2^(3) = 8

```

**Congestion Avoidance Phase : additive increment –** This phase starts after the threshold value also denoted as *ssthresh*. The size of *cwnd*(congestion window) increases additive. After each RTT cwnd = cwnd + 1.

```
Initially cwnd = i
After 1 RTT, cwnd = i+1
2 RTT, cwnd = i+2
3 RTT, cwnd = i+3

```

**Congestion Detection Phase : multiplicative decrement –** 
If congestion occurs, the congestion window size is decreased. The only 
way a sender can guess that congestion has occurred is the need to 
retransmit a segment. Retransmission is needed to recover a missing 
packet that is assumed to have been dropped by a router due to 
congestion. Retransmission can occur in one of two cases: when the RTO 
timer times out or when three duplicate ACKs are received.

- **Case 1 : Retransmission due to Timeout –** In this case congestion possibility is high.
    
    (a) ssthresh is reduced to half of the current window size.(b) set cwnd = 1(c) start with slow start phase again.
    
- **Case 2 : Retransmission due to 3 Acknowledgement Duplicates –** In this case congestion possibility is less.
    
    (a) ssthresh value reduces to half of the current window size.(b) set cwnd= ssthresh(c) start with congestion avoidance phase
    

**Example –**
 Assume a TCP protocol experiencing the behavior of slow start. At 5th 
transmission round with a threshold (ssthresh) value of 32 goes into 
congestion avoidance phase and continues till 10th transmission. At 10th
 transmission round, 3 duplicate ACKs are received by the receiver and 
enter into additive increase mode. Timeout occurs at 16th transmission 
round. Plot the transmission round (time) vs congestion window size of 
TCP segments.

!https://media.geeksforgeeks.org/wp-content/uploads/20171028_002328.jpg

**GATE CS Corner Questions –**

Practicing
 the following questions will help you test your knowledge. All 
questions have been asked in GATE in previous years or in GATE Mock 
Tests. It is highly recommended that you practice them.

1. [GATE CS 2008, Question 56](https://www.geeksforgeeks.org/gate-gate-cs-2008-question-56/)
2. [GATE CS 2012, Question 65](https://www.geeksforgeeks.org/gate-gate-cs-2012-question-45/)
3. [GATE CS 2014 (Set 1), Question 65](https://www.geeksforgeeks.org/gate-gate-cs-2014-set-1-question-37/)
4. [GATE IT 2005, Question 73](https://www.geeksforgeeks.org/gate-gate-it-2005-question-73/)

This article is contributed by **[SHAURYA UPPAL](https://www.linkedin.com/in/shaurya-uppal-3b7a6373/)**. If you like GeeksforGeeks and would like to contribute, you can also write an article using [write.geeksforgeeks.org](https://write.geeksforgeeks.org/)
 or mail your article to review-team@geeksforgeeks.org. See your article
 appearing on the GeeksforGeeks main page and help other Geeks.

Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above.

!https://media.geeksforgeeks.org/wp-content/post-ads-banner/2022-05-25-15-57-36-InterviewSeriesPrepareInArticleAd.webp
*** TCP 3-Way Handshake Process
This
 could also be seen as a way of how TCP connection is established. 
Before getting into the details, let us look at some basics. TCP stands 
for **Transmission Control Protocol** which indicates that it does something to control the transmission of the data in a reliable way.

The process of communication between devices over the internet happens according to the current **TCP/IP**
 suite model(stripped out version of OSI reference model). The 
Application layer is a top pile of a stack of TCP/IP models from where 
network referenced applications like web browsers on the client-side 
establish a connection with the server. From the application layer, the 
information is transferred to the transport layer where our topic comes 
into the picture. The two important protocols of this layer are – TCP, **UDP(User Datagram Protocol)**
 out of which TCP is prevalent(since it provides reliability for the 
connection established). However, you can find an application of UDP in 
querying the DNS server to get the binary equivalent of the Domain Name 
used for the website.

!https://media.geeksforgeeks.org/wp-content/uploads/handshake-1.png

TCP provides reliable communication with something called **Positive Acknowledgement with Re-transmission(PAR)**.
 The Protocol Data Unit(PDU) of the transport layer is called a segment.
 Now a device using PAR resend the data unit until it receives an 
acknowledgement. If the data unit received at the receiver’s end is 
damaged(It checks the data with checksum functionality of the transport 
layer that is used for Error Detection), the receiver discards the 
segment. So the sender has to resend the data unit for which positive 
acknowledgement is not received. You can realize from the above 
mechanism that three segments are exchanged between sender(client) and 
receiver(server) for a reliable TCP connection to get established. Let 
us delve into how this mechanism works :

!https://media.geeksforgeeks.org/wp-content/uploads/TCP-connection-1.png

- **Step 1 (SYN):** In the first step, the client wants to establish a connection with a
server, so it sends a segment with SYN(Synchronize Sequence Number)
which informs the server that the client is likely to start
communication and with what sequence number it starts segments with
- **Step 2 (SYN + ACK):** Server responds to the client request with SYN-ACK signal bits set.
Acknowledgement(ACK) signifies the response of the segment it received
and SYN signifies with what sequence number it is likely to start the
segments with
- **Step 3 (ACK):** In the final part
client acknowledges the response of the server and they both establish a reliable connection with which they will start the actual data transfer
*** TCP Connection Establishment
Prerequisite – [TCP 3-Way Handshake Process](https://www.geeksforgeeks.org/computer-network-tcp-3-way-handshake-process/) TCP
 is a connection-oriented protocol and every connection-oriented 
protocol needs to establish a connection in order to reserve resources 
at both the communicating ends.

**Connection Establishment –**

1. Sender starts the process with the following:

- **Sequence number (Seq=521):** contains the random initial sequence number generated at the sender side.
- **Syn flag (Syn=1):** request the receiver to synchronize its sequence number with the above-provided sequence number.
- **Maximum segment size (MSS=1460 B):** sender tells its maximum segment size, so that receiver sends datagram
which won’t require any fragmentation. MSS field is present inside **Option** field in TCP header.
- **Window size (window=14600 B):** sender tells about his buffer capacity in which he has to store messages from the receiver.

2. TCP is a full-duplex protocol so both sender and receiver require a window for receiving messages from one another.

- **Sequence number (Seq=2000):** contains the random initial sequence number generated at the receiver side.
- **Syn flag (Syn=1):** request the sender to synchronize its sequence number with the above-provided sequence number.
- **Maximum segment size (MSS=500 B):** sender tells its maximum segment size, so that receiver sends datagram
which won’t require any fragmentation. MSS field is present inside **Option** field in TCP header. Since MSS < MSS, both parties agree for minimum MSS i.e., 500 B to avoid fragmentation of packets at both ends.
    
    receiver
    
    sender
    

```
Therefore, receiver can send maximum of 14600/500 = 29 packets.
This is the receiver's sending window size.
```

- **Window size (window=10000 B):** receiver tells about his buffer capacity in which he has to store messages from the sender.

```
Therefore, sender can send a maximum of 10000/500 = 20 packets.
This is the sender's sending window size.
```

- **Acknowledgement Number (Ack no.=522):** Since sequence number 521 is received by the receiver so, it makes a
request for the next sequence number with Ack no.=522 which is the next
packet expected by the receiver since Syn flag consumes 1 sequence no.
- **ACK flag (ACk=1):** tells that the acknowledgement number field contains the next sequence expected by the receiver.

3. Sender makes the final reply for connection establishment in the following way:

- **Sequence number (Seq=522):** since sequence number = 521 in 1 step and SYN flag consumes one sequence number hence, the next sequence number will be 522.
    
    st
    
- **Acknowledgement Number (Ack no.=2001):** since the sender is acknowledging SYN=1 packet from the receiver with
sequence number 2000 so, the next sequence number expected is 2001.
- **ACK flag (ACK=1):** tells that the acknowledgement number field contains the next sequence expected by the sender.

!https://media.geeksforgeeks.org/wp-content/uploads/net.png

Since the connection establishment phase of TCP makes use of 3 packets, it is also known as [3-way Handshaking](https://www.geeksforgeeks.org/computer-network-tcp-3-way-handshake-process/) **(SYN, SYN + ACK, ACK).**

- **GATE question –** [GATE IT 2008 | Question 67](https://www.geeksforgeeks.org/gate-gate-it-2008-question-67/)

Related next article – [TCP Connection Termination](https://www.geeksforgeeks.org/computer-network-tcp-connection-termination/)
*** TCP Connection Termination
In [TCP 3-way Handshake Process](https://www.geeksforgeeks.org/computer-network-tcp-3-way-handshake-process/) we studied that how connections are established between client and server in Transmission Control Protocol (TCP) using **SYN**
 bit segments. In this article, we will study how TCP close connection 
between Client and Server. Here we will also need to send bit segments 
to a server which **FIN** bit is set to 1.

TCP supports two types of connection releases like most connection-oriented transport protocols: 

1. **Graceful connection release –** In the Graceful connection release, the connection is open until both parties have closed their sides of the connection.
2. **Abrupt connection release –** In an Abrupt connection release, either one TCP entity is forced to close
the connection or one user closes both directions of data transfer.

**Abrupt connection release :** An abrupt connection release is carried out when an RST segment is sent. An RST segment can be sent for the below reasons:

1. When a non-SYN segment was received for a non-existing TCP connection. 
2. In an open connection, some TCP implementations send an RST segment when a segment with an invalid header is received. This will prevent attacks
by closing the corresponding connection. 
3. When some
implementations need to close an existing TCP connection, they send an
RST segment. They will close an existing TCP connection for the
following reasons:
    - Lack of resources to support the connection
    - The remote host is now unreachable and has stopped responding.

When
 a TCP entity sends an RST segment, it should contain 00 if it does not 
belong to any existing connection else it should contain the current 
value of the sequence number for the connection and the acknowledgment 
number should be set to the next expected in- sequence number on this 
connection.

**Graceful Connection Release :** The
 common way of terminating a TCP connection is by using the TCP header’s
 FIN flag. This mechanism allows each host to release its own side of 
the connection individually.

!https://media.geeksforgeeks.org/wp-content/uploads/CN.png

How mechanism works In TCP : 

1. **Step 1 (FIN From Client) –** Suppose that the client application decides it wants to close the connection.
(Note that the server could also choose to close the connection). This
causes the client to send a TCP segment with the **FIN** bit set to **1** to the server and to enter the **FIN_WAIT_1** state. While in the **FIN_WAIT_1** state, the client waits for a TCP segment from the server with an acknowledgment (ACK).
2. **Step 2 (ACK From Server) –** When the Server received the FIN bit segment from Sender (Client), Server
Immediately sends acknowledgement (ACK) segment to the Sender (Client).
3. **Step 3 (Client waiting) –** While in the **FIN_WAIT_1** state, the client waits for a TCP segment from the server with an
acknowledgment. When it receives this segment, the client enters the **FIN_WAIT_2** state. While in the **FIN_WAIT_2** state, the client waits for another segment from the server with the FIN bit set to 1.
4. **Step 4 (FIN from Server) –** The server sends the FIN bit segment to the Sender(Client) after some time
when the Server sends the ACK segment (because of some closing process
in the Server).
5. **Step 5 (ACK from Client) –** When the Client receives the FIN bit segment from the Server, the client acknowledges the server’s segment and enters the **TIME_WAIT** state. The **TIME_WAIT** state lets the client resend the final acknowledgment in case the **ACK** is lost. The time spent by clients in the **TIME_WAIT** state depends on their implementation, but their typical values are 30
seconds, 1 minute, and 2 minutes. After the wait, the connection
formally closes and all resources on the client-side (including port
numbers and buffer data) are released.

In the below Figures 
illustrate the series of states visited by the server-side and also the 
Client-side, assuming the client begins connection tear-down. In these 
two state-transition figures, we have only shown how a TCP connection is
 normally established and shut down.

TCP states visited by ClientSide – 

!https://media.geeksforgeeks.org/wp-content/uploads/CN-1.png

TCP states visited by ServerSide – 

!https://media.geeksforgeeks.org/wp-content/uploads/CN-2.png

Here
 we have not described what happens in certain scenarios like when both 
sides of a connection want to initiate or shut down at the same time. If
 you are interested in learning more about this and other advanced 
issues concerning TCP, you are encouraged to see Stevens’comprehensive 
book.

**GATE Question –** Consider a TCP client 
and a TCP server running on two different machines. After completing the
 data transfer, the TCP client calls **close** to terminate
 the connection and a FIN segment is sent to the TCP server. Server-side
 TCP responds by sending an ACK which is received by the client-side 
TCP. As per the TCP connection state diagram(RFC 793), in which state 
does the client-side TCP connection wait for the FIN from the 
server-side TCP? (A) LAST-ACK (B) TIME-WAIT (C) FIN-WAIT-1 (D) FIN-WAIT-2

**Explanation :** (D) [GATE CS 2017 (Set 1), Question 12](https://www.geeksforgeeks.org/gate-gate-cs-2017-set-1-question-12/)

**References –** [TCP Connection Termination – Wikipedia](https://en.wikipedia.org/wiki/Transmission_Control_Protocol#Connection_termination) http://www.bau.edu.jo/UserPortal/UserProfile/PostsAttach/10617_1870_1.pdf

This article is contributed by **[Kadam Patel](https://auth.geeksforgeeks.org/profile.php?user=kd)**. If you like GeeksforGeeks and would like to contribute, you can also write an article using [write.geeksforgeeks.org](http://www.write.geeksforgeeks.org/)
 or mail your article to review-team@geeksforgeeks.org. See your article
 appearing on the GeeksforGeeks main page and help other Geeks.

Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above.
*** Error Control in TCP
**Prerequisite –** [TCP/IP Model](https://www.geeksforgeeks.org/computer-network-tcpip-model/) TCP protocol has methods for finding out corrupted segments, missing segments, out-of-order segments and duplicated segments.

**Error control** in TCP is mainly done through the use of **three simple techniques** :

1. **Checksum –** Every segment contains a checksum field which is used to find corrupted segments. If the segment is corrupted, then that segment is discarded
by the destination TCP and is considered lost.
2. **Acknowledgement –** TCP has another mechanism called acknowledgement to affirm that the
data segments have been delivered. Control segments that contain no data but have sequence numbers will be acknowledged as well but ACK segments are not acknowledged.
3. **Retransmission –** When a
segment is missing, delayed to deliver to a receiver, corrupted when it
is checked by the receiver then that segment is retransmitted again.
Segments are retransmitted only during two events: when the sender
receives three duplicate acknowledgements (ACK) or when a retransmission timer expires.
    - **Retransmission after RTO:** TCP
    always preserves one retransmission time-out (RTO) timer for all sent
    but not acknowledged segments. When the timer runs out of time, the
    earliest segment is retransmitted. Here no timer is set for
    acknowledgement. In TCP, the RTO value is dynamic in nature and it is
    updated using the round trip time (RTT) of segments. RTT is the time
    duration needed for a segment to reach the receiver and an
    acknowledgement to be received by the sender.
    - **Retransmission after Three duplicate ACK segments:** RTO method works well when the value of RTO is small. If it is large,
    more time is needed to get confirmation about whether a segment has been delivered or not. Sometimes one segment is lost and the receiver
    receives so many out-of-order segments that they cannot be saved. In
    order to solve this situation, three duplicate acknowledgement method is used and missing segment is retransmitted immediately instead of
    retransmitting already delivered segment. This is a fast retransmission
    because it makes it possible to quickly retransmit lost segments instead of waiting for timer to end.

This article is contributed by **Swasthik**.
 If you like GeeksforGeeks and would like to contribute, you can also 
write an article using write.geeksforgeeks.org or mail your article to 
review-team@geeksforgeeks.org. See your article appearing on the 
GeeksforGeeks main page and help other Geeks.

Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above.
*** TCP Timers
TCP 
uses several timers to ensure that excessive delays are not encountered 
during communications. Several of these timers are elegant, handling 
problems that are not immediately obvious at first analysis. Each of the
 timers used by TCP is examined in the following sections, which reveal 
its role in ensuring data is properly sent from one connection to 
another.

**TCP implementation uses four timers –**

- **Retransmission Timer –** To retransmit lost segments, TCP uses retransmission timeout (RTO).
When TCP sends a segment the timer starts and stops when the
acknowledgment is received. If the timer expires timeout occurs and the
segment is retransmitted. RTO (retransmission timeout is for 1 RTT) to
calculate retransmission timeout we first need to calculate the
RTT(round trip time). **RTT three types –**
    - **Measured RTT(RTTm) –** The measured round-trip time for a segment is the time required for the segment to reach the destination and be acknowledged, although the
    acknowledgement may include other segments.
    - **Smoothed RTT(RTTs) –** It is the weighted average of RTTm. RTTm is likely to change and its
    fluctuation is so high that a single measurement cannot be used to
    calculate RTO.

```
Initially -> No value
After the first measurement -> RTTs=RTTm
After each measurement -> RTTs= (1-t)*RTTs + t*RTTm
Note: t=1/8 (default if not given)
```

- **Deviated RTT(RTTd) –** Most implementations do not use RTTs alone so RTT deviated is also calculated to find out RTO.

```
Initially -> No value
After the first measurement -> RTTd=RTTm/2
After each measurement -> RTTd= (1-k)*RTTd + k*(RTTm-RTTs)
Note: k=1/4 (default if not given)
```

- **Persistent Timer –** To deal with a zero-window-size deadlock situation, TCP uses a
persistence timer. When the sending TCP receives an acknowledgment with a window size of zero, it starts a persistence timer. When the
persistence timer goes off, the sending TCP sends a special segment
called a probe. This segment contains only 1 byte of new data. It has a
sequence number, but its sequence number is never acknowledged; it is
even ignored in calculating the sequence number for the rest of the
data. The probe causes the receiving TCP to resend the acknowledgment
which was lost.
- **Keep Alive Timer –** A keepalive
timer is used to prevent a long idle connection between two TCPs. If a
client opens a TCP connection to a server transfers some data and
becomes silent the client will crash. In this case, the connection
remains open forever. So a keepalive timer is used. Each time the server hears from a client, it resets this timer. The time-out is usually 2
hours. If the server does not hear from the client after 2 hours, it
sends a probe segment. If there is no response after 10 probes, each of
which is 75 s apart, it assumes that the client is down and terminates
the connection.
- **Time Wait Timer –** This timer is used during [tcp connection termination](https://www.geeksforgeeks.org/computer-network-tcp-connection-termination/). The timer starts after sending the last Ack for 2nd FIN and closing the connection.
    
    *After
     a TCP connection is closed, it is possible for datagrams that are still
     making their way through the network to attempt to access the closed 
    port. The quiet timer is intended to prevent the just-closed port from 
    reopening again quickly and receiving these last datagrams.*
    
    The **quiet timer**
     is usually set to twice the maximum segment lifetime (the same value as
     the Time-To-Live field in an IP header), ensuring that all segments 
    still heading for the port have been discarded.
    

**Reference –** [TCP Timers – Que10](http://www.ques10.com/p/9848/explain-tcp-timers-1/)

This article is contributed by **[SHAURYA UPPAL](https://www.linkedin.com/in/shaurya-uppal-3b7a6373/)**. If you like GeeksforGeeks and would like to contribute, you can also write an article using [write.geeksforgeeks.org](http://www.write.geeksforgeeks.org/)
 or mail your article to review-team@geeksforgeeks.org. See your article
 appearing on the GeeksforGeeks main page and help other Geeks.

Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above.
*** TCP flags
In 
TCP connection, flags are used to indicate a particular state of 
connection or to provide some additional useful information like 
troubleshooting purposes or to handle a control of a particular 
connection. Most commonly used flags are **“SYN”, “ACK” and “FIN”**. Each flag corresponds to 1 bit information.

**Types of Flags:** 

- **Synchronization (SYN) –** It is used in first step of [connection establishment](https://www.geeksforgeeks.org/computer-network-tcp-connection-establishment/) phase or 3-way handshake process between the two hosts. Only the first
packet from sender as well as receiver should have this flag set. This
is used for synchronizing sequence number i.e. to tell the other end
which sequence number they should accept.
- **Acknowledgement (ACK) –** It is used to acknowledge packets which are successful received by the
host. The flag is set if the acknowledgement number field contains a
valid acknowledgement number. In given below diagram, the receiver
sends an ACK = 1 as well as SYN = 1 in the second step of connection
establishment to tell sender that it received its initial packet.
- **Finish (FIN) –** It is used to request for [connection termination](https://www.geeksforgeeks.org/computer-network-tcp-connection-termination/) i.e. when there is no more data from the sender, it requests for
connection termination. This is the last packet sent by sender. It frees the reserved resources and gracefully terminate the connection.
- **Reset (RST) –** It is used to terminate the connection if the RST sender feels
something is wrong with the TCP connection or that the conversation
should not exist. It can get send from receiver side when packet is send to particular host that was not expecting it.

**Finish (FIN) v/s Reset (RST) –** 

!https://media.geeksforgeeks.org/wp-content/uploads/po-1-1.png

- **Push (PSH) –** Transport layer by default waits for some time for application layer to send enough data equal to maximum segment size so that the number of
packets transmitted on network minimizes which is not desirable by some
application like interactive applications(chatting). Similarly transport layer at receiver end buffers packets and transmit to application layer if it meets certain criteria.
    
    This problem is solved by using PSH. 
    Transport layer sets PSH = 1 and immediately sends the segment to 
    network layer as soon as it receives signal from application layer. 
    Receiver transport layer, on seeing PSH = 1 immediately forwards the 
    data to application layer. In general, it tells the receiver to process these packets as they are received instead of buffering them. 
    
- **Urgent (URG) –**Data inside a segment with URG = 1 flag is forwarded to application layer
immediately even if there are more data to be given to application
layer. It is used to notify the receiver to process the urgent packets
before processing all other packets. The receiver will be notified when
all known urgent data has been received.

**Push (PSH) v/s Urgent (URG) –** 

!https://media.geeksforgeeks.org/wp-content/uploads/po-1-2.png
*** TCP Server-Client implementation in C
Prerequisites – [Socket Programming in C/C++](https://www.geeksforgeeks.org/socket-programming-cc/), [TCP and UDP server using select](https://www.geeksforgeeks.org/tcp-and-udp-server-using-select/), [UDP Server-Client implementation in C](https://www.geeksforgeeks.org/udp-server-client-implementation-c/) If
 we are creating a connection between client and server using TCP then 
it has few functionality like, TCP is suited for applications that 
require high reliability, and transmission time is relatively less 
critical. It is used by other protocols like HTTP, HTTPs, FTP, SMTP, 
Telnet. TCP rearranges data packets in the order specified. There is 
absolute guarantee that the data transferred remains intact and arrives 
in the same order in which it was sent. TCP does Flow Control and 
requires three packets to set up a socket connection, before any user 
data can be sent. TCP handles reliability and congestion control. It 
also does error checking and error recovery. Erroneous packets are 
retransmitted from the source to the destination.

The entire process can be broken down into following steps:

!https://media.geeksforgeeks.org/wp-content/uploads/Socket_server-1.png

The entire process can be broken down into following steps:

**TCP Server –**

1. using create(), Create TCP socket.
2. using bind(), Bind the socket to server address.
3. using listen(), put the server socket in a passive mode, where it waits for
the client to approach the server to make a connection
4. using accept(), At this point, connection is established between client and server, and they are ready to transfer data.
5. Go back to Step 3.

**TCP Client –**

1. Create TCP socket.
2. connect newly created client socket to server.

TCP Server:

`#include <stdio.h>`

`#include <netdb.h>`

`#include <netinet/in.h>`

`#include <stdlib.h>`

`#include <string.h>`

`#include <sys/socket.h>`

`#include <sys/types.h>`

`#define MAX 80`

`#define PORT 8080`

`#define SA struct sockaddr`

`// Function designed for chat between client and server.`

`void` `func(int` `connfd)`

`{`

`char` `buff[MAX];`

`int` `n;`

`// infinite loop for chat`

`for` `(;;) {`

`bzero(buff, MAX);`

`// read the message from client and copy it in buffer`

`read(connfd, buff, sizeof(buff));`

`// print buffer which contains the client contents`

`printf("From client: %s\t To client : ", buff);`

`bzero(buff, MAX);`

`n = 0;`

`// copy server message in the buffer`

`while` `((buff[n++] = getchar()) != '\n')`

`;`

`// and send that buffer to client`

`write(connfd, buff, sizeof(buff));`

`// if msg contains "Exit" then server exit and chat ended.`

`if` `(strncmp("exit", buff, 4) == 0) {`

`printf("Server Exit...\n");`

`break;`

`}`

`}`

`}`

`// Driver function`

`int` `main()`

`{`

`int` `sockfd, connfd, len;`

`struct` `sockaddr_in servaddr, cli;`

`// socket create and verification`

`sockfd = socket(AF_INET, SOCK_STREAM, 0);`

`if` `(sockfd == -1) {`

`printf("socket creation failed...\n");`

`exit(0);`

`}`

`else`

`printf("Socket successfully created..\n");`

`bzero(&servaddr, sizeof(servaddr));`

`// assign IP, PORT`

`servaddr.sin_family = AF_INET;`

`servaddr.sin_addr.s_addr = htonl(INADDR_ANY);`

`servaddr.sin_port = htons(PORT);`

`// Binding newly created socket to given IP and verification`

`if` `((bind(sockfd, (SA*)&servaddr, sizeof(servaddr))) != 0) {`

`printf("socket bind failed...\n");`

`exit(0);`

`}`

`else`

`printf("Socket successfully binded..\n");`

`// Now server is ready to listen and verification`

`if` `((listen(sockfd, 5)) != 0) {`

`printf("Listen failed...\n");`

`exit(0);`

`}`

`else`

`printf("Server listening..\n");`

`len = sizeof(cli);`

`// Accept the data packet from client and verification`

`connfd = accept(sockfd, (SA*)&cli, &len);`

`if` `(connfd < 0) {`

`printf("server accept failed...\n");`

`exit(0);`

`}`

`else`

`printf("server accept the client...\n");`

`// Function for chatting between client and server`

`func(connfd);`

`// After chatting close the socket`

`close(sockfd);`

`}`

TCP Client:

`#include <netdb.h>`

`#include <stdio.h>`

`#include <stdlib.h>`

`#include <string.h>`

`#include <sys/socket.h>`

`#define MAX 80`

`#define PORT 8080`

`#define SA struct sockaddr`

`void` `func(int` `sockfd)`

`{`

`char` `buff[MAX];`

`int` `n;`

`for` `(;;) {`

`bzero(buff, sizeof(buff));`

`printf("Enter the string : ");`

`n = 0;`

`while` `((buff[n++] = getchar()) != '\n')`

`;`

`write(sockfd, buff, sizeof(buff));`

`bzero(buff, sizeof(buff));`

`read(sockfd, buff, sizeof(buff));`

`printf("From Server : %s", buff);`

`if` `((strncmp(buff, "exit", 4)) == 0) {`

`printf("Client Exit...\n");`

`break;`

`}`

`}`

`}`

`int` `main()`

`{`

`int` `sockfd, connfd;`

`struct` `sockaddr_in servaddr, cli;`

`// socket create and verification`

`sockfd = socket(AF_INET, SOCK_STREAM, 0);`

`if` `(sockfd == -1) {`

`printf("socket creation failed...\n");`

`exit(0);`

`}`

`else`

`printf("Socket successfully created..\n");`

`bzero(&servaddr, sizeof(servaddr));`

`// assign IP, PORT`

`servaddr.sin_family = AF_INET;`

`servaddr.sin_addr.s_addr = inet_addr("127.0.0.1");`

`servaddr.sin_port = htons(PORT);`

`// connect the client socket to server socket`

`if` `(connect(sockfd, (SA*)&servaddr, sizeof(servaddr)) != 0) {`

`printf("connection with the server failed...\n");`

`exit(0);`

`}`

`else`

`printf("connected to the server..\n");`

`// function for chat`

`func(sockfd);`

`// close the socket`

`close(sockfd);`

`}`

**Compilation –** Server side: gcc server.c -o server ./server

Client side: gcc client.c -o client ./client

**Output –**

Server side:

```
Socket successfully created..
Socket successfully binded..
Server listening..
server accept the client...
From client: hi
     To client : hello
From client: exit
     To client : exit
Server Exit...
```

Client side:

```
Socket successfully created..
connected to the server..
Enter the string : hi
From Server : hello
Enter the string : exit
From Server : exit
Client Exit...
```
*** User Datagram Protocol (UDP)
**User Datagram Protocol (UDP)** is a Transport Layer protocol. UDP is a part of the Internet Protocol suite, referred to as UDP/IP suite. Unlike TCP, it is an **unreliable and connectionless protocol.** So, there is no need to establish a connection prior to data transfer.

Though
 Transmission Control Protocol (TCP) is the dominant transport layer 
protocol used with most of the Internet services; provides assured 
delivery, reliability, and much more but all these services cost us 
additional overhead and latency. Here, UDP comes into the picture. For 
real-time services like computer gaming, voice or video communication, 
live conferences; we need UDP. Since high performance is needed, UDP 
permits packets to be dropped instead of processing delayed packets. 
There is no error checking in UDP, so it also saves bandwidth. User Datagram Protocol (UDP) is more efficient in terms of both latency and bandwidth.

**UDP Header –**

UDP header is an **8-bytes**
 fixed and simple header, while for TCP it may vary from 20 bytes to 60 
bytes. The first 8 Bytes contains all necessary header information and 
the remaining part consist of data. UDP port number fields are each 16 
bits long, therefore the range for port numbers is defined from 0 to 
65535; port number 0 is reserved. Port numbers help to distinguish 
different user requests or processes.

!https://media.geeksforgeeks.org/wp-content/uploads/UDP-header.png

1. **Source Port:** Source Port is a 2 Byte long field used to identify the port number of the source.
2. **Destination Port:** It is a 2 Byte long field, used to identify the port of the destined packet.
3. **Length:** Length is the length of UDP including the header and the data. It is a 16-bits field.
4. **Checksum:** Checksum is 2 Bytes long field. It is the 16-bit one’s complement of
the one’s complement sum of the UDP header, the pseudo-header of
information from the IP header, and the data, padded with zero octets at the end (if necessary) to make a multiple of two octets.

**Notes –**
 Unlike TCP, the Checksum calculation is not mandatory in UDP. No Error 
control or flow control is provided by UDP. Hence UDP depends on IP and 
ICMP for error reporting.

**Applications of UDP:**

- Used for simple request-response communication when the size of data is less and hence there is lesser concern about flow and error control.
- It is a suitable protocol for multicasting as UDP supports packet switching.
- UDP is used for some routing update protocols like RIP(Routing Information Protocol).
- Normally used for real-time applications which can not tolerate uneven delays between sections of a received message.
- Following implementations uses UDP as a transport layer protocol:
    - NTP (Network Time Protocol)
    - DNS (Domain Name Service)
    - BOOTP, DHCP.
    - NNP (Network News Protocol)
    - Quote of the day protocol
    - TFTP, RTSP, RIP.
- The application layer can do some of the tasks through UDP-
    - Trace Route
    - Record Route
    - Timestamp
- UDP takes a datagram from Network Layer, attaches its header, and sends it to the user. So, it works fast.
- Actually, UDP is a null protocol if you remove the checksum field.
    1. Reduce the requirement of computer resources.
    2. When using the Multicast or Broadcast to transfer.
    3. The transmission of Real-time packets, mainly in multimedia applications.
1. [GATE CS 2013, Question 12](https://www.geeksforgeeks.org/gate-gate-cs-2013-question-12/)
2. [GATE CS 2012, Question 65](https://www.geeksforgeeks.org/gate-gate-cs-2012-question-22-2/)
3. [GATE CS 2007, Question 20](https://www.geeksforgeeks.org/gate-gate-cs-2007-question-20/)
4. [GATE CS 2005, Question 23](https://www.geeksforgeeks.org/gate-gate-cs-2005-question-23/)
5. [GATE IT 2008, Question 66](https://www.geeksforgeeks.org/gate-gate-it-2008-question-66/)
6. [GATE Mock 2015, Question 5](https://www.geeksforgeeks.org/gate-gate-cs-2015-mock-test-question-5/)
*** Differences between TCP and UDP
[Untitled Database](https://www.notion.so/180e59230eba45d1a347f4b6b7857eb8?pvs=21)

A short example to understand the differences clearly : Suppose
 there are two houses, H1 and H2 and a letter have to be sent from H1 to
 H2. But there is a river in between those two houses. Now how can we 
send the letter? Solution 1: Make a bridge over the river and then it can be delivered. Solution 2: Get it delivered through a pigeon.

Consider the first solution as TCP. A connection has to be made ( bridge ) to get the data (letter) delivered. The data is reliable because it will directly reach another end without loss in data or error. And the second solution is UDP. No connection is required for sending the data. The
 process is fast as compared to TCP, where we need to set up a 
connection(bridge). But the data is not reliable: we don’t know whether 
the pigeon will go in the right direction, or it will drop the letter on
 the way, or some issue is encountered in mid-travel.
 
*** Multiplexing and Demultiplexing in Transport Layer
**Prerequisite –** [Layers of OSI Model](https://www.geeksforgeeks.org/layers-osi-model/) Multiplexing
 and Demultiplexing services are provided in almost every protocol 
architecture ever designed. UDP and TCP perform the demultiplexing and 
multiplexing jobs by including two special fields in the segment 
headers: the source port number field and the destination port number 
field.

**Multiplexing –** Gathering
 data from multiple application processes of the sender, enveloping that
 data with a header, and sending them as a whole to the intended 
receiver is called multiplexing.

**Demultiplexing –** Delivering received segments at the receiver side to the correct app layer processes is called demultiplexing.

!https://media.geeksforgeeks.org/wp-content/cdn-uploads/CN_Multiplexing-1.jpg

**Figure –** Abstract view of multiplexing and demultiplexing

Multiplexing and demultiplexing are the services facilitated by the transport layer of the OSI model.

!https://media.geeksforgeeks.org/wp-content/cdn-uploads/CN_Multiplexing-2.jpg

**Figure –** Transport layer- junction for multiplexing and demultiplexing

There are two types of multiplexing and Demultiplexing : 

1. Connectionless Multiplexing and Demultiplexing
2. Connection-Oriented Multiplexing and Demultiplexing

**How Multiplexing and Demultiplexing is done –** For
 sending data from an application on the sender side to an application 
at the destination side, the sender must know the IP address of the 
destination and port number of the application (at the destination side)
 to which he wants to transfer the data. Block diagram is shown below :

!https://media.geeksforgeeks.org/wp-content/cdn-uploads/CN_Multiplexing-3.jpg

**Figure –** Transfer of packet between applications of sender and receiver

Let
 us consider two messaging apps that are widely used nowadays viz. Hike 
and WhatsApp. Suppose A is the sender and B is the receiver. Both sender
 and receiver have these applications installed in their system (say 
smartphone). Suppose A wants to send messages to B in WhatsApp and hike 
both. In order to do so, A must mention the IP address of B and 
destination port number of the WhatsApp while sending the message 
through the WhatsApp application. Similarly, for the latter case, A must
 mention the IP address of B and the destination port number of the hike
 while sending the message.

Now the messages from both the apps 
will be wrapped up along with appropriate headers(viz. source IP 
address, destination IP address, source port no, destination port 
number) and sent as a single message to the receiver. This process is 
called multiplexing. At the destination, the received message is 
unwrapped and constituent messages (viz messages from a hike and 
WhatsApp application) are sent to the appropriate application by looking
 to the destination the port number. This process is called 
demultiplexing. Similarly, B can also transfer the messages to A.

!https://media.geeksforgeeks.org/wp-content/cdn-uploads/CN_Multiplexing-4.jpg

**Figure –** Message transfer using WhatsApp and hike messaging application

**References –** [Multiplexing/Demultiplexing](http://www.cs.ccsu.edu/~stan/classes/cs490/slides/networks4-ch3-1.pdf) [dcs.bbk.ac.uk](http://www.dcs.bbk.ac.uk/~ptw/teaching/IWT/transport-layer/notes.html)

This article is contributed by **Shivam Shukla**. If you like GeeksforGeeks and would like to contribute, you can also write an article using [write.geeksforgeeks.org](https://write.geeksforgeeks.org/)
 or mail your article to review-team@geeksforgeeks.org. See your article
 appearing on the GeeksforGeeks main page and help other Geeks.

Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above.
** APPLICATION LAYER
*** Protocols in Application Layer
### Application Layer:-

The
 application layer is present at the top of the OSI model. It is the 
layer through which users interact. It provides services to the user.

### Application Layer protocol:-

### 1. TELNET:

Telnet stands for the **TEL**etype **NET**work.
 It helps in terminal emulation. It allows Telnet clients to access the 
resources of the Telnet server. It is used for managing files on the 
internet. It is used for the initial setup of devices like switches. The
 telnet command is a command that uses the Telnet protocol to 
communicate with a remote device or system. Port number of telnet is 
23. 

**Command**

```
telnet [\\RemoteServer]
\\RemoteServer   : Specifies the name of the server to which you want to connect
```

### 2. FTP:

FTP
 stands for file transfer protocol. It is the protocol that actually 
lets us transfer files. It can facilitate this between any two machines 
using it. But FTP is not just a protocol but it is also a program.FTP 
promotes sharing of files via remote computers with reliable and 
efficient data transfer. The Port number for FTP is 20 for data and 21 
for control.

**Command**

```
ftp machinename
```

### 3. TFTP:

The
 Trivial File Transfer Protocol (TFTP) is the stripped-down, stock 
version of FTP, but it’s the protocol of choice if you know exactly what
 you want and where to find it. It’s a technology for transferring files
 between network devices and is a simplified version of FTP. The Port 
number for TFTP is 69.

**Command**

```
tftp [ options... ] [host [port]] [-c command]
```

### 4. NFS:

It
 stands for a network file system. It allows remote hosts to mount file 
systems over a network and interact with those file systems as though 
they are mounted locally. This enables system administrators to 
consolidate resources onto centralized servers on the network. The Port 
number for NFS is 2049.

**Command**

```
service nfs start
```

### 5. SMTP:

It
 stands for Simple Mail Transfer Protocol. It is a part of the TCP/IP 
protocol. Using a process called “store and forward,” SMTP moves your 
email on and across networks. It works closely with something called the
 Mail Transfer Agent (MTA) to send your communication to the right 
computer and email inbox. The Port number for SMTP is 25.

**Command**

```
MAIL FROM:<mail@abc.com?
```

### 6. LPD:

It
 stands for Line Printer Daemon. It is designed for printer sharing. It 
is the part that receives and processes the request. A “daemon” is a 
server or agent. The Port number for LPD is 515.

**Command**

```
lpd [ -d ] [ -l ] [ -D DebugOutputFile]
```

### 7. X window:

It
 defines a protocol for the writing of graphical user interface–based 
client/server applications. The idea is to allow a program, called a 
client, to run on one computer. It is primarily used in networks of 
interconnected mainframes. Port number for X window starts from 6000 and
 increases by 1 for each server.

**Command**

```
Run xdm in runlevel 5
```

### 8. SNMP:

It
 stands for Simple Network Management Protocol. It gathers data by 
polling the devices on the network from a management station at fixed or
 random intervals, requiring them to disclose certain information. It is
 a way that servers can share information about their current state, and
 also a channel through which an administrate can modify pre-defined 
values. The Port number of SNMP is 161(TCP) and 162(UDP). 

**Command**

```
snmpget -mALL -v1 -cpublic snmp_agent_Ip_address sysName.0
```

### 9. DNS:

It
 stands for Domain Name System. Every time you use a domain name, 
therefore, a DNS service must translate the name into the corresponding 
IP address. For example, the domain name www.abc.com might translate to 
198.105.232.4. The Port number for DNS is 53. 

**Command**

```
ipconfig /flushdns
```

### 10. DHCP:

It
 stands for Dynamic Host Configuration Protocol (DHCP). It gives IP 
addresses to hosts. There is a lot of information a DHCP server can 
provide to a host when the host is registering for an IP address with 
the DHCP server. Port number for DHCP is 67, 68.

**Command**

```
clear ip dhcp binding {address | * }
```

This article is contributed by **Kritka**. If you like GeeksforGeeks and would like to contribute, you can also write an article using [write.geeksforgeeks.org](https://write.geeksforgeeks.org/)
 or mail your article to review-team@geeksforgeeks.org. See your article
 appearing on the GeeksforGeeks main page and help other Geeks.

Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above.
*** Domain Name System (DNS) in Application Layer
DNS
 is a hostname for IP address translation service. DNS is a distributed 
database implemented in a hierarchy of name servers. It is an 
application layer protocol for message exchange between clients and 
servers.

**Requirement:**
 Every host is identified by the IP address but remembering numbers is 
very difficult for the people also the IP addresses are not static 
therefore a mapping is required to change the domain name to the IP 
address. So DNS is used to convert the domain name of the websites to 
their numerical IP address.

**Domain:** There are various kinds of DOMAIN:

1. Generic domain: .com(commercial) .edu(educational) .mil(military) .org(non
profit organization) .net(similar to commercial) all these are generic
domain.
2. Country domain .in (india) .us .uk
3. Inverse domain if we want to know what is the domain name of the website. Ip to domain name mapping. So DNS can provide both the mapping for example to find the ip addresses of geeksforgeeks.org then we have to type
nslookup www.geeksforgeeks.org.

**Organization of Domain:**

!https://media.geeksforgeeks.org/wp-content/cdn-uploads/gq/2017/02/DNS.png

It
 is very difficult to find out the ip address associated to a website 
because there are millions of websites and with all those websites we 
should be able to generate the ip address immediately, there should not 
be a lot of delay for that to happen organization of database is very 
important.

**DNS record:**
 Domain name, ip address what is the validity?? what is the time to live
 ?? and all the information related to that domain name. These records 
are stored in tree like structure.

**Namespace:**
 Set of possible names, flat or hierarchical. The naming system 
maintains a collection of bindings of names to values – given a name, a 
resolution mechanism returns the corresponding value.

**Name server:**
 It is an implementation of the resolution mechanism. DNS (Domain Name 
System) = Name service in Internet – Zone is an administrative unit, 
domain is a subtree.

**Name to Address Resolution:**

!https://media.geeksforgeeks.org/wp-content/cdn-uploads/gq/2017/02/DNS_2.png

The
 host requests the DNS name server to resolve the domain name. And the 
name server returns the IP address corresponding to that domain name to 
the host so that the host can future connect to that IP address.

**Hierarchy of Name Servers** **Root name servers:**
 It is contacted by name servers that can not resolve the name. It 
contacts authoritative name server if name mapping is not known. It then
 gets the mapping and returns the IP address to the host.

**Top level domain (TLD) server:**
 It is responsible for com, org, edu etc and all top level country 
domains like uk, fr, ca, in etc. They have info about authoritative 
domain servers and know the names and IP addresses of each authoritative
 name server for the second-level domains.

**Authoritative name servers** are
 the organization’s DNS server, providing authoritative hostName to IP 
mapping for organization servers. It can be maintained by an 
organization or service provider. In order to reach cse.dtu.in we have 
to ask the root DNS server, then it will point out to the top level 
domain server and then to authoritative domain name server which 
actually contains the IP address. So the authoritative domain server 
will return the associative ip address.

**Domain Name Server**

!https://media.geeksforgeeks.org/wp-content/cdn-uploads/gq/2017/02/DNS_3.png

The
 client machine sends a request to the local name server, which , if 
root does not find the address in its database, sends a request to the 
root name server , which in turn, will route the query to an top-level 
domain (TLD) or authoritative name server. The root name server can also
 contain some hostName to IP address mappings. The Top-level domain 
(TLD) server always knows who the authoritative name server is. So 
finally the IP address is returned to the local name server which in 
turn returns the IP address to the host.

This article is contributed by **Monika Singh**
*** Address Resolution in DNS (Domain Name Server)
Prerequisite – [Domain Name Server](https://www.geeksforgeeks.org/dns-domain-name-server/) Mapping a domain name to an IP Address is known as **Name-Address Resolution**. The Domain Name Server (DNS) Resolver performs this operation by consulting name servers.

In
 order to find a particular DNS requesting host place its query to the 
Local DNS Server with a mapping request. If it has the information, the 
resolver is satisfied else the resolver is referred to other servers or 
other servers are asked to provide the information. After the resolver, 
gets the response, it checks whether the response is correct or not. If 
the response is correct, the response is passed to the process that 
requested it, else the name query fails.

A resolution can be of two types – iterative and recursive. 

**1. Recursive Resolution –** Here,
 the client requires the Local Server to give either the requested 
mapping or an error message. A DNS Query is generated by the application
 program to the resolver to fetch the destination IP Address. The Query 
is then forward to the local DNS Server. If it knows the IP Address, it 
sends a response to the resolver. Assuming, it does not know the IP 
Address, it sends the query to the root name server.

The root 
name server contains information about at least one server of Top Level 
Domain. The query is then sent to the respective Top-Level Domain 
server. If it contains the mapping, the response is sent back to the 
root server and then to the host’s local server. If it doesn’t contain 
the mapping, it should contain the IP Address of the destination’s local
 DNS Server. The local DNS server knows the destination host’s IP 
Address. The information is then sent back to the top-level domain 
server, then to the root server and then to the host’s Local DNS Server,
 and finally to the host.

!https://media.geeksforgeeks.org/wp-content/uploads/222-1.jpg

**2. Iterative Resolution –** The
 main difference between iterative and recursive resolution is that here
 each server that does not know the mapping sends the IP Address of the 
next server to the one requested it. Here, the client allows the server 
to return the best answer it can give as a match or as a referral. A DNS
 Query is generated by the application program to the resolver to fetch 
the destination IP Address. The Query is then forward to the local DNS 
Server. Assuming, it does not know the IP Address, it sends the query to
 the root name server.

The root name server returns the IP 
Address of the Top-Level Domain Server to the Local Server. The 
Top-Level Domain server is contacted by the Local Server and it returns 
either the IP of the destination host or its local DNS Server. If it 
returns the server’s address, then by contacting the destination’s Local
 DNS Server, we get the IP Address of the destination host. The 
response/mapping is then passed from the host’s local DNS server to the 
resolver and then finally to the host.

**Caching Mechanism –** In
 both iterative and recursive resolution, after a server asks for a 
mapping request from another server, it receives the response and stores
 this information in the Cache memory before sending it to the client. 
This is done to lower the search time it takes for a server to check the
 IP Address in its Database. So, the next time, if a request comes to 
the server, it first checks its cache memory and tries to resolve the 
request. The response is marked as **Unauthoritative** to 
inform the client that the response is from Cache. The only way caching 
can be problematic is when the server caches the mapping for a long time
 and the mapping gets outdated. However, there are techniques to resolve
 this like using **TTL**.
 
*** DNS Spoofing or DNS Cache poisoning
Prerequisite – [Domain Name Server](https://www.geeksforgeeks.org/dns-domain-name-server/) Before Discussing DNS Spoofing, First, discuss what is DNS.

**A Domain Name System (DNS)**
 converts a human-readable name (such as www.geeksforgeeks.org) to a 
numeric IP address. The DNS system responds to one or more IP-address by
 which your computer connects to a website (such as geeksforgeeks.org) 
by using one of the IP-address.

There is not only one DNS server.
 There are series of DNS servers used to resolve the domain name. DNS 
uses cache to work efficiently so that it can quickly refer to DNS 
lookups it’s already performed rather than performing a DNS lookup over 
and over again. Although DNS caching increase the speed of the 
domain name resolution process But the major change in the domain then 
takes a day to reflect worldwide.

**DNS Spoofing** 
means getting a wrong entry or IP address of the requested site from the
 DNS server. Attackers find out the flaws in the DNS system and take 
control and will redirect to a malicious website.

!https://media.geeksforgeeks.org/wp-content/uploads/DNS_Spoofing.png

**In above image –**

1. Request to Real Website: User hits a request for a particular website it goes
to the DNS server to resolve the IP address of that website.
2. Inject Fake DNS entry: Hackers already take control over the DNS server by
detecting the flaws and now they add false entries to the DNS server.
3. Resolve to Fake Website: Since the fake entry in the DNS server redirect the user to the wrong website.

**To Prevent From DNS Spoofing –** DNS
 Security Extensions (DNSSEC) is used to add an additional layer of 
security in the DNS resolution process to prevent security threats such 
as DNS Spoofing or DNS cache poisoning. DNSSEC protects against such attacks by digitally ‘signing’ data so you can be assured it is valid.
*** Why does DNS use UDP and not TCP?
DNS 
is an application layer protocol. All application layer protocols use 
one of the two transport layer protocols, UDP and TCP. TCP is reliable 
and UDP is not reliable. DNS is supposed to be reliable, but it uses 
UDP, why?

There are the following interesting facts about TCP and UDP on the transport layer that justify the above. **1)**
 UDP is much faster. TCP is slow as it requires a 3-way handshake. The 
load on DNS servers is also an important factor. DNS servers (since they
 use UDP) don’t have to keep connections. **2)** DNS requests are generally very small and fit well within UDP segments. **3)**
 UDP is not reliable, but reliability can be added to the application 
layer. An application can use UDP and can be reliable by using a timeout
 and resend at the application layer.

Actually, DNS 
primarily uses the User Datagram Protocol (UDP) on port number 53 to 
serve requests. DNS queries consist of a single UDP request from the 
client followed by a single UDP reply from the server. When the length 
of the answer exceeds 512 bytes and both client and server support EDNS,
 larger UDP packets are used. Otherwise, the query is sent again using 
the Transmission Control Protocol (TCP). TCP is also used for tasks such
 as zone transfers. Some resolver implementations use TCP for all 
queries.

https://en.wikipedia.org/wiki/Domain_Name_System#DNS_protocol_transport

Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above.
*** Dynamic Host Configuration Protocol (DHCP)
Prerequisite – [Protocols in Application Layer](https://www.geeksforgeeks.org/protocols-application-layer/) **Dynamic Host Configuration Protocol(DHCP)** is an application layer protocol which is used to provide: 

1. Subnet Mask (Option 1 – e.g., 255.255.255.0)
2. Router Address (Option 3 – e.g., 192.168.1.1)
3. DNS Address (Option 6 – e.g., 8.8.8.8)
4. Vendor Class Identifier (Option 43 – e.g., ‘unifi’ = 192.168.1.9 ##where unifi = controller)

DHCP is based on a client-server model and based on discovery, offer, request, and ACK.

DHCP **port number**
 for server is 67 and for the client is 68. It is a Client server 
protocol which uses UDP services. IP address is assigned from a pool of 
addresses. In DHCP, the client and the server exchange mainly 4 DHCP 
messages in order to make a connection, also called DORA process, but 
there are 8 DHCP messages in the process.

These messages are given as below:

1. **DHCP discover message –** This is a first message generated in the communication process between
server and client. This message is generated by Client host in order to
discover if there is any DHCP server/servers are present in a network or not. This message is broadcasted to all devices present in a network to find the DHCP server. This message is 342 or 576 bytes long

!https://media.geeksforgeeks.org/wp-content/uploads/DHCP1.png

1. As shown in the figure, source MAC address (client PC) is 08002B2EAF2A,
destination MAC address(server) is FFFFFFFFFFFF, source IP address is
0.0.0.0(because PC has no IP address till now) and destination IP
address is 255.255.255.255 (IP address used for broadcasting). As the
discover message is broadcast to find out the DHCP server or servers in
the network therefore broadcast IP address and MAC address is used. 
2. **DHCP offer message –** The server will respond to host in this message specifying the unleased IP
address and other TCP configuration information. This message is
broadcasted by server. Size of message is 342 bytes. If there are more
than one DHCP servers present in the network then client host will
accept the first DHCP OFFER message it receives. Also a server ID is
specified in the packet in order to identify the server.

!https://media.geeksforgeeks.org/wp-content/uploads/DSCP2.png

1. Now, for the offer message, source IP address is 172.16.32.12 (server’s IP
address in the example), destination IP address is 255.255.255.255
(broadcast IP address) ,source MAC address is 00AA00123456, destination
MAC address is FFFFFFFFFFFF. Here, the offer message is broadcast by the DHCP server therefore destination IP address is broadcast IP address
and destination MAC address is FFFFFFFFFFFF and the source IP address is server IP address and MAC address is server MAC address.
    
    Also 
    the server has provided the offered IP address 192.16.32.51 and lease 
    time of 72 hours(after this time the entry of host will be erased from 
    the server automatically) . Also the client identifier is PC MAC address
     (08002B2EAF2A) for all the messages. 
    
2. **DHCP request message –** When a client receives a offer message, it responds by broadcasting a DHCP
request message. The client will produce a gratuitous ARP in order to
find if there is any other host present in the network with same IP
address. If there is no reply by other host, then there is no host with
same TCP configuration in the network and the message is broadcasted to
server showing the acceptance of IP address .A Client ID is also added
in this message.

!https://media.geeksforgeeks.org/wp-content/uploads/DHCP.png

1. Now, the request message is broadcast by the client PC therefore source IP
address is 0.0.0.0(as the client has no IP right now) and destination IP address is 255.255.255.255 (broadcast IP address) and source MAC
address is 08002B2EAF2A (PC MAC address) and destination MAC address is
FFFFFFFFFFFF.
    
    **Note –** This message is broadcast 
    after the ARP request broadcast by the PC to find out whether any other 
    host is not using that offered IP. If there is no reply, then the client
     host broadcast the DHCP request message for the server showing the 
    acceptance of IP address and Other TCP/IP Configuration. 
    
2. **DHCP acknowledgement message –** In response to the request message received, the server will make an entry with specified client ID and bind the IP address offered with lease
time. Now, the client will have the IP address provided by server.

!https://media.geeksforgeeks.org/wp-content/uploads/DHCP4.png

1. Now the server will make an entry of the client host with the offered IP
address and lease time. This IP address will not be provided by server
to any other host. The destination MAC address is FFFFFFFFFFFF and the
destination IP address is 255.255.255.255 and the source IP address is
172.16.32.12 and the source MAC address is 00AA00123456 (server MAC
address). 
2. **DHCP negative acknowledgement message –** Whenever a DHCP server receives a request for IP address that is invalid
according to the scopes that is configured with, it send DHCP Nak
message to client. Eg-when the server has no IP address unused or the
pool is empty, then this message is sent by the server to client. 
3. **DHCP decline –** If DHCP client determines the offered configuration parameters are
different or invalid, it sends DHCP decline message to the server .When
there is a reply to the gratuitous ARP by any host to the client, the
client sends DHCP decline message to the server showing the offered IP
address is already in use. 
4. **DHCP release –** A DHCP client sends DHCP release packet to server to release IP address and cancel any remaining lease time. 
5. **DHCP inform –** If a client address has obtained IP address manually then the client uses a DHCP inform to obtain other local configuration parameters, such as
domain name. In reply to the dhcp inform message, DHCP server generates
DHCP ack message with local configuration suitable for the client
without allocating a new IP address. This DHCP ack message is unicast to the client. 

**Note –** All the messages can be unicast also by dhcp relay agent if the server is present in different network.

**Advantages –** The advantages of using DHCP include: 

- centralized management of IP addresses
- ease of adding new clients to a network
- reuse of IP addresses reducing the total number of IP addresses that are required
- simple reconfiguration of the IP address space on the DHCP server without needing to reconfigure each client

The DHCP protocol gives the network administrator a method to configure the network from a centralised area. With the help of DHCP, easy handling of new users and reuse of IP address can be achieved.

**Disadvantages –** Disadvantage of using DHCP is: 

- IP conflict can occur

**References –** [DHCP – help.ubnt](https://help.ubnt.com/hc/en-us/articles/115005987748-Intro-to-Networking-Dynamic-Host-Configuration-Protocol-DHCP-) [DHCP – docs.oracle](https://docs.oracle.com/cd/E37670_01/E41138/html/ol_about_netaddr.html)
*** DHCP Relay Agent in Computer Network
Prerequisite – [Dynamic Host Configuration Protocol (DHCP)](https://www.geeksforgeeks.org/computer-network-dynamic-host-configuration-protocol-dhcp/), [How DHCP server dynamically assigns IP address to a host?](https://www.geeksforgeeks.org/how-dhcp-server-dynamically-assigns-ip-address-to-a-host/)

To
 assign an IP address to the host dynamically, the DHCP client exchanges
 DHCP messages with the DHCP server in the DORA process.

In the 
DORA process, the discover and request message is broadcast, the offer 
and the acknowledgement message is broadcast or unicast depending upon 
the value of the broadcast flag i.e. If the value of the broadcast flag 
is 1, then the offer and acknowledgement message is broadcast and if 0, 
the messages are unicast. But this is valid only when the DHCP server is
 present in the same network because the router doesn’t forward any 
broadcast packet. What if the server is present in a different network? 
Here comes the role of DHCP relay agent.

**DHCP Relay Agent –** The
 DHCP relay agent is any TCP/IP host which is used to forward requests 
and replies between the DHCP server and client when the server is 
present on a different network. Relay agents receive DHCP messages and 
then generate a new DHCP message to send out on another INTERFACE. Also,
 the DHCP relay agent adds a giaddr (gateway address of the packet) 
field and also the Relay agent information option 82 if enabled. The 
options field is removed when the server reply is forwarded to the 
host.

**Note –** The discover and request messages are unicast by the DHCP relay agent.

**Example –**

!https://media.geeksforgeeks.org/wp-content/uploads/dhcp1.jpg

Here
 is a topology in which there is a DHCP client having no IP address. 
There is a DHCP server having IP address 192.168.2.2 and there is a 
router in the middle which we want as the DHCP relay agent has an IP 
address 192.168.1.1 on interface fa0/0 and 192.168.2.1 on interface 
fa0/1.

!https://media.geeksforgeeks.org/wp-content/uploads/dhcp2.jpg

Now,
 first, the discover message is broadcast by the DHCP client to find out
 the DHCP server which is received by the switch as it is in the same 
broadcast domain. The switch broadcast the DHCP packet in the network, 
received by both PC and Router(DHCP Relay Agent). The PC and the router 
receive the broadcast packet but the PC drops the packet as the DHCP 
server is present in the different network therefore the packet has to 
be delivered to the default gateway only.

!https://media.geeksforgeeks.org/wp-content/uploads/dhcp3.jpg

The
 router, with DHCP relay agent feature, enabled, replaces the source 
address with its own address and the destination IP address with DHCP 
server IP address i.e. the DHCP relay agent unicast the packet to DHCP 
server. DHCP relay agent adds giaddr field into the packet and forwards 
it to the DHCP server. giaddr field is added to the packet so that the 
server should know from which pool, it has to assign the IP address.

In
 our case, the giaddr field will contain 192.168.1.1 (IP address of the 
interface on which the router [DHCP relay agent] receives the discover 
message).

!https://media.geeksforgeeks.org/wp-content/uploads/dhcp4.jpg

The server replies with a unicast DHCP offer to the router offering the unleashed IP address.

!https://media.geeksforgeeks.org/wp-content/uploads/dhcp5.jpg

In
 return, the router broadcast the DHCP Offer message to the network 
which has sent the DHCP request. The broadcast message is received by a 
switch as shown in the above figure.

!https://media.geeksforgeeks.org/wp-content/uploads/dhcp6.jpg

The switch broadcasts the DHCP offer message to the hosts. Therefore, the message is received by the DHCP client

!https://media.geeksforgeeks.org/wp-content/uploads/dhcp7.jpg

Now,
 the DHCP client broadcast the DHCP request message, showing the 
acceptance of the IP address, for the server which is received by the 
switch. The switch broadcast the DHCP request message to the other host 
and the router(DHCP Relay Agent)as shown in the above figure.

!https://media.geeksforgeeks.org/wp-content/uploads/dhcp8.jpg

The
 router replaces the source IP address with its own IP address and 
destination IP remains the same i.e. It is unicast by the DHCP relay 
agent

!https://media.geeksforgeeks.org/wp-content/uploads/dhcp9.jpg

The server replies with a unicast DHCP Acknowledgement message to the router (DHCP relay agent) as shown in the above figure.

!https://media.geeksforgeeks.org/wp-content/uploads/dhcp10.jpg

The
 router in turn broadcast the DHCP Acknowledgement message to the 
network it receives the DHCP request for an IP address. The broadcast 
message is received by a switch as shown in the above figure.

!https://media.geeksforgeeks.org/wp-content/uploads/dhcp11.jpg

The
 broadcast DHCP Acknowledgement message is received by the DHCP client 
as the switch broadcast the message through all its ports.

**Configuration –**

This
 is the basic configuration of the client, router, dhcp_server. The 
router has been assigning IP addresses 192.168.1.1 on fa0/0 and 
192.168.2.1 on fa0/1.

```
ROUTER(config)#int f0/0
ROUTER(config-if)#ip address 192.168.1.1 255.255.255.0
ROUTER(config-if)#no shutdown
ROUTER(config)#int f0/1
ROUTER(config-if)#ip address 192.168.2.1 255.255.255.0
ROUTER(config-if)#no shutdown
```

The DHCP_SERVER is assigned IP 
Address 192.168.2.2 on the interface fa0/0 and the DHCP pool is defined 
with name POOL1 and network of 192.168.1.0 with subnet mask 
255.255.255.0 is assigned to the pool POOL1.

```

DHCP_SERVER(config)#int f0/0
DHCP_SERVER(config-if)#ip address 192.168.2.2 255.255.255.0
DHCP_SERVER(config-if)#no shutdown
DHCP_SERVER(config)#ip dhcp pool POOL1
DHCP_SERVER(dhcp-config)#network 192.168.1.0 255.255.255.0
DHCP_SERVER(dhcp-config)#default-router 192.168.1.1
DHCP_SERVER(dhcp-config)#exit
```

Now, the IP helper-address command
 is used for configuring the router as a DHCP relay agent, giving 
192.168.2.2 the address of DHCP_server.

```
ROUTER(config)#int f0/0
ROUTER(config-if)#ip helper-address 192.168.2.2
ROUTER(config-if)#exit
```
*** How DHCP server dynamically assigns IP address to a host?
DHCP
 is an abbreviation for Dynamic Host Configuration Protocol. It is an 
application layer protocol used by hosts for obtaining network setup 
information. The DHCP is controlled by a DHCP server that **dynamically distributes** network configuration parameters such as IP addresses, subnet masks, and gateway addresses.

**What is a Dynamic host configuration protocol?** 

- Dynamic – Automatically
- Host – Any computer that is connected to the network
- Configuration – To configure a host means to provide network information(IP address, subnet mask, Gateway address) to a host
- Protocol – Set of rules

Summing up, a DHCP server dynamically configures a host in a network.

**The disadvantage of manually Configuring the host:** Configuring
 a host when it is connected to the network can be done either manually 
i.e., by the network administrator or by the DHCP server. In the case of
 home networks, manual configuration is quite easy. Whereas in large 
networks, the network administrator might face many problems. Also, 
the manual configuration is prone to mistakes. Say a Network 
administrator might assign an IP address that was already assigned. 
Thus, causing difficulty for both administrators as well as neighbors on
 the network.

So, here comes the use of the DHCP server. Before discussing how the DHCP server works, let’s go through the DHCP entities. 

**Configuring a host using DHCP :**To configure a host, we require the following things: 

- **Leased IP address** – IP address to a host that lasts for a particular duration which goes for a few hours, a few days, or a few weeks.
- **Subnet Mask** – The host can know on which network it is on.
- **Gateway address** – The Gateway is the Internet Service Provider that connects users to
the internet. The Gateway address lets the host know where the gateway
is to connect to the internet.

**DHCP Entities**

- **DHCP server:** It automatically provides network information(IP address, subnet mask,
gateway address) on lease. Once the duration is expired, that network
information can be assigned to another machine. It also maintains the
data storage which stores the available IP addresses.
- **DHCP client: ****Any node which requests an IP address allocation to a network is considered a DHCP client.
- **DHCP Relay Agent:** In case, we have only one DHCP server for multiple LAN’s then this Agent
which presents in every network forwards the DHCP request to the DHCP
server. So, using DHCP Relay Agent we can configure multiple LANs with a single server.

**How DHCP server assigns an IP address to a host?**

1. **DHCPDISCOVER:** When a new node is connected to the network, it broadcasts the
DHCPDISCOVER message which contains the source address as 0.0.0.0 to
every node on the network including the server. DHCP server on receiving the message returns the DHCPOFFER message to the requested host which
contains the server address and new IP address to the node.
2. **DHCPOFFER:** If there are multiple servers on the network, the host receives multiple
DHCPOFFER messages. It is up to the host to select a particular
message. 
3. **DHCPREQUEST:** The requested host on receiving the offer message, again broadcasts the DHCPREQUEST
message on the network with the address of the server whose offer
message is accepted by the host. The server which pertains to that
server address sent by the host checks whether the address to be
assigned to the node is available in the data storage. 
4. **DHCPACK:** If the address is assigned, it marks the IP address in the storage as
unavailable to ensure consistency. Now, the server sends a DHCPACK
packet to the requested host which contains network information(IP
address, subnet mask, gateway address). In case, if the address is
assigned to another machine meanwhile, then the server sends the packet
DHCPNAK to the requested host indicating that the IP address is assigned to some other machine. 
5. **DHCPRELEASE:** And
finally, If the host wants to move to another network or if it
has finished its work, it sends the DHCPRELEASE packet to the server
indicating that it wants to disconnect. Then the server marks the IP
address as available in the storage so that it can be assigned to other
machines. 

**References:** For reference to DHCP protocol, [click here](https://www.youtube.com/watch?v=k4t-NJrKLgM)

This article is contributed by **Brahmani Sai**. If you like GeeksforGeeks and would like to contribute, you can also write an article using [write.geeksforgeeks.org](http://www.write.geeksforgeeks.org/)
 or mail your article to review-team@geeksforgeeks.org. See your article
 appearing on the GeeksforGeeks main page and help other Geeks.

Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above.
*** Simple Network Management Protocol (SNMP)
If 
an organization has 1000 devices then to check all devices, one by one 
every day, are working properly or not is a hectic task. To ease these 
up, Simple Network Management Protocol (SNMP) is used.

**Simple Network Management Protocol (SNMP) –** SNMP
 is an application layer protocol that uses UDP port number 161/162.SNMP
 is used to monitor the network, detect network faults, and sometimes 
even used to configure remote devices.

**SNMP components –** There are 3 components of SNMP: 

1. **SNMP Manager –** It is a centralized system used to monitor network. It is also known as Network Management Station (NMS) 
2. **SNMP agent –** It is a software management software module installed on a managed device. Managed devices can be network devices like PC, routers, switches,
servers, etc. 
3. **Management Information Base –** MIB consists of information on resources that are to be managed. This
information is organized hierarchically. It consists of objects
instances which are essentially variables. 

**SNMP messages –** Different variables are: 

1. **GetRequest –** SNMP manager sends this message to request data from the SNMP agent. It is
simply used to retrieve data from SNMP agents. In response to this, the
SNMP agent responds with the requested value through a response
message. 
2. **GetNextRequest –** This
message can be sent to discover what data is available on an SNMP agent. The SNMP manager can request data continuously until no more data is
left. In this way, the SNMP manager can take knowledge of all the
available data on SNMP agents. 
3. **GetBulkRequest –** This message is used to retrieve large data at once by the SNMP manager from the SNMP agent. It is introduced in SNMPv2c. 
4. **SetRequest –** It is used by the SNMP manager to set the value of an object instance on the SNMP agent. 
5. **Response –** It is a message sent from the agent upon a request from the manager. When
sent in response to Get messages, it will contain the data requested.
When sent in response to the Set message, it will contain the newly set
value as confirmation that the value has been set. 
6. **Trap –** These are the message sent by the agent without being requested by the manager. It is sent when a fault has occurred. 
7. **InformRequest –** It was introduced in SNMPv2c, used to identify if the trap message has
been received by the manager or not. The agents can be configured to
send trap message continuously until it receives an Inform message. It
is the same as a trap but adds an acknowledgement that the trap doesn’t
provide. 

**SNMP security levels –** It
 defines the type of security algorithm performed on SNMP packets. These
 are used in only SNMPv3. There are 3 security levels namely: 

1. **noAuthNoPriv –** This (no authentication, no privacy) security level uses a community string for authentication and no encryption for privacy. 
2. **authNopriv –** This security level (authentication, no privacy) uses HMAC with Md5 for authentication and no encryption is used for privacy. 
3. **authPriv –** This security level (authentication, privacy) uses HMAC with Md5 or SHA for authentication and encryption uses the DES-56 algorithm. 

**SNMP versions –** There are 3 versions of SNMP: 

1. **SNMPv1 –** It uses community strings for authentication and uses UDP only. 
2. **SNMPv2c –** It uses community strings for authentication. It uses UDP but can be configured to use TCP. 
3. **SNMPv3 –** It uses Hash-based MAC with MD5 or SHA for authentication and DES-56 for
privacy. This version uses TCP. Therefore, the conclusion is the higher
the version of SNMP, the more secure it will be.
*** Simple Mail Transfer Protocol (SMTP)
Email
 is emerging as one of the most valuable services on the internet today.
 Most internet systems use SMTP as a method to transfer mail from one 
user to another. SMTP is a push protocol and is used to send the mail 
whereas POP (post office protocol) or IMAP (internet message access 
protocol) are used to retrieve those emails at the receiver’s side.

**SMTP Fundamentals** SMTP
 is an application layer protocol. The client who wants to send the mail
 opens a TCP connection to the SMTP server and then sends the mail 
across the connection. The SMTP server is an always-on listening mode. 
As soon as it listens for a TCP connection from any client, the SMTP 
process initiates a connection through port 25. After successfully 
establishing a TCP connection the client process sends the mail 
instantly.

**SMTP Protocol**

The SMTP model is of two types:

1. End-to-end method
2. Store-and- forward method

The
 end-to-end model is used to communicate between different organizations
 whereas the store and forward method is used within an organization. An
 SMTP client who wants to send the mail will contact the destination’s 
host SMTP directly, in order to send the mail to the destination. The 
SMTP server will keep the mail to itself until it is successfully copied
 to the receiver’s SMTP. The client SMTP is the one that initiates 
the session so let us call it client- SMTP and the server SMTP is the 
one that responds to the session request so let us call it 
receiver-SMTP. The client- SMTP will start the session and the 
receiver-SMTP will respond to the request.

**Model of SMTP system**

In
 the SMTP model user deals with the user agent (UA), for example, 
Microsoft Outlook, Netscape, Mozilla, etc. In order to exchange the mail
 using TCP, MTA is used. The user sending the mail doesn’t have to deal 
with MTA as it is the responsibility of the system admin to set up a 
local MTA. The MTA maintains a small queue of mails so that it can 
schedule repeat delivery of mails in case the receiver is not available.
 The MTA delivers the mail to the mailboxes and the information can 
later be downloaded by the user agents.

!https://media.geeksforgeeks.org/wp-content/cdn-uploads/gq/2017/02/SMTP_1.png

**Both the SMTP-client and SMTP-server should have 2 components:**

1. User-agent (UA)
2. Local MTA

**Communication between sender and the receiver :** The
 sender’s user agent prepares the message and sends it to the MTA. The 
MTA’s responsibility is to transfer the mail across the network to the 
receiver’s MTA. To send mails, a system must have a client MTA, and to 
receive mails, a system must have a server MTA.

**SENDING EMAIL:** Mail
 is sent by a series of request and response messages between the client
 and the server. The message which is sent across consists of a header 
and a body. A null line is used to terminate the mail header and 
everything after the null line is considered as the body of the message,
 which is a sequence of ASCII characters. The message body contains the 
actual information read by the receipt.

**RECEIVING EMAIL:** The
 user agent at the server-side checks the mailboxes at a particular time
 of intervals. If any information is received, it informs the user about
 the mail. When the user tries to read the mail it displays a list of 
emails with a short description of each mail in the mailbox. By 
selecting any of the mail users can view its contents on the terminal.

**Some SMTP Commands:**

- HELO – Identifies the client to the server, fully qualified domain name, only sent once per session
- MAIL – Initiate a message transfer, fully qualified domain of originator
- RCPT – Follows MAIL, identifies an addressee, typically the fully qualified
name of the addressee, and for multiple addressees use one RCPT for each addressee
- DATA – send data line by line

This article is contributed by **Monika Singh**
*** File Transfer Protocol (FTP) in Application Laye
Prerequisite: [Protocols in Application Layer](https://www.geeksforgeeks.org/protocols-application-layer/)

File
 Transfer Protocol(FTP) is an application layer protocol that moves 
files between local and remote file systems. It runs on the top of TCP, 
like HTTP. To transfer a file, 2 TCP connections are used by FTP in 
parallel: control connection and data connection.

!https://media.geeksforgeeks.org/wp-content/uploads/FTP.jpg

**What is a control connection?** For
 sending control information like user identification, password, 
commands to change the remote directory, commands to retrieve and store 
files, etc., FTP makes use of a control connection. The control 
connection is initiated on port number 21.

**What is a data connection?** For sending the actual file, FTP makes use of a data connection. A data connection is initiated on port number 20. FTP
 sends the control information out-of-band as it uses a separate control
 connection. Some protocols send their request and response header lines
 and the data in the same TCP connection. For this reason, they are said
 to send their control information in-band. HTTP and SMTP are such 
examples.

**FTP Session :** When an FTP session 
is started between a client and a server, the client initiates a control
 TCP connection with the server-side. The client sends control 
information over this. When the server receives this, it initiates a 
data connection to the client-side. Only one file can be sent over one 
data connection. But the control connection remains active throughout 
the user session. As we know HTTP is stateless i.e. it does not have to 
keep track of any user state. But FTP needs to maintain a state about 
its user throughout the session.

**Data Structures:** FTP allows three types of data structures :

1. **File Structure –** In file structure, there is no internal structure and the file is considered to be a continuous sequence of data bytes.
2. **Record Structure –** In record structure, the file is made up of sequential records.
3. **Page Structure –** In page structure, the file is made up of independent indexed pages.

**FTP Commands –** Some of the FTP commands are :

*USER* – This command sends the user identification to the server. *PASS* – This command sends the user password to the server. *CWD*
 – This command allows the user to work with a different directory or 
dataset for file storage or retrieval without altering his login or 
accounting information. *RMD* – This command causes the directory specified in the path name to be removed as a directory. *MKD* – This command causes the directory specified in the pathname to be created as a directory. *PWD* – This command causes the name of the current working directory to be returned in the reply. *RETR* – This command causes the remote host to initiate a data connection and to send the requested file over the data connection. *STOR* – This command causes to store of a file into the current directory of the remote host. *LIST* – Sends a request to display the list of all the files present in the directory. *ABOR* – This command tells the server to abort the previous FTP service command and any associated transfer of data. *QUIT* – This command terminates a USER and if file transfer is not in progress, the server closes the control connection.

**FTP Replies –** Some of the FTP replies are :

200 Command okay. 530 Not logged in. 331 User name okay, need a password. 225 Data connection open; no transfer in progress. 221 Service closing control connection. 551 Requested action aborted: page type unknown. 502 Command not implemented. 503 Bad sequence of commands. 504 Command not implemented for that parameter. 

- FTP uses TCP as a transport layer protocol.
- It is good for simple file transfers, such as during boot time.
- Errors in the transmission (lost packets, checksum errors) must be handled by the TFTP server.
- It uses only one connection through well-known port 69.
- TFTP uses a simple lock-step protocol (each data packet needs to be acknowledged). Thus the throughput is limited

### Advantages of FTP(File Transfer Protocol):-

- Speed is one of the advantages of FTP(File Transfer Protocol).
- File sharing also comes in the category of advantages of FTP in this between two machines files can be shared on the network.
- Efficiency is more in FTP.

### Disadvantages of FTP(File Transfer Protocol):-

- File size limit is the drawback of FTP only 2 GB size files can be transferred.
- Multiple receivers are not supported by the FTP.
- FTP does not encrypt the data this is one of the biggest drawbacks of FTP.
- FTP is unsecured we use login IDs and passwords making it secure but they can be attacked by hackers.

**Anonymous FTP:** 
 Anonymous FTP is enabled on some sites whose files are available for 
public access. A user can access these files without having any username
 or password. Instead, the username is set to anonymous and the password
 to the guest by default. Here, user access is very limited. For 
example, the user can be allowed to copy the files but not to navigate 
through directories.

This article is contributed by **Achiv Chauhan**. If you like GeeksforGeeks and would like to contribute, you can also write an article using [write.geeksforgeeks.org](http://www.write.geeksforgeeks.org/)
 or mail your article to review-team@geeksforgeeks.org. See your article
 appearing on the GeeksforGeeks main page and help other Geeks.

Please write comments if you find anything incorrect, or if you want to share more information about the topic discussed above.
*** HTTP Non-Persistent & Persistent Connection
The 
Hypertext Transfer Protocol (HTTP) is an application-level protocol that
 uses TCP as an underlying transport and typically runs on port 80. HTTP
 is a stateless protocol i.e. server maintains no information about past
 client requests.

**HTTP Connections**

1. Non-Persistent
2. Persistent

Before starting with persistent and non-persistent HTTP connection lets know what is RTT.

**RTT**-> Time for a small packet to travel from client to server and back.

```
RTT= 2*propagation time
```

1. For a connection Persistent or Non-persistent it is sure that to initiate TCP connection one RTT is used.2. One RTT is used for HTTP request and first few bytes to HTTP response to return.

So in order to know total file transmission time->

```
 total = 2RTT+transmit time
```

**Difference between Persistent & Non-Persistent connection.**

!https://media.geeksforgeeks.org/wp-content/uploads/rough.jpg

**Non-Persistent Connection**

1. Without parallel connection
2. With parallel connection

**Without parallel connection Non-Persistent**Each objection takes two RTT (assuming no window limit) one for TCP connection and other for HTTP image/text file.

**With parallel connection Non-Persistent**

!https://media.geeksforgeeks.org/wp-content/uploads/1.-1.png

**Persistent connection**

1. Non-Pipelined
2. Pipelined

!https://media.geeksforgeeks.org/wp-content/uploads/2.-1.png

In **Non-pipeline connection**
 we first establish connection which takes two RTT then we send all the 
objects images/text files which takes 1 RTT each (TCP for each object is
 not required).

In **Pipelined connection** 2RTT for connection establishment and then 1RTT(assuming no window limit) for all the objects i.e. images/text.

**Advantages of persistent connections :**1) Lower CPU and memory usage because there are less number of connections.2) Allows HTTP pipelining of requests and responses.3) Reduced network congestion (fewer TCP connections).4) Reduced latency in subsequent requests (no handshaking).5) Errors can be reported without the penalty of closing the TCP connection.

**Disadvantages of persistent connections :**Resources may be kept occupied even when not needed and may not be available to others.

Most of the modern browsers like Chrome, Firefox and Internet Explorer use persistent connections.

**Reference :** https://en.wikipedia.org/wiki/HTTP_persistent_connection

This article is contributed by **SHAURYA UPPAL**. If you like GeeksforGeeks and would like to contribute, you can also write an article using [write.geeksforgeeks.org](https://write.geeksforgeeks.org/)
 or mail your article to review-team@geeksforgeeks.org. See your article
 appearing on the GeeksforGeeks main page and help other Geeks.

Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above.

*** Multipurpose Internet Mail Extension (MIME) Protocol
**Multipurpose Internet Mail Extension (MIME)** is a standard that was proposed by Bell Communications in 1991 in order to expand the limited capabilities of email. MIME is a kind of add-on *or a supplementary protocol*
 that allows non-ASCII data to be sent through SMTP. It allows the users
 to exchange different kinds of data files on the Internet: audio, 
video, images, application programs as well.

**Why do we need MIME?** Limitations of Simple Mail Transfer Protocol (SMTP):

1. SMTP has a very simple structure
2. Its simplicity however comes with a price as it only sends messages in NVT 7-bit ASCII format.
3. It cannot be used for languages that do not support 7-bit ASCII format
such as French, German, Russian, Chinese and Japanese, etc. so it cannot be transmitted using SMTP. So, in order *to make SMTP more broad*, *we use MIME*.
4. It cannot be used to send binary files or video or audio data.

**Purpose and Functionality of MIME –** Growing
 demand for Email Messages as people also want to express themselves in 
terms of Multimedia. So, MIME another email application is introduced as
 it is not restricted to textual data.

MIME *transforms non-ASCII data*
 at the sender side to NVT 7-bit data and delivers it to the client 
SMTP. The message on the receiver side is transferred back to the 
original data. As well as we can send video and audio data using MIME as
 it transfers them also in 7-bit ASCII data.

**Features of MIME –**

1. It is able to send multiple attachments with a single message.
2. Unlimited message length.
3. Binary attachments (executables, images, audio, or video files) may be divided if needed.
4. MIME provided support for varying content types and multi-part messages.

**Working of MIME –** Suppose
 a user wants to send an email through a user agent and it is in a 
non-ASCII format so there is a MIME protocol that converts it into 7-bit
 NVT ASCII format. The message is transferred through the e-mail system 
to the other side in the 7-bit format now MIME protocol again converts 
it back into non-ASCII code and now the user agent of the receiver side 
reads it and then information is finally read by the receiver. MIME 
header is basically inserted at the beginning of any e-mail transfer.

**MIME with SMTP and POP –** SMTP
 transfers the mail being a message transfer agent from the sender’s 
side to the mailbox of the receiver side and stores it and MIME header 
is added to the original header and provides additional information. 
while POP being the message access agent organizes the mails from the 
mail server to the receiver’s computer. POP allows the user agent to 
connect with the message transfer agent.

**MIME Header:** It is added to the original e-mail header section to define transformation. There are *five headers* that we add to the original header:

1. **MIME-Version –** Defines the version of the MIME protocol. It must have the parameter *Value 1.0*, which indicates that message is formatted using MIME.
2. **Content-Type –** Type of data used in the body of the message. They are of different types
like text data (plain, HTML), audio content, or video content.
3. **Content-Type Encoding –** It defines the method used for encoding the message. Like 7-bit encoding, 8-bit encoding, etc.
4. **Content Id –** It is used for uniquely identifying the message.
5. **Content description –** It defines whether the body is actually an image, video, or audio.
*** Difference between http and https
In address bar of a browser, have you noticed either *http://* or *https://* at the time of browsing a website? If neither of these are present then most likely, it’s *http://* Let’s find out the difference…

In
 short, both of these are protocols using which the information of a 
particular website is exchanged between Web Server and Web Browser. But 
what’s difference between these two? Well, extra

***s***

is present in

*https*

and that makes it secure! What a difference

A very short and concise difference between

*http*

and

*https*

is that

*https*

is much more secure compared to

*http*

.

Let us dig a little more. **H**yper**T**ext **T**ransfer **P**rotocol (HTTP) is a protocol using which hypertext is transferred over the Web. Due to its simplicity, *http* has been the most widely used protocol for data transfer over the Web but the data (i.e. hypertext) exchanged using *http* isn’t as secure as we would like it to be. In fact, hyper-text exchanged using *http*
 goes as plain text i.e. anyone between the browser and server can read 
it relatively easy if one intercepts this exchange of data. But why do 
we need this security over the Web? Think of ‘Online shopping’ at Amazon
 or Flipkart. You might have noticed that as soon as we click on the 
Check-out on these online shopping portals, the address bar gets changed
 to use *https*. This is done so that the subsequent data transfer (i.e. financial transaction etc.) is made secure. And that’s why *https*
 was introduced so that a secure session is setup first between Server 
and Browser. In fact, cryptographic protocols such as SSL and/or TLS 
turn *http* into *https* i.e. **https** = **http** + **cryptographic protocols**. Also, to achieve this security in *https*,
 Public Key Infrastructure (PKI) is used because public keys can be used
 by several Web Browsers while private key can be used by the Web Server
 of that particular website. The distribution of these public keys is 
done via Certificates which are maintained by the Browser. You can check
 these certificates in your Browser settings. We’ll detail out this 
setting up secure session procedure in another post.

Also, another syntactic difference between *http* and *https* is that *http* uses default port 80 while *https* uses default port 443. But it should be noted that this security in *https*
 is achieved at the cost of processing time because Web Server and Web 
Browser needs to exchange encryption keys using Certificates before 
actual data can be transferred. Basically, setting up of a secure 
session is done before the actual hypertext exchange between server and 
browser.

**Differences between HTTP and HTTPS**

- HTTP stands for HyperText Transfer Protocol and HTTPS stands for HyperText Transfer Protocol Secure.
- In HTTP, URL begins with “http://” whereas URL starts with “https://”
- HTTP uses port number 80 for communication and HTTPS uses 443
- HTTP is considered to be insecure and HTTPS is secure
- HTTP Works at Application Layer and HTTPS works at Transport Layer
- In HTTP, Encryption is absent and Encryption is present in HTTPS as discussed above
- HTTP does not require any certificates and HTTPS needs SSL Certificates
- HTTP speed is faster than HTTPS and HTTPS speed is slower than HTTP
- HTTP does not improve search ranking while HTTPS improves search ranking.
- HTTP does not use data hashtags to secure data, while HTTPS will have the
data before sending it and return it to its original state on the
receiver side.
*** What’s difference between The Internet and The Web ?
Do many folks consider that they both are the same but are they really the same?

*The Internet* is a global network of networks while *the Web*, also referred formally as World Wide Web (www) is a collection of information that is accessed via *the Internet*. Another way to look at this difference is; *the Internet* is infrastructure while *the Web* is served on top of that infrastructure. Alternatively, *the Internet* can be viewed as a big book store while *the Web* can be viewed as a collection of books on that store. At a high level, we can even think of *the Internet* as hardware and *the Web* as software!

Web
 applications use HTTP protocol which is a layer over TCP protocol. 
Whereas internet applications can use either TCP or UDP protocol. To 
visualize the difference think of it as the internet is a network of 
many computers connected together so you can use any port say 90 to send
 or receive data whereas in web port is fixed as HTTP uses port 80 to 
communicate and also the data which is sent is HTML, CSS, and 
JavaScript. So if you want a feel of internet application make a socket 
connection at a random port and send data to another computer via the 
socket. So in this case you are using the internet for communication and
 not the web.

Hope this helps!!
*** Basics of Wi-Fi
We’ve
 been studying a lot about the Wired Network. Ethernet is the most 
common example. Wired networks differ from wireless which uses radio 
waves rather than transmitting electrical signals over the cables.Wi-Fi stands for Wireless Fidelity. It is a technology for wireless local area networking with devices based on [IEEE 802.11](https://en.wikipedia.org/wiki/IEEE_802.11) standards.Wi-Fi compatible devices can connect to the internet via WLAN network and a wireless **[access point](https://en.wikipedia.org/wiki/Wireless_access_point)** abbreviated as AP. Every WLAN has an access point which is responsible for receiving and transmitting data from/to users.IEEE has defined certain specifications for wireless LAN, called **IEEE 802.11** which covers physical and data link layers.

**[Access Point(AP)](https://www.geeksforgeeks.org/basics-of-wi-fi/#AccessPoint)**

is a wireless LAN base station that can connect one or many wireless devices simultaneously to internet.

The architecture of this standard has 2 kinds of services:

**1. BSS (Basic Service Set)2. ESS (Extended Service Set)**

**BSS**

is
 the basic building block of WLAN. It is made of wireless mobile 
stations and an optional central base station called Access Point.

Stations can form a network without an AP and can agree to be a part of a BSS.

A BSS without an AP cannot send data to other BSSs and defines a standalone network. It is called

**Ad-hoc network**

or

**Independent BSS(IBSS).**

i.e A BSS without AP is an ad-hoc network.

A BSS with AP is

**infrastructure network.**

The figure below depicts an IBSS, BSS with the green coloured box depicting an AP.

!https://media.geeksforgeeks.org/wp-content/uploads/BaicsWiFi.png

**ESS**
 is made up of 2 or more BSSs with APs. BSSs are connected to the 
distribution system via their APs. The distribution system can be any 
IEEE LAN such as Ethernet. ESS has 2 kinds of stations:

1. Mobile – stations inside the BSS

2. Stationary – AP stations that are part of wired LAN.

!https://media.geeksforgeeks.org/wp-content/uploads/BaicsWiFi-1.png

The topmost green box represents the distribution system and the other 2 green boxes represent the APs of 2 BSSs.

This article is contributed by **Saloni.**
 If you like GeeksforGeeks and would like to contribute, you can also 
write an article and mail your article to contribute@geeksforgeeks.org. 
See your article appearing on the GeeksforGeeks main page and help other
 Geeks.
 
*** Wifi protected setup (WPS)
The **Wifi protected setup (WPS)**
 is a wireless network security standard that tries to make connections 
between a router and wireless devices in a faster and easier way. WPS 
works only for wireless networks that use a password that is protected 
with the *Wifi Protected Access Personal (WPA)* or *Wifi Protected Access2 (WPA2)*
 Personal security protocols. WPS does not work on wireless networks 
that use the disfavoured Wired Equivalent Privacy (WEP) security, which 
can be cracked easily by any hacker with basic skills.

In
 a standard setup, you can’t connect a wireless device to a wireless 
network until you know the network name (also named Service Set 
Identifier(SSID)) and its password (also called WPA-PSK key). If you 
want to connect a device, like your smartphone or a laptop, to your 
wireless network then on your device, you must first pick the network 
that you want to connect to and then enter its security password.

!https://media.geeksforgeeks.org/wp-content/uploads/222-9.png

**What can WPS do?** WPS can sometimes simplify the connection process. Here’s how **WPS connections** can be performed: 

1. First, press the WPS button on your router to turn on the discovery of new
devices. Then select the network you want to connect to on your device.
The device is automatically connected to the wireless network without
entering the network password. 
2. Devices like wireless
printers or range extenders have their own WPS button that can be used
for making quick connections. These devices can be connected to a
wireless network by pressing the WPS button on the router and then on
those devices. There is no need to input any data during this process.
WPS automatically sends the network password, and these devices remember it for future use. The devices will be able to connect to the same
network in the future without using the WPS button again. 
3. A third method involves the use of an eight-digit PIN. All routers with
WPS enabled to have a PIN code that is generated automatically and
cannot be configured by the users. This PIN can be found on the WPS
configuration page on your router. Some devices are without a WPS button but with WPS support they ask for that PIN. If the pin is entered, they authenticate themselves and connect to the wireless network. 
4. The last method also involves using an eight-digit PIN. Some devices
without a WPS button but with WPS support generate a client PIN. This
PIN can be entered in your router’s wireless configuration panels, and
then the router will use it to add that device to the network. 

The
 first two methods are fast but the last two methods do not provide any 
benefits regarding the time it takes to connect devices to your wireless
 network. The *eight-digit PIN* needs to be typed and typing the 
wireless network password is just slow. The fourth method of connecting 
to a wireless network is even slower because the router’s wireless 
configuration section needs to be accessed and the PIN is to be typed 
provided by the client device.

**Advantages of WPS –**

- WPS configures the network name (SSID) and WPA security key automatically
for the access point having WPS enabled on the network.
- SSID security key or passphrase need not be known when connecting WPS-enabled devices.
- WPS keys are randomly generated so no one can guess or figure out your security key or passphrase.
- Long sequences of hexadecimal codes or passphrases need not be entered.
- Extensible Authentication Protocol (EAP) is used to securely exchange information
and network credentials over the air, which is one of the authentication protocols used in WPA2.

**Disadvantages of WPS –**

- Network mode where wireless devices are communicated directly to each other without an access point is not supported by WPS.
- The WPS cannot be used if WiFi devices on the network are WPS certified or WPS-compatible.
- It is very difficult to add a non-WPS client device to the network as long sequences of hexadecimal characters are generated by the WPS
technology.
*** Wifi protected access (WPA)
The two security protocols and security certification programs are *Wi-Fi Protected Access (WPA)* and *Wi-Fi Protected Access II (WPA2)*.
 These are developed by the Wi-Fi Alliance to secure wireless computer 
networks. The Alliance defined these protocols because of the serious 
weaknesses the researchers found in the previous system, Wired 
Equivalent Privacy (WEP).

WPA
 also referred to as the draft IEEE 802.11i standard became available in
 2003. The Wi-Fi Alliance made it as an intermediate measure in 
anticipation of the availability of the more secure and complex WPA2, 
which became available in 2004 which is a common shorthand for the full 
IEEE 802.11i (or IEEE 802.11i-2004) standard.

In January 2018, with several security improvements over WPA2 Wi-Fi Alliance announced the release of *WPA3*.

1. **WPA –** The WPA is an intermediate measure to take the place of WEP. WPA could be
implemented through firmware upgrades on wireless network interface
cards that were designed for WEP in 1999. However, since more changes
were required in the wireless access points (APs) than those needed on
the network cards, most pre-2003 APs could not be upgraded to support
WPA.
    
    The WPA protocol implements almost all of the IEEE 802.11i 
    standard. The Temporal Key Integrity Protocol (TKIP) was adopted for 
    WPA. WEP used a 64-bit or 128-bit encryption key that must be manually 
    entered on wireless access points and devices which once entered can 
    never be changed. TKIP employs a per-packet key, which means that it 
    dynamically generates a new 128-bit key for each packet and thus 
    prevents the types of attacks that compromised WEP.
    
    WPA included a
     Message Integrity Check, which is designed to prevent an attacker to 
    alter or resend data packets. This replaced the cyclic redundancy check 
    (CRC) that was used by the WEP standard. CRC’s had a main flaw that it 
    did not provide a sufficiently strong data integrity guarantee for the 
    packets it handled. Well tested message authentication codes existed to 
    solve these problems, but they required too much computation to be used 
    on old network cards. WPA uses a message integrity check algorithm 
    called TKIP to verify the integrity of the packets. TKIP is much 
    stronger than a CRC, but the algorithm used in WPA2 is stronger. 
    Researchers discovered a flaw in WPA similar to older weaknesses in WEP 
    and the limitations of the message integrity code hash function, named 
    Michael, that is used to retrieve the keystream from short packets to 
    use for re-injection and spoofing.
    
2. **WPA2 –** WPA2 replaced WPA. WPA2, which requires testing and certification by the
Wi-Fi Alliance, implemented the mandatory elements of IEEE 802.11i.
Particularly, it included mandatory support for CCMP(Counter Mode
CBC-MAC Protocol), an AES(Advanced Encryption Standard) based encryption mode. Certification began in September, 2004. WPA2 certification is
mandatory for all new devices to bear the Wi-Fi trademark from March 13, 2006.
*** Difference between LiFi and WiFi
**Wi-Fi(wireless fidelity)** and **Li-Fi(light fidelity)** are two different technologies that are used *to send and receive data wirelessly*.
 In the case of Wi-Fi, we use Routers and Radio Frequency (RF) waves to 
transmit data, whereas in Li-Fi we use LED bulbs and Light signals to 
transmit and receive data.

The basic difference between LiFi and WiFi are as follows:

[Untitled Database](https://www.notion.so/1f83f5890181424eb769c7890fd3feb9?pvs=21)
** foot notes
